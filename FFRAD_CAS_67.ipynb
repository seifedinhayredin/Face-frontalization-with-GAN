{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a423dfbd-2bc1-44b6-9a8a-dc964718ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Additional information about the CUDA device\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd25df7-05b1-4635-85fe-4e5b277afd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900e08a8-bb57-441a-8453-13ed0468fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb20345-d854-4ef0-bb51-cf66c67edbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60af3247-8422-46cd-b953-6bd80f4e814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, width, height)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f82e90-8c62-4cbe-9000-d8e119fcc139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92691ab7-ac17-4792-af78-ab72ad8de9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        max_pool = self.max_pool(x)\n",
    "        avg_out = self.fc(avg_pool)\n",
    "        max_out = self.fc(max_pool)\n",
    "        out = avg_out + max_out\n",
    "        return out * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08f1af-044c-43f3-949f-cf371faa07c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3019fdcc-2860-4793-890e-f47083861fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1),  # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(64)  # Add channel attention\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),         # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(128)  # Add channel attention\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),        # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(256)  # Add channel attention\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),        # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),       # 1x1\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),   # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 256, 4, 2, 1),   # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(256)  # Add self-attention\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, 4, 2, 1),   # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(128)  # Add self-attention\n",
    "        )\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1),    # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 1, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "        enc6 = self.encoder6(enc5)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc6)\n",
    "\n",
    "        # Decoding and adding skip connection\n",
    "        dec1 = self.decoder1(torch.cat([bottleneck, enc6], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([dec1, enc5], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([dec2, enc4], dim=1))\n",
    "        dec4 = self.decoder4(torch.cat([dec3, enc3], dim=1))\n",
    "        dec5 = self.decoder5(torch.cat([dec4, enc2], dim=1))\n",
    "        decoded = self.decoder6(torch.cat([dec5, enc1], dim=1))\n",
    "\n",
    "        return decoded\n",
    "\n",
    "# Example usage:\n",
    "# generator = G()\n",
    "# generator.apply(weights_init)\n",
    "# print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dc895-b81e-4f12-a657-692a98917658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14960e53-e9f7-470e-a37d-7619e96c973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RelativeAvgDiscriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(RelativeAvgDiscriminator, self).__init__()\n",
    "\n",
    "    # Separate feature extraction for real and generated data\n",
    "    self.conv_real = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 4, 2, 1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(16, 32, 4, 2, 1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(32, 64, 4, 2, 1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "    self.conv_generated = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 4, 2, 1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(16, 32, 4, 2, 1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(32, 64, 4, 2, 1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "\n",
    "    # Relative Average Pooling\n",
    "    self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # Remaining convolutional layers (modified for combined features)\n",
    "    self.post_pool = nn.Sequential(\n",
    "        nn.Conv2d(128, 128, 4, 2, 1),  # Input channels changed to 128\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(128, 256, 4, 2, 1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "       \n",
    "    )\n",
    "\n",
    "    # Output layer with sigmoid activation\n",
    "    self.output = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, real, fake):\n",
    "    # Extract features from real and generated data\n",
    "    real_features = self.conv_real(real)\n",
    "    generated_features = self.conv_generated(fake)\n",
    "\n",
    "    # Concatenate features before pooling\n",
    "    combined_features = torch.cat([real_features, generated_features], dim=1)\n",
    "\n",
    "    # Relative Average Pooling\n",
    "    features = self.avgpool(combined_features)\n",
    "\n",
    "    # Process features with remaining layers\n",
    "    output = self.post_pool(features)\n",
    "\n",
    "    # Probability score\n",
    "    #probability = self.output(logits)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4b9a1-e9b3-4733-ae38-1dbe65172a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5e94e0-9ca3-4466-90ea-1eb6430971b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Define a function to calculate PSNR\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "# Define a function to calculate SSIM\n",
    "# Define a function to calculate SSIM\n",
    "def calculate_ssim(img1, img2):\n",
    "    # Ensure tensors are on the same device\n",
    "    if img1.device != img2.device:\n",
    "        raise ValueError(\"Input tensors must be on the same device\")\n",
    "\n",
    "    # Calculate SSIM directly on GPU tensors\n",
    "    img1 = img1.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    img2 = img2.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    return ssim(img1.transpose(1, 2, 0), img2.transpose(1, 2, 0), multichannel=True, data_range=1)\n",
    "\n",
    "\n",
    "# Define lists to store PSNR and SSIM values for each epoch\n",
    "psnr_values = []\n",
    "ssim_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f56e2-09ec-40ad-95a4-a4556ca96198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd9580e-2c1d-495f-ad8d-1f05cb0278bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "#gpu_id = 0\n",
    "#device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "netG = G().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = RelativeAvgDiscriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "L1_factor = 1\n",
    "L2_factor = 1\n",
    "GAN_factor = 0.005\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.002, betas=(0.5, 0.999), eps=1e-8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cf441-631c-41a8-bce8-96d6cd851a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5be3d16-f84d-47bb-8df5-4b45323224d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the losses\n",
    "losses_L1 = []\n",
    "losses_L2 = []\n",
    "losses_gan = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab0221-2504-4525-a667-effc587fe7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9986a49e-3aa8-49d5-a8f6-c5b77f67f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def multi_scale_pixelwise_loss(fake_images, real_images, num_scales=3):\n",
    "    loss = 0.0\n",
    "    for scale in range(num_scales):\n",
    "        fake_scaled = F.interpolate(fake_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        real_scaled = F.interpolate(real_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        pixel_loss = F.l1_loss(fake_scaled, real_scaled)\n",
    "        loss += pixel_loss / (2 ** scale)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec6d77-0d99-4e34-8c1b-c4b1ba2c200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e26b18-a07f-4458-9daa-07327c6448df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store losses\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "multi_scale_losses = []\n",
    "\n",
    "avg_generator_losses = []\n",
    "avg_discriminator_losses = []\n",
    "avg_multi_scale_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a78d3b-749e-4e49-8e3d-ede1b20b85df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c0516e-e3d9-4643-99b6-c64a7a0a937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac877be8-7fce-4f88-b256-decdffd43c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcd7851d-f9c3-4746-8daa-f58d15ffe6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='missing_files.log', level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "def get_subdirs(directory):\n",
    "    subdirs = sorted([os.path.join(directory, name) for name in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, name))])\n",
    "    return subdirs\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get subdirectories (assuming \"pose\" and \"frontal\" folders exist)\n",
    "        self.pose_dirs = os.path.join(imageset_dir, \"pose\")\n",
    "        self.frontal_dir = os.path.join(imageset_dir, \"frontal\")\n",
    "        print(self.frontal_dir)\n",
    "        print(self.pose_dirs)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = [os.path.join(self.pose_dirs, file) for file in sorted(os.listdir(self.pose_dirs)) if is_jpeg(file)]\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Collect frontal image paths\n",
    "        self.frontal_files = [os.path.join(self.frontal_dir, file) for file in sorted(os.listdir(self.frontal_dir)) if is_jpeg(file)]\n",
    "        print(len(self.frontal_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "            np.random.shuffle(self.frontal_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            try:\n",
    "                with Image.open(profile_filename) as profile_img:\n",
    "                    profiles.append(np.array(profile_img))\n",
    "            except FileNotFoundError:\n",
    "                logging.error(f'Profile image not found: {profile_filename}')\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                logging.error(f'Error opening profile image {profile_filename}: {e}')\n",
    "                raise\n",
    "\n",
    "            if frontal_filename is None:\n",
    "                logging.error(f'Matching frontal image not found for: {profile_filename}')\n",
    "                raise FileNotFoundError(f'Matching frontal image not found for: {profile_filename}')\n",
    "            try:\n",
    "                with Image.open(frontal_filename) as frontal_img:\n",
    "                    frontals.append(np.array(frontal_img))\n",
    "            except FileNotFoundError:\n",
    "                logging.error(f'Frontal image not found: {frontal_filename}')\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                logging.error(f'Error opening frontal image {frontal_filename}: {e}')\n",
    "                raise\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[1]\n",
    "        for frontal_file in self.frontal_files:\n",
    "            if profile_name in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64, device=device):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7905e-9c9f-49c9-b100-e496fddbbe00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8f0e44-71c9-4f33-a685-2ddb5c89d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\CAS_5000\\frontal\n",
      "C:\\Users\\zed\\Dataset\\CAS_5000\\pose\n",
      "5248\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"C:\\Users\\zed\\Dataset\\CAS_5000\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "#gpu_id = 0\n",
    "#device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "#checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=1, device=device)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,batch_size=128,drop_last=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b921581-f45b-48fe-ba0c-17908b568052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a4bbb26-29f2-4355-bf5f-6ea3cea8aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir1 = \"FFRAD_CAS_67_Checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17770732-ad7f-419e-a80a-4453c9f107df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc87e21-df1a-4165-a123-c1ff63872002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:18:27<00:00, 290.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  12311.57608294487  seconds\n",
      "[1/40] Training absolute losses: L1 0.0033723 ; L2 0.0009225 BCE 0.0049726; Average PSNR: 9.52; Average SSIM: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:11:25<00:00, 280.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/40] Training absolute losses: L1 0.0026301 ; L2 0.0005976 BCE 0.0053839; Average PSNR: 11.18; Average SSIM: 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:12:02<00:00, 281.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/40] Training absolute losses: L1 0.0024495 ; L2 0.0005318 BCE 0.0054906; Average PSNR: 11.68; Average SSIM: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  24%|█████████████████▌                                                      | 10/41 [12:09<54:41, 105.86s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbdbea-004d-4666-b68c-94caa2eeb86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d6b4bf-ca37-49d2-9a65-c7a85963ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = 44\n",
    "checkpoint_path = os.path.join(checkpoint_dir1, f\"checkpoint_{latest_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "\n",
    "# Load training progress\n",
    "loss_L1 = checkpoint['loss_L1']\n",
    "loss_L2 = checkpoint['loss_L2']\n",
    "loss_gan = checkpoint['loss_gan']\n",
    "psnr_values = checkpoint['psnr_values']\n",
    "ssim_values = checkpoint['ssim_values']\n",
    "losses_L1 = checkpoint['losses_L1']\n",
    "losses_L2 = checkpoint['losses_L2']\n",
    "losses_gan = checkpoint['losses_gan']\n",
    "discriminator_losses = checkpoint['discriminator_losses']\n",
    "generator_losses = checkpoint['generator_losses']\n",
    "multi_scale_losses = checkpoint['multi_scale_losses']\n",
    "avg_generator_losses = checkpoint['avg_generator_losses']\n",
    "avg_discriminator_losses = checkpoint['avg_discriminator_losses']\n",
    "avg_multi_scale_losses = checkpoint['avg_multi_scale_losses']\n",
    "\n",
    "# Start training from the loaded epoch\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf14f-2311-412a-b007-4ba89ab6030b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6641b66-358d-493a-8f7d-c126331eb4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:12:25<00:00, 281.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/40] Training absolute losses: L1 0.0023149 ; L2 0.0004862 BCE 0.0055652; Average PSNR: 12.07; Average SSIM: 0.4877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:09:26<00:00, 277.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/40] Training absolute losses: L1 0.0021452 ; L2 0.0004263 BCE 0.0055383; Average PSNR: 12.64; Average SSIM: 0.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:15:15<00:00, 285.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/40] Training absolute losses: L1 0.0019310 ; L2 0.0003568 BCE 0.0055936; Average PSNR: 13.41; Average SSIM: 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  88%|█████████████████████████████████████████████████████████████▍        | 36/41 [2:25:57<37:12, 446.51s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366650b-46fe-432b-a95f-473c21911c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b889bb-d779-49f8-8991-2bc98e5995cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:12:02<00:00, 281.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/40] Training absolute losses: L1 0.0018586 ; L2 0.0003356 BCE 0.0055806; Average PSNR: 13.68; Average SSIM: 0.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  78%|██████████████████████████████████████████████████████▋               | 32/41 [1:55:41<59:10, 394.48s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e658a3e-b3d1-4129-bc07-f8edfd318e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066b601-87a7-43aa-aa1e-0155d67426ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:11:51<00:00, 280.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/40] Training absolute losses: L1 0.0016755 ; L2 0.0002746 BCE 0.0055999; Average PSNR: 14.56; Average SSIM: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:09:38<00:00, 277.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/40] Training absolute losses: L1 0.0015052 ; L2 0.0002263 BCE 0.0055916; Average PSNR: 15.39; Average SSIM: 0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [3:09:09<00:00, 276.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/40] Training absolute losses: L1 0.0013512 ; L2 0.0001849 BCE 0.0056376; Average PSNR: 16.27; Average SSIM: 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:33<00:00, 277.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/40] Training absolute losses: L1 0.0012374 ; L2 0.0001582 BCE 0.0056452; Average PSNR: 16.95; Average SSIM: 0.7732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:11:58<00:00, 280.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/40] Training absolute losses: L1 0.0011309 ; L2 0.0001343 BCE 0.0056330; Average PSNR: 17.67; Average SSIM: 0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:11:09<00:00, 279.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/40] Training absolute losses: L1 0.0010402 ; L2 0.0001155 BCE 0.0056815; Average PSNR: 18.32; Average SSIM: 0.8223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:16<00:00, 278.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/40] Training absolute losses: L1 0.0009716 ; L2 0.0001012 BCE 0.0056465; Average PSNR: 18.89; Average SSIM: 0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:38<00:00, 277.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/40] Training absolute losses: L1 0.0008892 ; L2 0.0000875 BCE 0.0056663; Average PSNR: 19.52; Average SSIM: 0.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:43<00:00, 277.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/40] Training absolute losses: L1 0.0008396 ; L2 0.0000779 BCE 0.0056431; Average PSNR: 20.03; Average SSIM: 0.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:20<00:00, 277.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/40] Training absolute losses: L1 0.0007822 ; L2 0.0000693 BCE 0.0056704; Average PSNR: 20.53; Average SSIM: 0.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:24<00:00, 277.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/40] Training absolute losses: L1 0.0007507 ; L2 0.0000635 BCE 0.0056558; Average PSNR: 20.92; Average SSIM: 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:23<00:00, 277.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/40] Training absolute losses: L1 0.0006997 ; L2 0.0000568 BCE 0.0055507; Average PSNR: 21.41; Average SSIM: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:51<00:00, 279.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/40] Training absolute losses: L1 0.0006872 ; L2 0.0000534 BCE 0.0057500; Average PSNR: 21.68; Average SSIM: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:01<00:00, 278.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/40] Training absolute losses: L1 0.0006487 ; L2 0.0000486 BCE 0.0057599; Average PSNR: 22.08; Average SSIM: 0.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:02<00:00, 278.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/40] Training absolute losses: L1 0.0006238 ; L2 0.0000450 BCE 0.0057495; Average PSNR: 22.42; Average SSIM: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:03<00:00, 278.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/40] Training absolute losses: L1 0.0006109 ; L2 0.0000428 BCE 0.0057326; Average PSNR: 22.64; Average SSIM: 0.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:05<00:00, 278.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/40] Training absolute losses: L1 0.0005837 ; L2 0.0000393 BCE 0.0057399; Average PSNR: 23.01; Average SSIM: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:27<00:00, 277.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/40] Training absolute losses: L1 0.0005659 ; L2 0.0000370 BCE 0.0057262; Average PSNR: 23.27; Average SSIM: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:57<00:00, 277.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/40] Training absolute losses: L1 0.0005649 ; L2 0.0000359 BCE 0.0057331; Average PSNR: 23.42; Average SSIM: 0.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:06<00:00, 278.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/40] Training absolute losses: L1 0.0005305 ; L2 0.0000327 BCE 0.0057221; Average PSNR: 23.81; Average SSIM: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:17:06<00:00, 288.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/40] Training absolute losses: L1 0.0005356 ; L2 0.0000319 BCE 0.0057093; Average PSNR: 23.93; Average SSIM: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28:   7%|█████▎                                                                   | 3/41 [01:05<15:48, 24.95s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e16975-f840-446a-9767-c65a52ffcc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bda48db-6666-40c8-b37f-abd66c7836de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:27:08<00:00, 303.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/40] Training absolute losses: L1 0.0005017 ; L2 0.0000293 BCE 0.0057040; Average PSNR: 24.31; Average SSIM: 0.9472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:13:24<00:00, 283.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/40] Training absolute losses: L1 0.0004948 ; L2 0.0000281 BCE 0.0057237; Average PSNR: 24.46; Average SSIM: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:14:50<00:00, 285.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/40] Training absolute losses: L1 0.0004921 ; L2 0.0000273 BCE 0.0056990; Average PSNR: 24.60; Average SSIM: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:12:05<00:00, 281.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/40] Training absolute losses: L1 0.0004690 ; L2 0.0000255 BCE 0.0057066; Average PSNR: 24.90; Average SSIM: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:12:21<00:00, 281.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/40] Training absolute losses: L1 0.0004691 ; L2 0.0000249 BCE 0.0057332; Average PSNR: 25.01; Average SSIM: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:11:44<00:00, 280.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/40] Training absolute losses: L1 0.0004519 ; L2 0.0000236 BCE 0.0057327; Average PSNR: 25.24; Average SSIM: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:15:08<00:00, 285.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/40] Training absolute losses: L1 0.0004536 ; L2 0.0000232 BCE 0.0057067; Average PSNR: 25.32; Average SSIM: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:14:26<00:00, 284.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/40] Training absolute losses: L1 0.0004376 ; L2 0.0000221 BCE 0.0057132; Average PSNR: 25.53; Average SSIM: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:13:28<00:00, 283.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/40] Training absolute losses: L1 0.0004444 ; L2 0.0000220 BCE 0.0057289; Average PSNR: 25.54; Average SSIM: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:12:10<00:00, 281.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/40] Training absolute losses: L1 0.0004252 ; L2 0.0000207 BCE 0.0057273; Average PSNR: 25.81; Average SSIM: 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:12:09<00:00, 281.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39/40] Training absolute losses: L1 0.0004299 ; L2 0.0000206 BCE 0.0057002; Average PSNR: 25.82; Average SSIM: 0.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:11:57<00:00, 280.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/40] Training absolute losses: L1 0.0004176 ; L2 0.0000198 BCE 0.0057145; Average PSNR: 26.01; Average SSIM: 0.9658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6421c-34ce-4c5b-97dc-02cbb2efc4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f3cf3-2693-4dc2-b51c-830333360f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:16:22<00:00, 287.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/50] Training absolute losses: L1 0.0004146 ; L2 0.0000193 BCE 0.0057004; Average PSNR: 26.11; Average SSIM: 0.9661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41:  61%|████████████████████████████████████████▊                          | 25/41 [1:13:22<1:22:21, 308.87s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,50):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/50] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b9410-f6ba-46c1-91b4-fe3cc2c2e06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946e8dc-de87-4c78-ab2b-e952b87f5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:13:39<00:00, 283.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42/50] Training absolute losses: L1 0.0003961 ; L2 0.0000181 BCE 0.0056868; Average PSNR: 26.39; Average SSIM: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:05<00:00, 276.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/50] Training absolute losses: L1 0.0003984 ; L2 0.0000180 BCE 0.0057351; Average PSNR: 26.41; Average SSIM: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:26:30<00:00, 302.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/50] Training absolute losses: L1 0.0003907 ; L2 0.0000173 BCE 0.0057037; Average PSNR: 26.57; Average SSIM: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:10:32<00:00, 278.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/50] Training absolute losses: L1 0.0003866 ; L2 0.0000169 BCE 0.0057082; Average PSNR: 26.67; Average SSIM: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45:  63%|██████████████████████████████████████████▍                        | 26/41 [1:17:54<1:19:27, 317.82s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,50):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/50] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32107726-c36d-46f4-8dfc-1625f39ee513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0591d5-3476-4280-a987-642b76163633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:19:09<00:00, 291.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/50] Training absolute losses: L1 0.0003797 ; L2 0.0000164 BCE 0.0057218; Average PSNR: 26.80; Average SSIM: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:08:41<00:00, 276.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/50] Training absolute losses: L1 0.0003740 ; L2 0.0000159 BCE 0.0057250; Average PSNR: 26.92; Average SSIM: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:09:11<00:00, 276.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/50] Training absolute losses: L1 0.0003671 ; L2 0.0000155 BCE 0.0057053; Average PSNR: 27.06; Average SSIM: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:08:35<00:00, 275.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/50] Training absolute losses: L1 0.0003629 ; L2 0.0000151 BCE 0.0057157; Average PSNR: 27.16; Average SSIM: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|█████████████████████████████████████████████████████████████████████| 41/41 [3:07:57<00:00, 275.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/50] Training absolute losses: L1 0.0003583 ; L2 0.0000148 BCE 0.0056949; Average PSNR: 27.27; Average SSIM: 0.9744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,50):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/50] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_67_Output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_67_Output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_67_Output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_67_Output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d87a3e-626a-48ab-8fbf-869828193c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
