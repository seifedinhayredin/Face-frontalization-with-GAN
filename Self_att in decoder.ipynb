{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f7a994-ed57-467b-8032-dfcdb25e4080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627085d-336e-494c-9805-cba8b2095c62",
   "metadata": {},
   "source": [
    "**Training CAS-PEAL-R1 with self-attention in decoder part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7c2b8-13e3-4aaf-a933-900aaff91757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9286293d-12a2-457c-8177-e711d7db5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "def get_subdirs(directory):\n",
    "    subdirs = sorted([os.path.join(directory, name) for name in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, name))])\n",
    "    return subdirs\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get subdirectories (assuming \"pose\" and \"frontal\" folders exist)\n",
    "        #self.pose_dirs = get_subdirs(os.path.join(imageset_dir, \"pose\"))\n",
    "        self.pose_dirs = os.path.join(imageset_dir, \"pose\")\n",
    "        self.frontal_dir = os.path.join(imageset_dir, \"frontal\")\n",
    "        print(self.frontal_dir)\n",
    "        print(self.pose_dirs)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = []\n",
    "        #for pose_dir in self.pose_dirs:\n",
    "        profile_files = [os.path.join(self.pose_dirs, file) for file in sorted(os.listdir(self.pose_dirs)) if is_jpeg(file)]\n",
    "        self.profile_files.extend(profile_files)\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Collect frontal image paths\n",
    "        self.frontal_files = [os.path.join(self.frontal_dir, file) for file in sorted(os.listdir(self.frontal_dir)) if is_jpeg(file)]\n",
    "        print(len(self.frontal_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "            np.random.shuffle(self.frontal_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            with Image.open(profile_filename) as profile_img:\n",
    "                profiles.append(np.array(profile_img))\n",
    "            with Image.open(frontal_filename) as frontal_img:\n",
    "                frontals.append(np.array(frontal_img))\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[0]\n",
    "        for frontal_file in self.frontal_files:\n",
    "            if profile_name in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64,device_id = 0):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Calculate mean and standard deviation for each channel separately\n",
    "        #mean = np.array([0.5, 0.5, 0.5])  # Assuming RGB images have pixel values in [0, 255] range\n",
    "        #std = np.array([0.5, 0.5, 0.5])   # Assuming RGB images have pixel values in [0, 255] range\n",
    "        \n",
    "        # Normalize each channel independently\n",
    "        #normalized_images = (resized_images / 255.0 - mean) / std\n",
    "        #normalized_targets = (resized_targets / 255.0 - mean) / std\n",
    "\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee724417-bd3d-489e-a5e1-531b719f880e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f45e93a-9cb4-4da8-a190-c93ca571102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aacd16-5ef3-437e-a426-6288157f15cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ecb2bbb-3d34-4e5d-9874-5e7b841fb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, width, height)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        # Encoder\n",
    "        # Same as before\n",
    "\n",
    "        # Bottleneck\n",
    "        # Same as before\n",
    "         # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1),  # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),         # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),        # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),        # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),       # 1x1\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),   # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #SelfAttention(512)  # Add self-attention\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #SelfAttention(512)  # Add self-attention\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 256, 4, 2, 1),   # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(256)  # Add self-attention\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, 4, 2, 1),   # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(128)  # Add self-attention\n",
    "        )\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1),    # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            #SelfAttention(64)  # Add self-attention\n",
    "        )\n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 1, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        # Same as before\n",
    "\n",
    "        # Bottleneck\n",
    "        # Same as before\n",
    "\n",
    "         # Encoding\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "        enc6 = self.encoder6(enc5)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc6)\n",
    "\n",
    "        # Decoding and adding skip connection\n",
    "        dec1 = self.decoder1(torch.cat([bottleneck, enc6], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([dec1, enc5], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([dec2, enc4], dim=1))\n",
    "        dec4 = self.decoder4(torch.cat([dec3, enc3], dim=1))\n",
    "        dec5 = self.decoder5(torch.cat([dec4, enc2], dim=1))\n",
    "        decoded = self.decoder6(torch.cat([dec5, enc1], dim=1))\n",
    "\n",
    "        return decoded\n",
    "\n",
    "# Example usage:\n",
    "# generator = G()\n",
    "# generator.apply(weights_init)\n",
    "# print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e31beb-41b6-4df2-9af3-83bde4508c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b730a5-0212-4594-b97b-2d8d1a9bff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Discriminator network for 128x128 RGB images '''\n",
    "class D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                                  nn.Conv2d(1, 16, 4, 2, 1),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(16, 32, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(32),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(32, 64, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(64, 128, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(128, 256, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(256, 512, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(512, 1, 4, 2, 1, bias = False),\n",
    "                                  #nn.Sigmoid()\n",
    "                                  )\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe186b9-d30c-462e-82cc-b8885a0882e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627e145b-437d-4440-ba63-f30d9ce817ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Define a function to calculate PSNR\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "# Define a function to calculate SSIM\n",
    "# Define a function to calculate SSIM\n",
    "def calculate_ssim(img1, img2):\n",
    "    # Ensure tensors are on the same device\n",
    "    if img1.device != img2.device:\n",
    "        raise ValueError(\"Input tensors must be on the same device\")\n",
    "\n",
    "    # Calculate SSIM directly on GPU tensors\n",
    "    img1 = img1.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    img2 = img2.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    return ssim(img1.transpose(1, 2, 0), img2.transpose(1, 2, 0), multichannel=True, data_range=1)\n",
    "\n",
    "\n",
    "# Define lists to store PSNR and SSIM values for each epoch\n",
    "psnr_values = []\n",
    "ssim_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db282080-c960-4017-a54f-cbdaf3673c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989e4a0c-8f07-40c6-a216-0b9149e0184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the losses\n",
    "losses_L1 = []\n",
    "losses_L2 = []\n",
    "losses_gan = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103eefe-874b-4afd-9733-32d608d1cb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a332bf1e-8284-4768-a040-e77bb96e696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\\\Grayscale_Dataset\\frontal\n",
      "C:\\Users\\zed\\Dataset\\\\Grayscale_Dataset\\pose\n",
      "200\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"C:\\Users\\zed\\Dataset\\\\Grayscale_Dataset\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "gpu_id = 0\n",
    "device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=32, device_id=gpu_id)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c321de3-3808-4d31-ad2b-507ed8a6b950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd69ccc-3074-44a3-93c1-6715237b4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator:\n",
    "#netG = network.G().to(device)\n",
    "#netG.apply(network.weights_init)\n",
    "netG = G().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Discriminator:\n",
    "#netD = network.D().to(device)\n",
    "#netD.apply(network.weights_init)\n",
    "netD = D().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Here is where you set how important each component of the loss function is:\n",
    "L1_factor = 0\n",
    "L2_factor = 1\n",
    "GAN_factor = 0.005\n",
    "\n",
    "#criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers for the generator and the discriminator (Adam is a fancier version of gradient descent with a few more bells and whistles that is used very often):\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999), eps = 1e-8)\n",
    "\n",
    "# Create a directory for the output files\n",
    "try:\n",
    "    os.mkdir('SA_output')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821913f-cff3-4437-8519-d4eb0c7c2264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7dde38-d0dd-4659-ba31-d56eb37494d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53725b5e-a144-4371-8eff-d3a54657ad33",
   "metadata": {},
   "source": [
    "**Multi-scale pixel wise loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dcd7bf8-b15c-497b-a660-2389ed5a4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def multi_scale_pixelwise_loss(fake_images, real_images, num_scales=3):\n",
    "    loss = 0.0\n",
    "    for scale in range(num_scales):\n",
    "        fake_scaled = F.interpolate(fake_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        real_scaled = F.interpolate(real_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        pixel_loss = F.l1_loss(fake_scaled, real_scaled)\n",
    "        loss += pixel_loss / (2 ** scale)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30041f04-be0e-40a8-b9e3-8470cf9dcb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c85e5497-d6ba-41c5-a998-683a8197a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f4065-7636-4bb5-98dd-3c801e6ffbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c5c3ac-e520-40af-b7b0-a0f35ba20c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the losses\n",
    "losses_L1 = []\n",
    "losses_L2 = []\n",
    "losses_gan = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b8b7a-8d0f-40fa-abc1-a85e14299d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d591643-da26-4fd4-9c56-36dbef2a5a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [10:00<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  620.2399475574493  seconds\n",
      "[1/30] Training absolute losses: L1 0.2194084 ; L2 0.0366404 BCE 2.0717555; Average PSNR: 16.49; Average SSIM: 0.7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:15<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/30] Training absolute losses: L1 0.1000893 ; L2 0.0063845 BCE 1.6380848; Average PSNR: 22.08; Average SSIM: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/30] Training absolute losses: L1 0.0797461 ; L2 0.0041537 BCE 1.9090165; Average PSNR: 23.93; Average SSIM: 0.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:11<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/30] Training absolute losses: L1 0.0681393 ; L2 0.0031310 BCE 1.8732890; Average PSNR: 25.20; Average SSIM: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:09<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/30] Training absolute losses: L1 0.0560324 ; L2 0.0021644 BCE 1.5653444; Average PSNR: 26.70; Average SSIM: 0.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/30] Training absolute losses: L1 0.0622550 ; L2 0.0026234 BCE 2.4918565; Average PSNR: 25.91; Average SSIM: 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/30] Training absolute losses: L1 0.0639576 ; L2 0.0027832 BCE 2.7507297; Average PSNR: 25.69; Average SSIM: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:07<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/30] Training absolute losses: L1 0.0626840 ; L2 0.0026741 BCE 4.3524851; Average PSNR: 25.79; Average SSIM: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:09<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/30] Training absolute losses: L1 0.0691827 ; L2 0.0032963 BCE 5.5822435; Average PSNR: 24.83; Average SSIM: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:09<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] Training absolute losses: L1 0.0837109 ; L2 0.0065088 BCE 2.5419209; Average PSNR: 24.02; Average SSIM: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] Training absolute losses: L1 0.0552474 ; L2 0.0020416 BCE 1.8440224; Average PSNR: 26.94; Average SSIM: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] Training absolute losses: L1 0.0527116 ; L2 0.0018936 BCE 2.7870176; Average PSNR: 27.29; Average SSIM: 0.9739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:07<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] Training absolute losses: L1 0.0493582 ; L2 0.0016700 BCE 2.3256762; Average PSNR: 27.79; Average SSIM: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:09<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] Training absolute losses: L1 0.0540871 ; L2 0.0019781 BCE 3.3360878; Average PSNR: 27.08; Average SSIM: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:06<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] Training absolute losses: L1 0.0586371 ; L2 0.0022946 BCE 5.3749483; Average PSNR: 26.41; Average SSIM: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:07<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] Training absolute losses: L1 0.0596961 ; L2 0.0023946 BCE 3.4254105; Average PSNR: 26.22; Average SSIM: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:10<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] Training absolute losses: L1 0.0548634 ; L2 0.0019536 BCE 1.2617812; Average PSNR: 27.14; Average SSIM: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] Training absolute losses: L1 0.0458105 ; L2 0.0013972 BCE 1.4049680; Average PSNR: 28.56; Average SSIM: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] Training absolute losses: L1 0.0484084 ; L2 0.0015488 BCE 3.4083128; Average PSNR: 28.15; Average SSIM: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [09:11<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] Training absolute losses: L1 0.0462329 ; L2 0.0014232 BCE 2.0742649; Average PSNR: 28.48; Average SSIM: 0.9798\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's train for 30 epochs (meaning, we go through the entire training set 30 times):\n",
    "for epoch in range(20):\n",
    "    \n",
    "    # Lets keep track of the loss values for each epoch:\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0  # Total PSNR for this epoch\n",
    "    total_ssim = 0  # Total SSIM for this epoch\n",
    "    \n",
    "    # Your train_pipe_loader will load the images one batch at a time\n",
    "    # The inner loop iterates over those batches:\n",
    "    #print(\"starting...\")\n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "        \n",
    "        # These are your images from the current batch:\n",
    "        #profile = data[0]['profiles']\n",
    "        #frontal = data[0]['frontals']\n",
    "            profile = data[0].view(32, 1, 128, 128)\n",
    "            frontal = data[1].view(32, 1, 128, 128)\n",
    "        \n",
    "        \n",
    "        # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(real)\n",
    "        # D should accept the GT images\n",
    "            errD_real = criterion(output.squeeze(), target)\n",
    "        \n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            generated = netG(profile)\n",
    "            target = Variable(torch.zeros(real.size()[0])).to(device)\n",
    "            output = netD(generated.detach()) # detach() because we are not training G here\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, real)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, real)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # D should reject the synthetic images\n",
    "            errD_fake = criterion(output, target)\n",
    "        \n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "        # Update D\n",
    "            optimizerD.step()\n",
    "        \n",
    "        # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(generated)\n",
    "        \n",
    "        # G wants to :\n",
    "        # (a) have the synthetic images be accepted by D (= look like frontal images of people)\n",
    "            errG_GAN = criterion(output, target)\n",
    "        \n",
    "        # (b) have the synthetic images resemble the ground truth frontal image\n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            #errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "        \n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "        \n",
    "            errG.backward()\n",
    "        # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'SA_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'SA_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'SA_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'SA_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7237e-3975-4f07-bb9b-f658486c66e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
