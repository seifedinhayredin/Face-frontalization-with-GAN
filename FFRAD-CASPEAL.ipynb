{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c028a8c-5deb-4664-a3ba-8560a3f31ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Additional information about the CUDA device\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf0142-7c0d-4a68-b3ac-f88a1e7e9899",
   "metadata": {},
   "source": [
    "**For merging frontal and pose images with the same folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb3349f-9535-49aa-8e8c-c2880076dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Set pose directory\n",
    "        self.pose_dir = os.path.join(imageset_dir, \"pose\")\n",
    "        print(self.pose_dir)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = [os.path.join(self.pose_dir, file) for file in sorted(os.listdir(self.pose_dir)) if is_jpeg(file)]\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            with Image.open(profile_filename) as profile_img:\n",
    "                profiles.append(np.array(profile_img))\n",
    "            with Image.open(frontal_filename) as frontal_img:\n",
    "                frontals.append(np.array(frontal_img))\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[0]\n",
    "        for frontal_file in self.profile_files:\n",
    "            if profile_name in frontal_file and \"051\" in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64, device_id=0):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9ce9a9-7af9-4659-ba01-0a0c0dc6dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6d076f-1943-49b9-9033-1eee001812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m_batchsize, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, width, height)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946f6b02-7412-4761-b5e6-fc828b0bff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        max_pool = self.max_pool(x)\n",
    "        avg_out = self.fc(avg_pool)\n",
    "        max_out = self.fc(max_pool)\n",
    "        out = avg_out + max_out\n",
    "        return out * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a79352-07fb-459d-a8a3-2fe6139146d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1),  # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(64)  # Add channel attention\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),         # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(128)  # Add channel attention\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),        # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(256)  # Add channel attention\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),        # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),        # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            ChannelAttention(512)  # Add channel attention\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),       # 1x1\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),   # 4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 256, 4, 2, 1),   # 16x16\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(256)  # Add self-attention\n",
    "        )\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, 4, 2, 1),   # 32x32\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            SelfAttention(128)  # Add self-attention\n",
    "        )\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1),    # 64x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 1, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "        enc6 = self.encoder6(enc5)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc6)\n",
    "\n",
    "        # Decoding and adding skip connection\n",
    "        dec1 = self.decoder1(torch.cat([bottleneck, enc6], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([dec1, enc5], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([dec2, enc4], dim=1))\n",
    "        dec4 = self.decoder4(torch.cat([dec3, enc3], dim=1))\n",
    "        dec5 = self.decoder5(torch.cat([dec4, enc2], dim=1))\n",
    "        decoded = self.decoder6(torch.cat([dec5, enc1], dim=1))\n",
    "\n",
    "        return decoded\n",
    "\n",
    "# Example usage:\n",
    "# generator = G()\n",
    "# generator.apply(weights_init)\n",
    "# print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419dc538-007b-4158-8937-8aec153ca19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RelativeAvgDiscriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(RelativeAvgDiscriminator, self).__init__()\n",
    "\n",
    "    # Separate feature extraction for real and generated data\n",
    "    self.conv_real = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 4, 2, 1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(16, 32, 4, 2, 1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(32, 64, 4, 2, 1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "    self.conv_generated = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 4, 2, 1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(16, 32, 4, 2, 1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(32, 64, 4, 2, 1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "\n",
    "    # Relative Average Pooling\n",
    "    self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # Remaining convolutional layers (modified for combined features)\n",
    "    self.post_pool = nn.Sequential(\n",
    "        nn.Conv2d(128, 128, 4, 2, 1),  # Input channels changed to 128\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(128, 256, 4, 2, 1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "       \n",
    "    )\n",
    "\n",
    "    # Output layer with sigmoid activation\n",
    "    self.output = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, real, fake):\n",
    "    # Extract features from real and generated data\n",
    "    real_features = self.conv_real(real)\n",
    "    generated_features = self.conv_generated(fake)\n",
    "\n",
    "    # Concatenate features before pooling\n",
    "    combined_features = torch.cat([real_features, generated_features], dim=1)\n",
    "\n",
    "    # Relative Average Pooling\n",
    "    features = self.avgpool(combined_features)\n",
    "\n",
    "    # Process features with remaining layers\n",
    "    output = self.post_pool(features)\n",
    "\n",
    "    # Probability score\n",
    "    #probability = self.output(logits)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd799826-fbe1-481e-b76f-98fc413e9649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\All_image_in_one\\pose\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"D:\\All_image_in_one\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "gpu_id = 0\n",
    "device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "#checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=64, random_shuffle=True, batch_size=4, device_id=gpu_id)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,batch_size=32)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18b2e45-dd17-4268-848f-62c823bc5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Define a function to calculate PSNR\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "# Define a function to calculate SSIM\n",
    "# Define a function to calculate SSIM\n",
    "def calculate_ssim(img1, img2):\n",
    "    # Ensure tensors are on the same device\n",
    "    if img1.device != img2.device:\n",
    "        raise ValueError(\"Input tensors must be on the same device\")\n",
    "\n",
    "    # Calculate SSIM directly on GPU tensors\n",
    "    img1 = img1.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    img2 = img2.detach().squeeze().clamp(0, 1).cpu().numpy()  # Ensure pixel values are in [0, 1] range\n",
    "    return ssim(img1.transpose(1, 2, 0), img2.transpose(1, 2, 0), multichannel=True, data_range=1)\n",
    "\n",
    "\n",
    "# Define lists to store PSNR and SSIM values for each epoch\n",
    "psnr_values = []\n",
    "ssim_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5feeca-453f-40c5-bcc0-fecb59470d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "#gpu_id = 0\n",
    "#device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "netG = G().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = RelativeAvgDiscriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "L1_factor = 1\n",
    "L2_factor = 1\n",
    "GAN_factor = 0.005\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999), eps=1e-8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426e49f0-257e-431e-a368-f3ade74cc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the losses\n",
    "losses_L1 = []\n",
    "losses_L2 = []\n",
    "losses_gan = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87de561-eb5c-4b08-a038-035ecc114b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def multi_scale_pixelwise_loss(fake_images, real_images, num_scales=3):\n",
    "    loss = 0.0\n",
    "    for scale in range(num_scales):\n",
    "        fake_scaled = F.interpolate(fake_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        real_scaled = F.interpolate(real_images, scale_factor=1 / (2 ** scale), mode='bilinear', align_corners=False)\n",
    "        pixel_loss = F.l1_loss(fake_scaled, real_scaled)\n",
    "        loss += pixel_loss / (2 ** scale)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c13f799-d937-4338-a717-45bd80a87cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store losses\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "multi_scale_losses = []\n",
    "\n",
    "avg_generator_losses = []\n",
    "avg_discriminator_losses = []\n",
    "avg_multi_scale_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e96e6c-b47f-4519-b677-a4593a6d7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bd5fc16-01ee-4687-9b65-b03de582087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "def get_subdirs(directory):\n",
    "    subdirs = sorted([os.path.join(directory, name) for name in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, name))])\n",
    "    return subdirs\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get subdirectories (assuming \"pose\" and \"frontal\" folders exist)\n",
    "        #self.pose_dirs = get_subdirs(os.path.join(imageset_dir, \"pose\"))\n",
    "        self.pose_dirs = os.path.join(imageset_dir, \"pose\")\n",
    "        self.frontal_dir = os.path.join(imageset_dir, \"frontal\")\n",
    "        print(self.frontal_dir)\n",
    "        print(self.pose_dirs)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = []\n",
    "        #for pose_dir in self.pose_dirs:\n",
    "        profile_files = [os.path.join(self.pose_dirs, file) for file in sorted(os.listdir(self.pose_dirs)) if is_jpeg(file)]\n",
    "        self.profile_files.extend(profile_files)\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Collect frontal image paths\n",
    "        self.frontal_files = [os.path.join(self.frontal_dir, file) for file in sorted(os.listdir(self.frontal_dir)) if is_jpeg(file)]\n",
    "        print(len(self.frontal_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "            np.random.shuffle(self.frontal_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            with Image.open(profile_filename) as profile_img:\n",
    "                profiles.append(np.array(profile_img))\n",
    "            with Image.open(frontal_filename) as frontal_img:\n",
    "                frontals.append(np.array(frontal_img))\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[1]\n",
    "        for frontal_file in self.frontal_files:\n",
    "            if profile_name in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64,device=device):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Calculate mean and standard deviation for each channel separately\n",
    "        #mean = np.array([0.5, 0.5, 0.5])  # Assuming RGB images have pixel values in [0, 255] range\n",
    "        #std = np.array([0.5, 0.5, 0.5])   # Assuming RGB images have pixel values in [0, 255] range\n",
    "        \n",
    "        # Normalize each channel independently\n",
    "        #normalized_images = (resized_images / 255.0 - mean) / std\n",
    "        #normalized_targets = (resized_targets / 255.0 - mean) / std\n",
    "\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c570a-639f-4899-ac6e-0cd07b848f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125c4df3-f0fd-4740-9673-a938790ecd4e",
   "metadata": {},
   "source": [
    "**Solving error if the file is not found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c738b87-a37b-4d6a-a995-2e95e40df849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51c8092-8667-4be5-8c5f-a4df419a5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='missing_files.log', level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "def get_subdirs(directory):\n",
    "    subdirs = sorted([os.path.join(directory, name) for name in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, name))])\n",
    "    return subdirs\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get subdirectories (assuming \"pose\" and \"frontal\" folders exist)\n",
    "        self.pose_dirs = os.path.join(imageset_dir, \"pose\")\n",
    "        self.frontal_dir = os.path.join(imageset_dir, \"frontal\")\n",
    "        print(self.frontal_dir)\n",
    "        print(self.pose_dirs)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = [os.path.join(self.pose_dirs, file) for file in sorted(os.listdir(self.pose_dirs)) if is_jpeg(file)]\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Collect frontal image paths\n",
    "        self.frontal_files = [os.path.join(self.frontal_dir, file) for file in sorted(os.listdir(self.frontal_dir)) if is_jpeg(file)]\n",
    "        print(len(self.frontal_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "            np.random.shuffle(self.frontal_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            try:\n",
    "                with Image.open(profile_filename) as profile_img:\n",
    "                    profiles.append(np.array(profile_img))\n",
    "            except FileNotFoundError:\n",
    "                logging.error(f'Profile image not found: {profile_filename}')\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                logging.error(f'Error opening profile image {profile_filename}: {e}')\n",
    "                raise\n",
    "\n",
    "            if frontal_filename is None:\n",
    "                logging.error(f'Matching frontal image not found for: {profile_filename}')\n",
    "                raise FileNotFoundError(f'Matching frontal image not found for: {profile_filename}')\n",
    "            try:\n",
    "                with Image.open(frontal_filename) as frontal_img:\n",
    "                    frontals.append(np.array(frontal_img))\n",
    "            except FileNotFoundError:\n",
    "                logging.error(f'Frontal image not found: {frontal_filename}')\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                logging.error(f'Error opening frontal image {frontal_filename}: {e}')\n",
    "                raise\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[1]\n",
    "        for frontal_file in self.frontal_files:\n",
    "            if profile_name in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64, device=device):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc0a9e-76dc-40a4-a811-c7a500d3a8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b1ea34e-d4ed-4381-bc97-12a72978001a",
   "metadata": {},
   "source": [
    "**For training on CAS-PEAL-R1 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb58065-040c-4e2f-a71c-82648bcbe73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3adda57-fa25-4de9-bd6c-2b5d3ea88af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\CAS_5000\\frontal\n",
      "C:\\Users\\zed\\Dataset\\CAS_5000\\pose\n",
      "5055\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"C:\\Users\\zed\\Dataset\\CAS_5000\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "#gpu_id = 0\n",
    "#device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "#checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=1, device=device)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,batch_size=128,drop_last=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525aaa5-cb3c-4aac-a704-e779443a42f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25faf311-0746-46d6-ae15-5fa357249545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46835aec-84c7-470a-8e87-9205b58f2dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:04<00:00, 10.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  772.8737080097198  seconds\n",
      "[1/30] Training absolute losses: L1 0.0126016 ; L2 0.0037668 BCE 0.0162341; Average PSNR: 8.90; Average SSIM: 0.3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/30] Training absolute losses: L1 0.0084249 ; L2 0.0018818 BCE 0.0168373; Average PSNR: 11.69; Average SSIM: 0.5204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/30] Training absolute losses: L1 0.0074788 ; L2 0.0015516 BCE 0.0171350; Average PSNR: 12.51; Average SSIM: 0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/30] Training absolute losses: L1 0.0070122 ; L2 0.0013533 BCE 0.0167902; Average PSNR: 13.10; Average SSIM: 0.6135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/30] Training absolute losses: L1 0.0064149 ; L2 0.0011841 BCE 0.0169770; Average PSNR: 13.66; Average SSIM: 0.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/30] Training absolute losses: L1 0.0057405 ; L2 0.0009902 BCE 0.0168366; Average PSNR: 14.42; Average SSIM: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/30] Training absolute losses: L1 0.0052923 ; L2 0.0008535 BCE 0.0176959; Average PSNR: 15.06; Average SSIM: 0.7135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:03<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/30] Training absolute losses: L1 0.0050238 ; L2 0.0007756 BCE 0.0172082; Average PSNR: 15.48; Average SSIM: 0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:04<00:00, 10.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/30] Training absolute losses: L1 0.0050184 ; L2 0.0007992 BCE 0.0177462; Average PSNR: 15.34; Average SSIM: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [01:04<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] Training absolute losses: L1 0.0045527 ; L2 0.0006608 BCE 0.0173684; Average PSNR: 16.16; Average SSIM: 0.7548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(10):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        \n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            #errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "         \n",
    "            #pbar.set_postfix(batch_size=batch_size)  # Display batch size in the progress bar\n",
    "    \n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "    vutils.save_image(profile[1:4].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(frontal[1:4].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:4].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "              \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dc7ed-f0af-41d3-a920-ccd2f02e27f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f9b289a-09eb-4d8e-90c2-04db43693570",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('FFRAD_CAS_output')\n",
    "except OSError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00be66ea-4bea-4e31-91d9-1db4ceb26262",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir1 = \"FFRAD_CAS_Checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535d601-6044-4aa2-a859-f827cd8607ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:54:20<00:00, 268.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  70951.05814671516  seconds\n",
      "[1/30] Training absolute losses: L1 0.0021888 ; L2 0.0004611 BCE 0.0049742; Average PSNR: 12.25; Average SSIM: 0.5639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|███████▌                                                                  | 4/39 [01:50<19:31, 33.46s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile[1:4].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real[1:4].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:4].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161519b-3294-4e8c-92f7-b271d87a10a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e580a8-7759-4a9c-8f5e-aef3f877da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = 0\n",
    "checkpoint_path = os.path.join(checkpoint_dir1, f\"checkpoint_{latest_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "\n",
    "# Load training progress\n",
    "loss_L1 = checkpoint['loss_L1']\n",
    "loss_L2 = checkpoint['loss_L2']\n",
    "loss_gan = checkpoint['loss_gan']\n",
    "psnr_values = checkpoint['psnr_values']\n",
    "ssim_values = checkpoint['ssim_values']\n",
    "losses_L1 = checkpoint['losses_L1']\n",
    "losses_L2 = checkpoint['losses_L2']\n",
    "losses_gan = checkpoint['losses_gan']\n",
    "discriminator_losses = checkpoint['discriminator_losses']\n",
    "generator_losses = checkpoint['generator_losses']\n",
    "multi_scale_losses = checkpoint['multi_scale_losses']\n",
    "avg_generator_losses = checkpoint['avg_generator_losses']\n",
    "avg_discriminator_losses = checkpoint['avg_discriminator_losses']\n",
    "avg_multi_scale_losses = checkpoint['avg_multi_scale_losses']\n",
    "\n",
    "# Start training from the loaded epoch\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa157e63-a1e4-4a49-9b4a-57a2ffa2094b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a28af-a3dc-44f3-9d89-01aa8ecba6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:51:26<00:00, 263.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/30] Training absolute losses: L1 0.0020503 ; L2 0.0004163 BCE 0.0050338; Average PSNR: 12.69; Average SSIM: 0.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:50:00<00:00, 261.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/30] Training absolute losses: L1 0.0019713 ; L2 0.0003882 BCE 0.0050295; Average PSNR: 12.99; Average SSIM: 0.6159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:50:51<00:00, 262.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/30] Training absolute losses: L1 0.0018753 ; L2 0.0003584 BCE 0.0051132; Average PSNR: 13.34; Average SSIM: 0.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:50:32<00:00, 262.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/30] Training absolute losses: L1 0.0017845 ; L2 0.0003288 BCE 0.0051529; Average PSNR: 13.72; Average SSIM: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  59%|█████████████████████████████████████████▎                            | 23/39 [59:07<1:11:58, 269.90s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile[1:6].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real[1:6].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:6].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79276ec3-9679-4a4d-9673-45d05ebdcf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ad78f5-039e-420c-ac58-fef03f77dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = 5\n",
    "checkpoint_path = os.path.join(checkpoint_dir1, f\"checkpoint_{latest_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "\n",
    "# Load training progress\n",
    "loss_L1 = checkpoint['loss_L1']\n",
    "loss_L2 = checkpoint['loss_L2']\n",
    "loss_gan = checkpoint['loss_gan']\n",
    "psnr_values = checkpoint['psnr_values']\n",
    "ssim_values = checkpoint['ssim_values']\n",
    "losses_L1 = checkpoint['losses_L1']\n",
    "losses_L2 = checkpoint['losses_L2']\n",
    "losses_gan = checkpoint['losses_gan']\n",
    "discriminator_losses = checkpoint['discriminator_losses']\n",
    "generator_losses = checkpoint['generator_losses']\n",
    "multi_scale_losses = checkpoint['multi_scale_losses']\n",
    "avg_generator_losses = checkpoint['avg_generator_losses']\n",
    "avg_discriminator_losses = checkpoint['avg_discriminator_losses']\n",
    "avg_multi_scale_losses = checkpoint['avg_multi_scale_losses']\n",
    "\n",
    "# Start training from the loaded epoch\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36d35c-9cf2-4589-bbda-1a89742b582c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ba986-1869-4b46-a4b1-bcd6fac1bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:58:36<00:00, 274.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/30] Training absolute losses: L1 0.0016526 ; L2 0.0002882 BCE 0.0051534; Average PSNR: 14.29; Average SSIM: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  26%|██████████████████▍                                                     | 10/39 [11:15<48:31, 100.39s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile[1:6].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real[1:6].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:6].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9b307-ee3c-4916-a6f5-e77f022296fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a5cd0-1f53-4465-a75e-ec238ebc7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:57:52<00:00, 273.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/30] Training absolute losses: L1 0.0014686 ; L2 0.0002341 BCE 0.0051699; Average PSNR: 15.18; Average SSIM: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:51:26<00:00, 263.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/30] Training absolute losses: L1 0.0016593 ; L2 0.0002905 BCE 0.0052004; Average PSNR: 14.26; Average SSIM: 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:51:47<00:00, 264.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/30] Training absolute losses: L1 0.0015888 ; L2 0.0002678 BCE 0.0052232; Average PSNR: 14.61; Average SSIM: 0.7135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [2:51:34<00:00, 263.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] Training absolute losses: L1 0.0015370 ; L2 0.0002562 BCE 0.0052496; Average PSNR: 14.80; Average SSIM: 0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:28<00:00, 263.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] Training absolute losses: L1 0.0014877 ; L2 0.0002420 BCE 0.0052843; Average PSNR: 15.05; Average SSIM: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:42<00:00, 264.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] Training absolute losses: L1 0.0014018 ; L2 0.0002172 BCE 0.0052639; Average PSNR: 15.51; Average SSIM: 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:53:01<00:00, 266.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] Training absolute losses: L1 0.0014066 ; L2 0.0002175 BCE 0.0052646; Average PSNR: 15.51; Average SSIM: 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:58<00:00, 266.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] Training absolute losses: L1 0.0013666 ; L2 0.0002078 BCE 0.0053313; Average PSNR: 15.71; Average SSIM: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:55:55<00:00, 270.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] Training absolute losses: L1 0.0013297 ; L2 0.0001968 BCE 0.0053395; Average PSNR: 15.94; Average SSIM: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:21<00:00, 265.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] Training absolute losses: L1 0.0013024 ; L2 0.0001899 BCE 0.0053612; Average PSNR: 16.10; Average SSIM: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:19:55<00:00, 307.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] Training absolute losses: L1 0.0012437 ; L2 0.0001759 BCE 0.0053509; Average PSNR: 16.43; Average SSIM: 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:12:15<00:00, 295.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] Training absolute losses: L1 0.0012300 ; L2 0.0001718 BCE 0.0053690; Average PSNR: 16.53; Average SSIM: 0.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:55:32<00:00, 270.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] Training absolute losses: L1 0.0012080 ; L2 0.0001662 BCE 0.0053445; Average PSNR: 16.67; Average SSIM: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:38<00:00, 264.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] Training absolute losses: L1 0.0011664 ; L2 0.0001566 BCE 0.0053705; Average PSNR: 16.93; Average SSIM: 0.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:38<00:00, 264.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] Training absolute losses: L1 0.0011484 ; L2 0.0001521 BCE 0.0054117; Average PSNR: 17.06; Average SSIM: 0.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:  69%|██████████████████████████████████████████████▍                    | 27/39 [1:22:17<1:05:21, 326.81s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile[1:6].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real[1:6].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:6].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80958e0-788a-4a16-b201-e592a84ca24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760c44c0-a67d-4eaf-8010-1c806364ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = 29\n",
    "checkpoint_path = os.path.join(checkpoint_dir1, f\"checkpoint_{latest_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "\n",
    "# Load training progress\n",
    "loss_L1 = checkpoint['loss_L1']\n",
    "loss_L2 = checkpoint['loss_L2']\n",
    "loss_gan = checkpoint['loss_gan']\n",
    "psnr_values = checkpoint['psnr_values']\n",
    "ssim_values = checkpoint['ssim_values']\n",
    "losses_L1 = checkpoint['losses_L1']\n",
    "losses_L2 = checkpoint['losses_L2']\n",
    "losses_gan = checkpoint['losses_gan']\n",
    "discriminator_losses = checkpoint['discriminator_losses']\n",
    "generator_losses = checkpoint['generator_losses']\n",
    "multi_scale_losses = checkpoint['multi_scale_losses']\n",
    "avg_generator_losses = checkpoint['avg_generator_losses']\n",
    "avg_discriminator_losses = checkpoint['avg_discriminator_losses']\n",
    "avg_multi_scale_losses = checkpoint['avg_multi_scale_losses']\n",
    "\n",
    "# Start training from the loaded epoch\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46586fea-b03a-4a48-8e31-c1d35bbd61ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:46<00:00, 265.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] Training absolute losses: L1 0.0010607 ; L2 0.0001330 BCE 0.0054153; Average PSNR: 17.64; Average SSIM: 0.8379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:50:42<00:00, 262.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] Training absolute losses: L1 0.0010653 ; L2 0.0001343 BCE 0.0053960; Average PSNR: 17.60; Average SSIM: 0.8368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23:  67%|████████████████████████████████████████████▋                      | 26/39 [1:14:44<1:06:31, 307.07s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile[1:6].data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real[1:6].data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated[1:6].data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd0ccf-458a-4f5e-ae88-31e22f018022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3427d39f-c853-4063-b1f6-ee6a0bd89361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:34<00:00, 265.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] Training absolute losses: L1 0.0009600 ; L2 0.0001122 BCE 0.0054506; Average PSNR: 18.38; Average SSIM: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:50:54<00:00, 262.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] Training absolute losses: L1 0.0009559 ; L2 0.0001119 BCE 0.0054192; Average PSNR: 18.39; Average SSIM: 0.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:38<00:00, 264.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] Training absolute losses: L1 0.0010240 ; L2 0.0001237 BCE 0.0053920; Average PSNR: 17.96; Average SSIM: 0.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:55<00:00, 264.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] Training absolute losses: L1 0.0009964 ; L2 0.0001210 BCE 0.0054171; Average PSNR: 18.05; Average SSIM: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:59<00:00, 264.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] Training absolute losses: L1 0.0009775 ; L2 0.0001156 BCE 0.0054288; Average PSNR: 18.25; Average SSIM: 0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:14<00:00, 264.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] Training absolute losses: L1 0.0009367 ; L2 0.0001072 BCE 0.0054065; Average PSNR: 18.58; Average SSIM: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:35<00:00, 265.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] Training absolute losses: L1 0.0009454 ; L2 0.0001085 BCE 0.0054033; Average PSNR: 18.52; Average SSIM: 0.8649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,30):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(32, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941df63-c61c-4bda-8205-e61e339a58b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ff702a-76d0-4e60-a9e7-b6693b420f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(generator_losses)\n",
    "#plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "#plt.plot(multi_scale_losses, label='Multi-Scale Pixel-wise Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator  Loss ')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71e9e976-18ab-400b-9da9-e9ce7ffdffd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHWCAYAAACbsXOkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAADQpUlEQVR4nOydd5gUZdbFT3dPHmaGOAwZBAVRgqAggiuuKLqsa1jjZ3Z1DaCruO7qumIWXXPGAIqurjmDSDIDIkGUDJLDAANMYIaZ6VDfHz3V/VZ1xe7qOOf3PDz0VFdXvd1V3fWeuvee65IkSQIhhBBCCCGEkJhwJ3sAhBBCCCGEEJIJUFwRQgghhBBCiANQXBFCCCGEEEKIA1BcEUIIIYQQQogDUFwRQgghhBBCiANQXBFCCCGEEEKIA1BcEUIIIYQQQogDUFwRQgghhBBCiANQXBFCCCGEEEKIA1BcEUIIIYQQQogDUFwRQgjRZOPGjRg3bhwOO+wwFBQUoKCgAH379sXYsWPxyy+/JHt4jjJ9+nTcfffdyR4G7r77brhcLlRUVCR7KIQQQqIgK9kDIIQQknp8/vnnOP/885GVlYWLLroIAwYMgNvtxurVq/Hhhx/ihRdewMaNG9GtW7dkD9URpk+fjueeey4lBBYhhJD0heKKEEKIgt9++w0XXHABunXrhjlz5qBDhw6K5x9++GE8//zzcLtTN/mhtrYWhYWFSR1DIBBAY2Mj8vLykjoOQgghiSN1r4yEEEKSwn/+8x/U1tbi1VdfjRBWAJCVlYUbb7wRXbp0USxfvXo1zjnnHLRu3Rp5eXk4+uij8emnnyrWee211+ByufDDDz9g/PjxaNeuHQoLC3HWWWdhz549Efv64osvcPzxx6OwsBBFRUUYM2YMVqxYoVjn8ssvR4sWLfDbb7/hD3/4A4qKinDRRRcBAL777juce+656Nq1K3Jzc9GlSxfcfPPNOHjwoOL1zz33HADA5XKF/snU1tbilltuQZcuXZCbm4vevXvj0UcfhSRJinG4XC6MGzcOb775Jo444gjk5uZixowZVj5y28ydOzf0ubRs2RJnnHEGVq1apVinpqYGN910E7p3747c3FyUlpbi5JNPxpIlS0LrrFu3Dn/+859RVlaGvLw8dO7cGRdccAGqqqriMm5CCMl0GLkihBCi4PPPP0evXr0wdOhQy69ZsWIFhg8fjk6dOuG2225DYWEh3n33XZx55pn44IMPcNZZZynWv+GGG9CqVSvcdddd2LRpE5588kmMGzcO77zzTmidN954A5dddhlGjx6Nhx9+GHV1dXjhhRcwYsQILF26FN27dw+t6/P5MHr0aIwYMQKPPvooCgoKAADvvfce6urqcN1116FNmzZYuHAhnnnmGWzbtg3vvfceAOCaa67Bjh07MGvWLLzxxhuKcUqShD/96U/46quv8Je//AUDBw7El19+iVtvvRXbt2/HE088oVh/7ty5ePfddzFu3Di0bdtWMUanmD17Nk477TQccsghuPvuu3Hw4EE888wzGD58OJYsWRLa57XXXov3338f48aNQ9++fbF37158//33WLVqFQYNGoTGxkaMHj0aDQ0NuOGGG1BWVobt27fj888/R2VlJUpKShwfOyGEZDwSIYQQ0kRVVZUEQDrzzDMjntu/f7+0Z8+e0L+6urrQcyeddJLUr18/qb6+PrQsEAhIxx13nHTooYeGlr366qsSAGnUqFFSIBAILb/55pslj8cjVVZWSpIkSTU1NVLLli2lq6++WjGG8vJyqaSkRLH8sssukwBIt912W8SYxTHKTJw4UXK5XNLmzZtDy8aOHStpXRI//vhjCYB0//33K5afc845ksvlktavXx9aBkByu93SihUrIrZjlbvuuksCIO3Zs0d3nYEDB0qlpaXS3r17Q8uWLVsmud1u6dJLLw0tKykpkcaOHau7naVLl0oApPfeey/q8RJCCFHCtEBCCCEhqqurAQAtWrSIeG7kyJFo165d6J+cSrdv3z7MnTsX5513HmpqalBRUYGKigrs3bsXo0ePxrp167B9+3bFtv76178qUu+OP/54+P1+bN68GQAwa9YsVFZW4sILLwxtr6KiAh6PB0OHDsVXX30VMb7rrrsuYll+fn7ocW1tLSoqKnDcccdBkiQsXbrU9POYPn06PB4PbrzxRsXyW265BZIk4YsvvlAsP+GEE9C3b1/T7UbLzp078fPPP+Pyyy9H69atQ8v79++Pk08+GdOnTw8ta9myJX788Ufs2LFDc1tyZOrLL79EXV1d3MZMCCHNCYorQgghIYqKigAABw4ciHjuxRdfxKxZs/Df//5XsXz9+vWQJAl33nmnQny1a9cOd911FwBg9+7ditd07dpV8XerVq0AAPv37wcQrAUCgN///vcR25w5c2bE9rKystC5c+eIMW/ZsiUkRFq0aIF27drhhBNOAABLdUWbN29Gx44dQ5+LzOGHHx56XqRHjx6m24wFeX+9e/eOeO7www9HRUUFamtrAQRr55YvX44uXbpgyJAhuPvuu7FhwwbFWMePH49XXnkFbdu2xejRo/Hcc8+x3ooQQmKANVeEEEJClJSUoEOHDli+fHnEc3IN1qZNmxTLA4EAAODvf/87Ro8erbndXr16Kf72eDya60lNJhHyNt944w2UlZVFrJeVpbx85ebmRrgX+v1+nHzyydi3bx/++c9/ok+fPigsLMT27dtx+eWXh/bhJGKkLNmcd955OP744/HRRx9h5syZeOSRR/Dwww/jww8/xGmnnQYAeOyxx3D55Zfjk08+wcyZM3HjjTdi4sSJWLBggaZYJYQQYgzFFSGEEAVjxozBK6+8goULF2LIkCGm6x9yyCEAgOzsbIwaNcqRMfTs2RMAUFpaGvU2f/31V6xduxZTp07FpZdeGlo+a9asiHXFFEWRbt26Yfbs2aipqVFEr1avXh16PpHI+1uzZk3Ec6tXr0bbtm0VFvQdOnTA9ddfj+uvvx67d+/GoEGD8MADD4TEFQD069cP/fr1w7///W/MmzcPw4cPx6RJk3D//ffH/w0RQkiGwbRAQgghCv7xj3+goKAAV155JXbt2hXxvKSyIC8tLcXIkSPx4osvYufOnRHra1msmzF69GgUFxfjwQcfhNfrjWqbcnRMHK8kSXjqqaci1pUFSWVlpWL5H/7wB/j9fjz77LOK5U888QRcLpdCpCSCDh06YODAgZg6dapirMuXL8fMmTPxhz/8AUAwaqdO7ystLUXHjh3R0NAAIFhf5/P5FOv069cPbrc7tA4hhBB7MHJFCCFEwaGHHoq33noLF154IXr37o2LLroIAwYMgCRJ2LhxI9566y243W5F2thzzz2HESNGoF+/frj66qtxyCGHYNeuXZg/fz62bduGZcuW2RpDcXExXnjhBVxyySUYNGgQLrjgArRr1w5btmzBtGnTMHz48AjBo6ZPnz7o2bMn/v73v2P79u0oLi7GBx98EKrrEhk8eDAA4MYbb8To0aPh8XhwwQUX4PTTT8eJJ56IO+64A5s2bcKAAQMwc+ZMfPLJJ7jppptCETanefzxx0N28jJutxv/+te/8Mgjj+C0007DsGHD8Je//CVkxV5SUoK7774bQLDHVefOnXHOOedgwIABaNGiBWbPno2ffvoJjz32GICgbfy4ceNw7rnn4rDDDoPP58Mbb7wBj8eDP//5z3F5X4QQkvEkz6iQEEJIKrN+/Xrpuuuuk3r16iXl5eVJ+fn5Up8+faRrr71W+vnnnyPW/+2336RLL71UKisrk7Kzs6VOnTpJf/zjH6X3338/tI5sxf7TTz8pXvvVV19JAKSvvvoqYvno0aOlkpISKS8vT+rZs6d0+eWXS4sWLQqtc9lll0mFhYWa72HlypXSqFGjpBYtWkht27aVrr76amnZsmUSAOnVV18Nrefz+aQbbrhBateuneRyuRS27DU1NdLNN98sdezYUcrOzpYOPfRQ6ZFHHlFYyUtS0IrdyPrcCrIVu9Y/j8cTWm/27NnS8OHDpfz8fKm4uFg6/fTTpZUrV4aeb2hokG699VZpwIABUlFRkVRYWCgNGDBAev7550PrbNiwQbryyiulnj17Snl5eVLr1q2lE088UZo9e3ZM74EQQpozLklS5XcQQgghhBBCCLENa64IIYQQQgghxAEorgghhBBCCCHEASiuCCGEEEIIIcQBKK4IIYQQQgghxAEorgghhBBCCCHEASiuCCGEEEIIIcQB2ERYg0AggB07dqCoqAgulyvZwyGEEEIIIYQkCUmSUFNTg44dO8LtNo5NUVxpsGPHDnTp0iXZwyCEEEIIIYSkCFu3bkXnzp0N16G40qCoqAhA8AMsLi5O8mgIIYQQQgghyaK6uhpdunQJaQQjKK40kFMBi4uLKa4IIYQQQgghlsqFaGhBCCGEEEIIIQ5AcUUIIYQQQgghDkBxRQghhBBCCCEOQHFFCCGEEEIIIQ5AcUUIIYQQQgghDkBxRQghhBBCCCEOQHFFCCGEEEIIIQ5AcUUIIYQQQgghDkBxRQghhBBCCCEOQHFFCCGEEEIIIQ5AcUUIIYQQQgghDkBxRQghhBBCCCEOQHFFCCGEEEIIIQ5AcZXiPDBtJUY/8S0+W7Yj2UMhhBBCCCGEGEBxleLsrKrHml01qDjQkOyhZBw/rK/Aaz9shCRJyR4KIYQQQgjJALKSPQBiTF62BwBQ7w0keSSZx0Wv/AgAaFWYgzMGdkryaAghhBBCSLrDyFWKk5sVPEQNPn+SR5K5fLR0e7KHQAghhBBCMgCKqxQnNysYuWrwMXIVL35YX5HsIRBCCCGEkAyA4irFycsOHqJ6LyNX8cLrl1BV5032MAghhBBCSJpDcZXiMHIVP9oX54Yez/uN0StCCCGEEBIbFFcpDiNX8UM0CZz3297kDYQQQgghhGQEFFcpTtjQgpErpxEN2NfsqknaOAghhBBCSGZAcZXiyFbsDYxcxZXfdh9I9hAIIYQQQkiaQ3GV4uRmM3IVL8S0wL21jaisa0zeYAghhBBCSNpDcZXi5GXJTYQZuXIeSfHXtv0HkzQOQgghhBCSCVBcpTiMXMUf2TRkRyXFFSGEEEIIiR6KqxQnZMXuVYorSZK0Vic2kD/CTi3zAQDbKa4IIYQQQkgMUFylOCErdl84LfC6/y7Gn579AV4/o1mxIMvTTq0KADByRQghhBBCYoPiKsXRilx9sbwcv26vwtItlUkaVWYhR652VNYneSSEEEIIISSdobhKcbQiVzK1jb5EDyejkFMrO7cKiqttjFwRQgghhJAYoLhKcdSRq0AgXGtV10AHwVgIpQWGIlcUV4QQQgghJHoorlKcXCFyJUkS/IKRRR0jV47QqSlytaemAQ0aEUJCCCGEEEKsQHGV4siRK0kCvH4JfiFydZC9r2JC1qmtCnJC6Zc7WXdFCCGEEEKihOIqxcnNCh+iep8fASFyVcu0wJiQa65cLqYGEkIIIYSQ2KG4SnFEcdXgDSgjV0wLdAQXgI7sdUUIIYQQQmKE4irFcblcIYHV4PMjILS2qmtk5CoWxDbMtGMnhBBCCCGxkpXsARBz8rI9aPAF8PCMNVi8aV9oeR1rrmKjSV25XK6QuNpeWZfEARFCCCGEkHSG4ioNkCNXny3boVju9QW0Vic2EdMCGbkihBBCCCHRwrTANCAv26O5vIHiKibEtMCONLQghBBCCCExQnGVBoimFiL1TAuMCS23wO2VB0PLCSGEEEIIsQPFVRrAyFV8ccGF0uJcAMHPtLqeLoyEEEIIIcQ+FFdpACNX8UGMT+Vle1CUFyxB3FPDuitCCCGEEGIfiqs0IDdb+zAxchUbUsgtMPh/aVEwerW7uiFJIyKEEEIIIekMxVUaUJCjberIyJWzlBblAQB211BcEUIIIYQQ+1BcpQGFOdo1V42MXMWEBKVxRYeWQXG1dR97XRFCCCGEEPtQXKUBBbn6kavZK3fh121VCR5RZqBOC+zdvggAsHpXTZJGRAghhBBC0pmUEFfPPfccunfvjry8PAwdOhQLFy7UXXfkyJFwuVwR/8aMGaO5/rXXXguXy4Unn3wyTqOPP3qRqx1V9bjq9UU4/dnvEzyizMLVpK76dCgGAKzeWZ3M4RBCCCGEkDQl6eLqnXfewfjx43HXXXdhyZIlGDBgAEaPHo3du3drrv/hhx9i586doX/Lly+Hx+PBueeeG7HuRx99hAULFqBjx47xfhtxRa/misSGuptV51bBXlc0tCCEEEIIIdGQdHH1+OOP4+qrr8YVV1yBvn37YtKkSSgoKMCUKVM012/dujXKyspC/2bNmoWCgoIIcbV9+3bccMMNePPNN5GdnZ2ItxI3CnO1I1ciPj/rr2wjpwU2/dmqIAcAUNPgg5efJyGEEEIIsUlSxVVjYyMWL16MUaNGhZa53W6MGjUK8+fPt7SNyZMn44ILLkBhYWFoWSAQwCWXXIJbb70VRxxxhOk2GhoaUF1drfiXSliJXNXROTBq5Jqrkvzs0OPKOm/yBkQIIYQQQtKSpIqriooK+P1+tG/fXrG8ffv2KC8vN339woULsXz5clx11VWK5Q8//DCysrJw4403WhrHxIkTUVJSEvrXpUsX628iAViJXNU1UFzZRe0W6HG7UJwXjHJW1jUmY0iEEEIIISSNSXpaYCxMnjwZ/fr1w5AhQ0LLFi9ejKeeegqvvfZayKjAjNtvvx1VVVWhf1u3bo3XkKPCUuSq0ZeAkWQWIbdAhM+T1oXB1MD9jFwRQgghhBCbJFVctW3bFh6PB7t27VIs37VrF8rKygxfW1tbi7fffht/+ctfFMu/++477N69G127dkVWVhaysrKwefNm3HLLLejevbvmtnJzc1FcXKz4l0oUWhJXjFxFi6jBWxYEI1f7ahm5IoQQQggh9kiquMrJycHgwYMxZ86c0LJAIIA5c+Zg2LBhhq9977330NDQgIsvvlix/JJLLsEvv/yCn3/+OfSvY8eOuPXWW/Hll1/G5X3EmwILaYG1DYxc2UXtFggAbVvkAgB219QndjCEEEIIISTtSbrH9/jx43HZZZfh6KOPxpAhQ/Dkk0+itrYWV1xxBQDg0ksvRadOnTBx4kTF6yZPnowzzzwTbdq0USxv06ZNxLLs7GyUlZWhd+/e8X0zccJS5IqGFraRmvICxeTRrq0LAABb9tYlYUSEEEIIISSdSbq4Ov/887Fnzx5MmDAB5eXlGDhwIGbMmBEyudiyZQvcbmWAbc2aNfj+++8xc+bMZAw54RToNBEWicbQIhCQcO/nKzGoWyv8aUB69wKLCUFdhcTVPoorQgghhBBij6SLKwAYN24cxo0bp/nc119/HbGsd+/eoaiDFTZt2hTlyFKDwtz4GFp8uaIcr83bhNfmbWqW4krrDKK4IoQQQggh0ZLWboHNBUuRqygMLZq7I56WW2CXJnG1dV+dLQFPCCGEEEIIxVUakJtlfphqo4hcZXmsWdVnOqJbYOdW+QCA2kY/HQMJIYQQQogtKK7SACv9ug5GEbnKclNcqcnL9qCsOA8AUwMJIYQQQog9KK4yhNooDC2yPDz8gNItEAA6NUWvyqtox04IIYQQQqzD2XWGcNBrPy0wW4hcNbf6IqP326qpkXBzr0kjhBBCCCH2oLhKE7JN6qOiiVx5BHHlDzQ3cRV+rE67bFmQAwDYX8eaK0IIIYQQYh2KqzQhN8vYMbCu0QefP2Brm9lCWqDX37zElYhatsqRq0qKK0IIIYQQYgOKqzTBzDHw1+1VOOreWXh85hrL2xQjV96APWGW7hhJyVaFcuSKaYGEEEIIIcQ6FFdpgpm42lXdgJoGH56eu97yNkW3QK+vmYkrIS9QbcbYqiktkJErQgghhBBiB4qrNCE3W5kW2K9TiaPbb95pgUp11bopcrW7piEZwyGEEEIIIWkKxVWakCPUR02/8XhMumRwzNsU5ZTXZr1WumMkJQ9pWwgA2LCnttm5KBJCCCGEkOihuEoTcrPDh6pvx2KU5GfrrmtVEIirNTY3cSV+RKq0wG5tCpHlduFAgw872euKEEIIIYRYhOIqTchTuQXmZ+u7Bx70WrNll4T4TXOLXImoa65ystzo2a4FAGDFjuokjIgQQgghhKQjFFdpQo7K0EJ0+lNTddCay53Y2srXzGquJMPEQOCori0BAIs270vAaAghhBBCSCZAcZUmmLkFilgVV2L6YHNOC9SSqbK4WrGdkStCCCGEEGINiqs0Qay5MqO2wWdpPYWhhY4V+xvzN+EPT32HPRnsnOdS5wUiWHcFANsrDyZ6OIQQQgghJE2huEoTTjisHYDI+iAtGqz2rBLUlZ4V+52frMDKndV4zEZz4kygc6t8AMD2/QcRCDSvlElCCCGEEBIdWckeALHGuYO7ID8nC0d1aWm6bqNFcWXH0KK20ZpJRrpglhZYVpwHj9uFRn8Au2saUFaSl7CxEUIIIYSQ9ISRqzTB7XbhTwM6okvrAtN1rUauJEXkyvg1gQzu96QVDczyuNGt6bNetZN1V4QQQgghxByKqwzEauQqYKPPVaalxpm5BQLAoG6tAAA/baJjICGEEEIIMYfiKgOxHrkKC4zqg8YmGJkWuVKmBWoXsh3dJK4Wbd6fiCERQgghhJA0h+IqjblieHfN5dZrrsKYuQFmWOBKgZ5JyNHdWwMAlm2ttPyZEkIIIYSQ5gvFVRoz4Y99sfBfJ+EP/coUyxt81swnxOjNngP1hutmXlqgOT3bFaJVQTYafAEs31EV9zERQgghhJD0huIqjXG5XCgtzkNBjtL00XqUJSwxKmoaDdf0Z1xaoPn7cblcGCynBrLuihBCCCGEmEBxlQEU5HgUf1utuRKDUbtrTCJXmaWtFBj1Djv2kDYAgJkrdiVoNIQQQgghJF2huMoAoo1cicGbOpM+VlYiPemE1Xdz+oCOcLuCphYbK2rjOiZCCCGEEJLeUFxlAIWqyJWZrbqMnSbCzdEtEADaF+fh+EPbAQA+XLIt3sMihBBCCCFpDMVVBpCvTgv02je08Jvk/Zk9n84YpQUCwJ8HdwYAfLhke8YZexBCCCGEEOeguMoACnNVaYGWI1dhfCaiIZBpTuQ2NNIpfdujKC8L2ysPYsHGvfEbEyGEEEIISWsorjKACEMLr/0mwj6/ibjKtLRAQV2ZBK6Ql+3B6COCdvcPTFuV0VE8QgghhBASPRRXGYDa0KJBiFwt2bIfd3+6AjX13ojXiXrJLHKVaVbsIi6zvEAAR3YsBgCs2FGNB6eviveQCCGEEEJIGkJxlQGoDS1qG3yhx2c/Pw+vzduEB6evjnidGL3xmeT9ZVqwxq5W7FnaIvR48vcb8dueAw6PiBBCCCGEpDsUVxmA2tBif11klGrJ5v0RyxSGFiZpgZlsxW4etwKO7tYaRzRFrwDgpMe+wa5q495ghBBCCCGkeUFxlQGoDS321zZGrLO/LnKZqJe8JpGrTK4zspAViPwcD6bdeDyuGN49tGzog3Pw7do98RsYIYQQQghJKyiuMoD8bHXkKlJIVWpEs0S51Nys2KONxLlVSuyaNxY7MRxCCCGEEJIBUFxlAOrIVU29L6IpsJY9uygwvH7JUHBkWFagMi3QSuiqiT8P6qz4+6DFnmKEEEIIISTzyTJfhaQ6ait2ADj9me8VJgxaqAVTQAI8Ojoj06zYo6Vvx2J8/feR+N9PW/DiNxvQs11hsodECCGEEEJSBEauMoDcrMjDuLq8BtN+2alYtnJHNWYsLw9FqCRVJ10jx8BME1exvJ3ubQtx1lGdAGibhxBCCCGEkOYJxVUGYDWt7ca3l+La/y7G81//BiBSYBg1Es6wkquQsLSREaigZX4OAGBfbSP+u2CzU8MihBBCCCFpDMVVM2L97mBvpo+WbgcAqPWSUSPhTDO0kIlSW6FlQXbo8b8/Xo5ft1U5MyBCCCGEEJK2UFw1Q+QUv8jIVfNJC4xQljbJUzk03v3Zitg2SAghhBBC0h6Kqwwhy209BhNoikKpBZNRdCpTtZUdp0A1lw3rFnpc10jXQEIIIYSQ5g7FVYYw7/bf452/HosRvdqariun/6n1kpdpgba454wjcevo3gCAvGx+lQghhBBCmjucEWYIpUV5GHpIG+Rr2LKrkSNX6nCU38DQwp9hoSun3s6xh7QBAOypaXBmg4QQQgghJG2huMow8rPNxZVf0o5cGVmxGzUYTmdiyAoEAJQW5QIIiqtM/YwIIYQQQog1KK4yDK2Gwmpk3wq1FvA2Qyv2WGnXJK4afAH2vCKEEEIIaeZQXGUYahc7LcJugUqBMfrJb/HaDxs1X5NpNVfyW3fFVHUV/Lzl6JXeZ0cIIYQQQpoHFFcZhpWaK3/ILTDyubs/W6n5moyzYpeJMS0QAHY31Vs9PXc9UwMJIYQQQpoxFFcZRoGVyJWOW6CV12QKTr6bsuK80OOaBp+DWyaEEEIIIelESoir5557Dt27d0deXh6GDh2KhQsX6q47cuRIuFyuiH9jxowBAHi9Xvzzn/9Ev379UFhYiI4dO+LSSy/Fjh07EvV2kkqLvCzTdfw6aYFWXpMpyO/dgcAVJl0yOPR474FGB7ZICCGEEELSkaSLq3feeQfjx4/HXXfdhSVLlmDAgAEYPXo0du/erbn+hx9+iJ07d4b+LV++HB6PB+eeey4AoK6uDkuWLMGdd96JJUuW4MMPP8SaNWvwpz/9KZFvK2m0LMg2XSea+qkMC1yFiNUtEAAGdmmJrq0LAAB7D9CSnRBCCCGkuZJ0cfX444/j6quvxhVXXIG+ffti0qRJKCgowJQpUzTXb926NcrKykL/Zs2ahYKCgpC4KikpwaxZs3Deeeehd+/eOPbYY/Hss89i8eLF2LJlSyLfWlIoyTcXV2FDC+vbzbRaIqffTpsWOQCAC19eQIFFCCGEENJMSaq4amxsxOLFizFq1KjQMrfbjVGjRmH+/PmWtjF58mRccMEFKCws1F2nqqoKLpcLLVu21Hy+oaEB1dXVin/pSkl+juk6/lDNlXWFkbGRK0cSA4E2hUHHQK9fwtNz1jmyTUIIIYQQkl4kVVxVVFTA7/ejffv2iuXt27dHeXm56esXLlyI5cuX46qrrtJdp76+Hv/85z9x4YUXori4WHOdiRMnoqSkJPSvS5cu9t5ICmEtcqX8PzfL/DTINCt2GSfSAgGgrCQ39Hgf+10RQgghhDRLkp4WGAuTJ09Gv379MGTIEM3nvV4vzjvvPEiShBdeeEF3O7fffjuqqqpC/7Zu3RqvIccdKzVXMnJqXItccxOMTMPptEC55goAWts4BoQQQgghJHNI6qy6bdu28Hg82LVrl2L5rl27UFZWZvja2tpavP3227j33ns1n5eF1ebNmzF37lzdqBUA5ObmIjc3V/f5dMJK5AoIRqLktMAcC5GrTEN+7w4FrlAoCNRii8eAEEIIIYRkFkmdVefk5GDw4MGYM2dOaFkgEMCcOXMwbNgww9e+9957aGhowMUXXxzxnCys1q1bh9mzZ6NNmzaOjz1Vyfa4cftpfUzX8/oDoeiNlbTATMXlUF7gkO6tQ48b/QFHtkkIIYQQQtKLpM+qx48fj5dffhlTp07FqlWrcN1116G2thZXXHEFAODSSy/F7bffHvG6yZMn48wzz4wQTl6vF+eccw4WLVqEN998E36/H+Xl5SgvL0djY/PoQXTNCT2Rb9JM2CfUUOVmmTcejgeVdY248KUFeG9R4tMwnU4LPLR9EYb3Cp6L9Y1+ZzdOCCGEEELSgqQX25x//vnYs2cPJkyYgPLycgwcOBAzZswImVxs2bIFbrdSA65Zswbff/89Zs6cGbG97du349NPPwUADBw4UPHcV199hZEjR8blfaQaB73GE3yvL4BAILlpgU/NWYf5G/Zi/oa9OPfoxJqIyNrKqbRAABjeqy1+WL/X9LMnhBBCCCGZSdLFFQCMGzcO48aN03zu66+/jljWu3dv3b5L3bt3z7ieTPGg0R8ICYxkiavqg76k7FeBg+pKjhYe9DItkBBCCCGkOZL0tECSHKb8sDHpNVduJ8NGNomHAA+JK6YFEkIIIYQ0SyiumimVtV5dt8BERf6c6jEVDfFIC8zPCYqreqYFEkIIIYQ0SyiumimNgltgjkd5GiSqYbA7meqqCafcAgEgL5QWSHFFCCGEENIcobhqpjT6wjVXuSpnQV+CxJWTwsYu8QjOMS2QEEIIIaR5Q3GVoTx/0SDD5xt8/lD6n7rmypugPk3JDVxJjo9BTgtk5IoQQgghpHlCcZWh/KFfB0Ph0OAT0gIjxFWCIlcJ2YsxjtZcNUWuaht8mPjFKlz0ygI0+ugcSAghhBDSXKC4ymCyDOz4gmmBTYYWqporX4IiV8msuYpHWqBcc7W7pgEvfrMBP6zfizmrdjm/I0IIIYQQkpJQXGUwRuJFNLRQr+ZNWM1VQnajScgt0MFByGmBIgn6KAkhhBBCSApAcZXBGIorwdDCpUqO8yYolS1T0wJFsj2p8C4JIYQQQkgioLjKYIya9DYKNVfq9XyBRBlaZFZaoKa4SlKDZkIIIYQQkng488tgjCJXQUMLbce8xFmxx38fCzbsxfuLt0Usl+LgFqh2XQQS15CZEEIIIYQkn6xkD4DEDyPhoEgLVK3oS5hbYPzV1QUvLQAAHNa+Bfp3bqk5Cqdwa4QKG30UV4QQQgghzQVGrjIYrcm+TNDQoil6A+D6kT1Dz/kTFLkySlt0mi376hR/JyqglKieYYQQQgghJPlQXGUwHjNDi7CjBf5xah90bV0AIHFpgUbiT0aSJDT4Ym/Kq35Lek6JTsM+V4QQQgghzQeKqwzGyDBCTAuUa7PkvliJilxZ0TVXv74Y/e6aib0HGmLaV0DnPcU7eMbIFSGEEEJI84HiKoMxrLnyB7Cpoja4XtMyT5O4SlQTYStugbNX7UKjP4DPlu2IaV8BVR6ghMQIyEaKK0IIIYSQZgPFVQajlXUn6pk5q3crloXElU6Ux2nnOzspebHatqujcfFKCzyqa0vF30wLJIQQQghpPlBcZTBaVuxZGopLdu3L9gRPB720QKdNIOzomljNL/TG7rRj4f+uPhZf/30kzh3cGQDgTZDzIiGEEEIIST4UVxmMlrjyaIkri5Erv8PqyqgPVwQxhpjUaYHxIi/bg+5tC0PNgxm5IoQQQghpPlBcZTBujaMb0Jjry7IlbGihLQicFii2tFWM+1ILw3i7BeY0RQFpaEEIIYQQ0nyguMpgtCJDPg3hJNczmddcOTg4mAsmscbLVpRLg0S7BeZkKcXVlr11eOW7DTjYGLutPCGEEEIISU2ykj0AEj+0BElAAsb074Bpv+wMLZNXy/IYW7E7bdFuZlIh7i/WCFOEoUWc3QKzmz7Lg96gmDr5iW/Q4AtgR2U9JpzeN677JoQQQgghyYGRqwxGT5A8dHY/5XqQI1fB08HnFyNG4fWcTgs0i0aJZhCxRpj0mwjHJ3Ylm4O8Pn8z3pi/CQ1NtVcLNuyNy/4IIYQQQkjyobjKYPTES1FeNvp2KA79HYpchdICA8Jz4W043VvYTNd4FeOIbV+JMrSQqRCaHt/5yYrQ43jVeBFCCCGEkORDcZXBiFGnkvxsxXMFOZ7Q44gmwgGdyJXD6srMXt0rOO3Fapke2UQ4vuyubjBfiRBCCCGEZBQUVxmMGLlq2yJH8dzmfXWhx/Jq2Ro1V6Kocd4t0HpaoJ7JhlX0Xh6vSNINvz80PhsmhBBCCCEpC8VVBtOqICyoRvVtDyAsoPbUhCMrYbfAyJorMWDkdJ8rEUlj26KNuZ49vFUiDC3inCbYr3MJjuraMmI50wIJIYQQQjIXugVmMN3bFmJ+k4HCzaMOQ6uCHIw6vDRiPXXNlUKIiA8d1iNuVT2XRyU8RHEVa+RKLabkv+Ipdlrk8utFCCGEENKcYOQqgzmsfYvQ47xsD649oSd6lRYBAG4aFU5bkyNVWjVXomV5PJsIa21bkRboj23fer18Y63lMqIoj+KKEEIIIaQ5QXGVwZx/TBcc0bEYlw3rFvHctSf0DD2WI0ThyFVYiYiax+k+V2Y272Lkal9dY0z7ijC0SIB5oFbkKp5ijhBCCCGEJBfeWs9gCnKyMO3G4zWfy80K6+rGJlc+OXLl1YkSyYJEkiT884Nf0KNtC1w3sqfmulYQhYaW2BHF1Qtf/4ZstwvjT+kd1b4ixVvw7/imBWabr0QIIYQQQjIGRq6aKaJTX2NE5EpMCwwjC5TFm/fj3UXb8PCM1TGOIXLbImqR9/Tc9VHvSy+lMZ5xpBa5HvOVCCGEEEJIxkBxRUIRopBboCiuBFEii656b2zOfTKiwNNKOfTqFUpFgXpTiUgLzM2OFFd0CySEEEIIyVworkgoLTDc50pb1Mj6x+3QWaOsuYp8Xk9c/by1EtsrD5puXxSG+m6B8VM7OZ7ID4raihBCCCEkc2HNFYmoufLppAXKAkW0UJckKWqBIr5Ku89V5LL1uw/gzOd+AABsemiM4fbFTSYjLTBb7S1PCCGEEEIyGkauSEjEaNZciW6BktKyXb2uXdxuZZ+ryHFFRq6Wb6+yvH1xk8lIC8zO4teLEEIIIaQ5wdkfQYNPv+ZKRM4WFNP5YmnuK8Z1tCJLTjYOjrRilyIH4TDZGmmBLLoihBBCCMlcKK5IuM9VUxqbT6fWKaCRFhhL5ErLiVBEr/bLqe0D8U0LZM0VIYQQQkjzguKKRDQR9jWlCarroLTEVazRJRkt7ePT6bcVzTbVIjABWYHakStCCCGEEJKxcPZHQoYWeU3W4Qe9fgCRgkfWJ07VXJkZTuhFm6IhMi0w+H883QJpaEEIIYQQ0ryguCKhyFV+TlBc1TU2iSvVelpCyhdD6p6yJiryea2omGQj5iSuqzfMuKYFahhasOSKEEIIISRzobhqxgzoXAIAOOuoTgCAghxl5EqNLIaM0u2iJaCxHa1l/5mxxvI2tZwOQ88lIDFQq+aKEEIIIYRkLuxz1Yx58+pjsXx7FYZ0bw1AEFdy5Cqi5kr+P7w8lrooM8MJrcjVzqr6qPYVsf1QWmBUm7OElhU7A1eEEEIIIZkLxVUzpkVuFo49pE3o7/zs4OlQ1+gDoJ8WKGksiwZlzVXk87FGxcTt65VvueIod2hoQQghhBDSvODsj4SIjFwpn5frqxSRK6fSAjWt2I23/eoPG7FyR7Xu82LqX3LcAhmnIoQQQghpTjByRUKEDC10aq60RJdTfa7UKYiAuXC757OVAIBND43R3r6BG6GUgLRAzT5XdLQghBBCCMlYGLkiIfKzVZErVXwnbNEuRq7i5xaoZWhha/vithy0dbeKllsgIYQQQgjJXDj7IyHktMAGXwD+gBSRFnhQw6LdMbfAKCJXZojiLdLPIv5iizVXhBBCCCHNC87+SIiCnHCWqJYdu9z/SowoOVZzpREAi9nQQnysFlcJaSJMt0BCCCGEkOYExRUJkZftDtUgyY6BIqG0QGGZc26BGoYWMabyKdwCdSJVcW0izMgVIYQQQkizIiVmf8899xy6d++OvLw8DB06FAsXLtRdd+TIkXC5XBH/xowJmxpIkoQJEyagQ4cOyM/Px6hRo7Bu3bpEvJW0xuVyhequXvpmAyrrvIrn5bRAp/pciWjpqJhTDg1enogKLLfGtysZtV+EEEIIISQxJF1cvfPOOxg/fjzuuusuLFmyBAMGDMDo0aOxe/duzfU//PBD7Ny5M/Rv+fLl8Hg8OPfcc0Pr/Oc//8HTTz+NSZMm4ccff0RhYSFGjx6N+vroGtA2J2Rx9cr3GzHy0a8Uz8lpgaIyic0tUDS0sG/Fbmf7kWmBwQXxNO8T0yxl/AEJy7dX4cMl2+K3Y0IIIYQQkhSSLq4ef/xxXH311bjiiivQt29fTJo0CQUFBZgyZYrm+q1bt0ZZWVno36xZs1BQUBASV5Ik4cknn8S///1vnHHGGejfvz9ef/117NixAx9//HEC31l6ItuxA0C9V1kIddAbTBUUNU9sboHhx1opgI42EdZZJ57iyuN2Yfk9o/HE+QNCy/yShD8+8z3Gv7sM836riN/OCSGEEEJIwkmquGpsbMTixYsxatSo0DK3241Ro0Zh/vz5lrYxefJkXHDBBSgsLAQAbNy4EeXl5YptlpSUYOjQobrbbGhoQHV1teJfc6VAEFdq6jQs2p1yC9TucxW9cANMDC1i2rJ1WuRmoTgvO/S3X3hL63cfSNAoCCGEEEJIIkiquKqoqIDf70f79u0Vy9u3b4/y8nLT1y9cuBDLly/HVVddFVomv87ONidOnIiSkpLQvy5duth9KxlDvkYqm0y45iq8LBa3QGUfqsjn/bFpK5Vg01ZXrgT49x17SJvQY78gGGnVTgghhBCSWaT17G7y5Mno168fhgwZEtN2br/9dlRVVYX+bd261aERph8F2fqRK60mwk65BWoZY/jjGLmSiWdaoExhbhbe+EvwHPUK7zPLTWN2QgghhJBMIqniqm3btvB4PNi1a5di+a5du1BWVmb42traWrz99tv4y1/+olguv87ONnNzc1FcXKz411yxlhYY5pdtVY7s16sRpoo9chV+rDbMSEQTYZG8JtFaUx+2uM/yUFwRQgghhGQSSRVXOTk5GDx4MObMmRNaFggEMGfOHAwbNszwte+99x4aGhpw8cUXK5b36NEDZWVlim1WV1fjxx9/NN0mAfIMxJWcFihGriZ981vU+xIFjra4ilFdCagDbKEmwo7twRh3U4ispt4bsYwQQgghhGQG+gU2CWL8+PG47LLLcPTRR2PIkCF48sknUVtbiyuuuAIAcOmll6JTp06YOHGi4nWTJ0/GmWeeiTZt2iiWu1wu3HTTTbj//vtx6KGHokePHrjzzjvRsWNHnHnmmYl6W2mLtbRAZ/YlbqfRFymkYqnnAsyt3gEkJi8QQHZTlKpBeJ9a75kQQgghhKQvSRdX559/Pvbs2YMJEyagvLwcAwcOxIwZM0KGFFu2bIFb1Y11zZo1+P777zFz5kzNbf7jH/9AbW0t/vrXv6KyshIjRozAjBkzkJeXF/f3k+4YpwVGWrE7RaNG5CrmhruiFbtO5CpR5GuIVq33TAghhBBC0pekiysAGDduHMaNG6f53Ndffx2xrHfv3prW3TIulwv33nsv7r33XqeG2Gwwcgus00gLdIoGrciVhsmFHZRuhOqaqyCJSszL0xJXjFwRQgghhGQUUdVcbd26Fdu2bQv9vXDhQtx000146aWXHBsYSQ45WfqnRL030oo9FkSRplVzFWvkysjQQiZRZU9aEUGKK0IIIYSQzCIqcfV///d/+OqrrwAE+0qdfPLJWLhwIe644w5Gi9IcI3twr1/CQ1+sVoiiHId6NcW/5kr1XILzAvMprgghhBBCMp6oZsbLly8P9ZZ69913ceSRR2LevHl488038dprrzk5PpJgzOzBJ33zG5Zs2R/62xeDo5+ZoUUsPbTU29fpIZy4tMCsSHGlFa0jhBBCCCHpS1Tiyuv1Ijc3FwAwe/Zs/OlPfwIA9OnTBzt37nRudCThZLu1TwkxoLV138HQ44AEBKIUQeKr4iKuhMf6aYGJkVdutwu5qpTLBoorQgghhJCMIipxdcQRR2DSpEn47rvvMGvWLJx66qkAgB07dkRYo5P0Qi9yVSAYXVQebFQ8F2v6HqAdxYk5LVAS0wJVhhYJdgsEIuuumBZICCGEEJJZRCWuHn74Ybz44osYOXIkLrzwQgwYMAAA8Omnn4bSBUl6kqVTQ5UtiK7KOq/iuWhTA0WBoxXFiTYiprV9vU0lso2v2o791R82YeWO6gSOgBBCCCGExJOoxNXIkSNRUVGBiooKTJkyJbT8r3/9KyZNmuTY4EjiydYxtPC4jcRVtGmB4dfFYmhxxrPfh5wMdfcVEapKfOgqT8PU4k/Pfp/wcRB7/LbnAK55YxGWb69K9lAIIYQQkuJEJa4OHjyIhoYGtGrVCgCwefNmPPnkk1izZg1KS0sdHSBJLHqRKzHGs79OmRboj7EfFRBbzdWybVWY/mtkrZ9R5Ep+LlFW7IB2I2EnUipJfLlsykJ8uWIXznzuh2QPhRBCCCEpTlTi6owzzsDrr78OAKisrMTQoUPx2GOP4cwzz8QLL7zg6ABJYsnWqLlyuZQiRN3w1+tAWmCsNVdaTYiVVuw6hhYJTAzUElck9dm2P2jgQiFMCCGEEDOiEldLlizB8ccfDwB4//330b59e2zevBmvv/46nn76aUcHSBJLlo5boJEEidbVz8wtsMEk1U9Ea+JrGLmyvGXnKMrLMl+JEEIIIYSkLVGJq7q6OhQVFQEAZs6cibPPPhtutxvHHnssNm/e7OgASWLRcgs0i+34nEgL1IhcaUWj9PBrvF7R5krPLTCBaYGtC3MTtzNCCCGEEJJwohJXvXr1wscff4ytW7fiyy+/xCmnnAIA2L17N4qLix0dIEks2mmBLrgNipOiTpeSjA0tzEwqzMZgZMUuk0i3wDYtchK4N2sEAhLu+3ylZs0aIYQQQgixR1TiasKECfj73/+O7t27Y8iQIRg2bBiAYBTrqKOOcnSAJLFopQW6YGz84IuyGa4od7SiVHbElZZ4UjYRVj+X+MTA1oWpJ64+/3UnJn+/Ede/uSTZQyGEEEIISXuiKgI555xzMGLECOzcuTPU4woATjrpJJx11lmODY4kHr0mwkYRHicK/Ru8GuLKRlqgec2VdlpgIt0CU1FcbW8yayCEEEIIIbETdYV9WVkZysrKsG3bNgBA586d2UA4A8jWsGIPugUapAXaqLl6cPoq5GV7MP7kwxTip96njFJ5/QFbRhmyHfzu6np8v74CY/p3UDyvkxWYULfANikorrTSMQkhhBBCSHRElRYYCARw7733oqSkBN26dUO3bt3QsmVL3HfffQhEactNUoMsjSbCZgLEZ/GY769txEvfbsDTc9ahut6rSM2r9/rx+S878MnP2wHYM7MAAH+TejrzuR8w/t1leG7ueoiJgVv21SlqsJLjFpidhL0ao2WBTwghhBBCoiMqcXXHHXfg2WefxUMPPYSlS5di6dKlePDBB/HMM8/gzjvvdHqMJIFoRa7gMk6fq2u0Xhsls6emQfF31UEvxr21FH97+2dU1Xlt1VsBwQjMok37sKOqHgAwa9VuRbTKH5Dw8Iw1ob9loZXItMCCnHCfqxN7twOQ/GiWlksjIYQQQgiJjqjE1dSpU/HKK6/guuuuQ//+/dG/f39cf/31ePnll/Haa685PESSSHRrrgxEyEWv/Gi4zZe/3YCrpv6kmMhX1DQoxE/1QV/o8UGvPySucrKsnaLl1fU4Z9L80N8ed2R0atI3v0W8LpHiqkVuOAu3W5tCAMlPy0v2/gkhhBBCMomoaq727duHPn36RCzv06cP9u3bF/OgSPLQdQuMoTbpgemrAABHd98eWlZxoFGxToOq5qq+yeAiL8ttSQCUN0WsZNwul26dVbIoyA1HruQoVkOSI0d20y8JIYQQQog+UUWuBgwYgGeffTZi+bPPPov+/fvHPCiSPLT7XDkT4ams84Ye766pN7RKl8VWXrYHVlC7BbpgbLcecgtMoKGFGLnyNNW2NfoCEQ2OEwlrrgghhBBCnCOqyNV//vMfjBkzBrNnzw71uJo/fz62bt2K6dOnOzpAkliytNwCHZIgYgSqss6rG1mSIIUjVxbF1cod1Yq/XSaRK1l4JTItMC8r/F7EsXn9EnKyEtnOOAzTAgkhhBBCnCOqyNUJJ5yAtWvX4qyzzkJlZSUqKytx9tlnY8WKFXjjjTecHiNJIHpTfCMrdquIURKjiIkkAQ1NNVe5FmuuDjT4FH973MbiSjY4dCdQXbk1nBgB4J8f/IKdVcnpN0VxRQghhBDiHFH3uerYsSMeeOABxbJly5Zh8uTJeOmll2IeGEkOWmLD5TJuImwVcSLf6AvAo2Oe4Q9IONgkrvJzPHjpksH4fn0FXp+/2fK+3C7jtEC5qbCO3kkoHy3djpL8bNz9pyMSvm+6BRJCCCGEOEdUkSuSuWiJDSv6w2dhki5Gqxr9Ad1mUwFJCtm7F+R4cMoRZbj6+EMsjCKMXlrg6/M34Zu1e8I1V4nMCxTwqnqDqSNvCRsHxVXM/LhhL0Y9/g3m/7Y32UMhhBBCSJKhuCIK2hXl4vhD26J7m4LQMpfLhUuGdYtY95C2haHH9RbSy8QoiVE6mj8goa4xKDYKc4LBVY/NEJNHRzRN+GQFLpuyMBTVSlbkakDnloq/WxUkp8Ew3QJj5/yXFmD97gO48OUFyR4KIYQQQpIMxRVR4HK58MZfhuLNq49VLL9sWHd8cN1xuGpEj9CygV1bhh5bafqrTgvUS9oLSBJqG8JpgYD92iiXC8Y1V0mKXH3195F46oKBOO3IMtwjpAF6/clxDKS4IoQQQghxDls1V2effbbh85WVlbGMhaQQoiW7C0EzhsHdWmHBhnDqk8flQk5THyork3QxctXg17cg9wcQqrmSI1d2I0xulysla656tC1Ej6aI3yXHdsO3a/dgzurd8AWSI3K8FFeEEEIIIY5hS1yVlJSYPn/ppZfGNCCSGuR6wrbhYg8p0Rrd5Qo3+bUSuVK4BZqkBdY21SCFIlc2VZDVyFUi3QLVuN0uDOzSEnNW74Zf3egrQQRSrdMyIYQQQkgaY0tcvfrqq/EaB0kxcgQLdFEU5WWHl7tdLuRle1Bd77OfFugP6Iof0dCiMDe6tECjtEMAoahZErUVgHBfsQUb9uH2D3/Fbaf2QUmS6q8IIYQQQkhsRG3FTjIbMS1QEbnKUkaucpvElqW0QIs1V6KhRUFTWqDdyE69Tz/tEAACAVlcJVddyZ/zxopabKyohT8QwH/OGZDUMRFCCCGEkOigoQXRRI6oqFGmBbpCYqve60e9148Zy8t1bcUbBdMGQ7dASUKtYMUOADk649Fj2dZK3Pf5St3n5ZEkMy0QALJU6Y7vLtqGfbWNSRoNIYQQQgiJBYorYov8nPAp40JYbDV4A7j70xW49r+LMe6tJZqvbfSFUwcN0wIDEg42Kg0tSgqy8dDZ/WyNdcmWSt3nwjVXtjbpOFoi9sHpq5IwEkIIIYQQEisUV8QWYlqg2+VCVlNam9cfwNs/bQUAfL1mj+Zr1X2u9Nz8xLTAvJzw/i4Y0jW2wQvIaYHJjlyJ6ZcyizfvT8JICCGEEEJIrFBcEVvkZoviCsh2B08hX0BCbpbx6aQ2tJDJF7YJBNMC5b5P6nTAJ853ph7JF0gRQwt35Ge2dV9dEkZCCCGEEEJiheKK2EJ0C3SpIldm4sqrqrmS0wLV0ZtAAPA1iS/1c2cd1TnqsYv4m/pKuZDkmiuNyJUvIOHB6auwurw6CSMihBBCCCHRQnFFbKHucyXXDHn9kiKqpYXaLVAmJ0s/cqVVk3RY+xb2B67CF0hOE2E12TpGHS99uwFnPTcvoWMxclckhBBCCCHmUFwRWyjEFVzIblInPguRK720wJyIyJUU6q2VraF+3r/uOLz912PtD17AnyI1V2q3QJGDFnqHOQm1FSGEEEJIbFBcEV20zBbE+igJUjgtMCApGg9rIQqqBm+4D1W26nX+gBSKLKmfA4DivGwce0gbzX1YjUTJkTGNkqeEohe5SgbUVoQQQgghsZE6MzuScmiZLYg1V15/IJS2F4xcGacFihz0+kONh9UCIyCFI1dGkR0tPBbXl2u6kt1EWKvmKlkEGLoihBBCCIkJiiuii1bkSrRib/AGhLRAc7dANXubmuUaiSu7kR3L4ipFaq60BKxMcV6W5vLv1u3BG/M3OT4WaitCCCGEkNjQnr0RAtlowqdY5hbUSIMvEEoF9AbMa67U7GsSV+qaK38gKNYA++IqKFYCpuvJNVep6BYoc0THEs3ll0xeGHy+UwkGdW3l2FgYuSKpiiRJ8AckTYMbQgghJJXglYroohW5Emnw+UPix6fjFmjkQFdxoKFpP6qaKzEt0GAM8277Pf77l6Ho0jo/tMyqVPI1WbEnP3KlPwAzsbOzst7p4RCSktz0zs845oHZqKrzJnsohBBCiCEUV0QXs6hRoy8QEmB6boFG+mDvAZ20wEDYij3bIG2uY8t8jDi0LQJCoMpvMfoiR8aSXXNl9BnL0bVEkQ6Rq1+3VeHaNxZjY0VtsodCEsgnP+/A/jovPl22PdlDIYQQQgyhuCK6mEeuAqGaIW9AWXMlR56MpusHGoIph9pugU01V1nm4kcUIVYFiS9VrNgNPmOfyXuRbPr7BQISFm7ch5p67bv/aaCtcPqz32PGinJc/fqiZA+FJAGxETkhhBCSilBcEV3MIlcNqshVQU44LXBPTTDlz0pj2hzNtMCmJsIWvNLFiIvV6Es6GFo4HUl6Z9FWnPfifPz5Be3mxOkQuZJh5Kp54vWb11MSQohdZizfiSdnr7U0ZyHEDBpaEF3M+lY1+PzhPld+CR5BKPyyrRIdW+bDSiApRxWdEpsNm0XPAKUosBy5apqkuZOsrozen8/hu/QfLQ2mVK3ddUDz+XS6pPAC2Dwxi+YSQkg0XPvfJQCAY7q3xvBebZM8GpLuMHJFdLFScyVHXnyBgGLCu2pnDQBrqWvq/TQI4sqKO5goqKzOvXwht8DkYvT+ElFzJdacSWkUFGjuU2yfP4Dv11WgtsFnvnIGwcgVISSeyFk3hMQCxRXRxUrNVTgtUFLU7NR7/QCs1fGoxZX8WitjAKITIRv2BKM3yTa0MHILNDPnsG0jb/Ix2a3hSibNPXD19Nz1uHjyj7hqavOqPXM6mksIIYQ4DdMCiS6WIldN63j9kqJ+qVE2tIhCXImRKyO3QJloJtq/7QnW7CS75srIUENLNIrRQafFEDOu0of/LdwCAJi/YW+SR5JYGLkihBCS6iQ9cvXcc8+he/fuyMvLw9ChQ7Fw4ULD9SsrKzF27Fh06NABubm5OOywwzB9+vTQ836/H3feeSd69OiB/Px89OzZE/fddx9rNKJAbTShJugW2BS5CgQUU/2wW6AVQwulwGjwBSNXbpe1miizCE+/TtrNeIP7SN3IlS8QOZGMZ6ogvyPpQ7LTWZMF3QIJIYSkOkmNXL3zzjsYP348Jk2ahKFDh+LJJ5/E6NGjsWbNGpSWlkas39jYiJNPPhmlpaV4//330alTJ2zevBktW7YMrfPwww/jhRdewNSpU3HEEUdg0aJFuOKKK1BSUoIbb7wxge8u/dGLXBXlZaGm3oeBXVoqmgh73OGJj9cXfGxlvq42zmjwBgz3r8ZMcBjpp6RHroyaCGvcpLfax0sLLaGrjIQRktpo3XAghBBCUomkiqvHH38cV199Na644goAwKRJkzBt2jRMmTIFt912W8T6U6ZMwb59+zBv3jxkZ2cDALp3765YZ968eTjjjDMwZsyY0PP/+9//TCNiJBJ1/ymZz8aNwNs/bcVVx/fAlyvKAQQjVTkafa6s2HurTR3kyJVVcXVIuxZYtbM69PfwXm3ww3qL6VIpHLny+gMIBCSFAIvn3DKdrNhJ84SRK0IIIalO0tICGxsbsXjxYowaNSo8GLcbo0aNwvz58zVf8+mnn2LYsGEYO3Ys2rdvjyOPPBIPPvgg/P6wAcJxxx2HOXPmYO3atQCAZcuW4fvvv8dpp52mO5aGhgZUV1cr/hF9M4nubQtx22l90LZFbqgmyheQFFGQRgtNhMP70Y5cGTXYFZl08aDQ44ln98NrVwxRPG+0lWRHrjwGA9hd04A/PP2dskmyGGlyYJ6p2AbnrWlDku8JJA0fa64IIYSkOEmLXFVUVMDv96N9+/aK5e3bt8fq1as1X7NhwwbMnTsXF110EaZPn47169fj+uuvh9frxV133QUAuO2221BdXY0+ffrA4/HA7/fjgQcewEUXXaQ7lokTJ+Kee+5x7s1lCGY1VwCEPlcBhSGC14ahhbrmqt5m5Kpbm0JsemgMauq9KMoLRjQ7tczH9sqDwRVcLky+7GhM+GRFeFkTya65Mtv/6vIa7Kg8iC6tCwA4F12SJAlXvPYT1uyqCS2joUX6YNspMkOgoQVJZz7/ZQeK87Lxu8PaJXsohJA4knRDCzsEAgGUlpbipZdewuDBg3H++efjjjvuwKRJk0LrvPvuu3jzzTfx1ltvYcmSJZg6dSoeffRRTJ06VXe7t99+O6qqqkL/tm7dmoi3k/JYETdZQs2V0tBCrrkyn7Gr645CNVc2w0qysAqOK/xaF4CTDm+PH277Pbo2iZTQvpM8RzVKC5TxKNICY6i5El66ZlcNvl6zR/k8Q1ckxfHyDgBJU7ZXHsS4t5bi0iksUSAk00la5Kpt27bweDzYtWuXYvmuXbtQVlam+ZoOHTogOzsbHo8ntOzwww9HeXk5GhsbkZOTg1tvvRW33XYbLrjgAgBAv379sHnzZkycOBGXXXaZ5nZzc3ORm5vr0DvLHKyIq2zBLVCMqtiJXKmRUwo9FtMCtRBFixgcUqfhJbvPlRU3RLG3j1NugVr9gjhvJakO0wKVSJKU9N8wYo0KNqclpNmQtMhVTk4OBg8ejDlz5oSWBQIBzJkzB8OGDdN8zfDhw7F+/XoEhKr+tWvXokOHDsjJyQEA1NXVwa3qjeTxeBSvIdbIzjK/aIt9rhQ1Vz7rNVfqFCf5tZ4YJg1ZwjkgbkW9yWSnBVqhUagpFGuuYkkR1Hoprdhjp97rxzVvLMI7P22J637S4LSNC2wiHGbx5n0YdN8sfLB4W7KHQizQXL+z6QaPE3GCpKYFjh8/Hi+//DKmTp2KVatW4brrrkNtbW3IPfDSSy/F7bffHlr/uuuuw759+/C3v/0Na9euxbRp0/Dggw9i7NixoXVOP/10PPDAA5g2bRo2bdqEjz76CI8//jjOOuushL+/dMdKA185/c4XCCgm7HbcAtU/ZnWNcp+r6H/lPIrIlTJF0GjfqYjYVFn8OB/6YjW27quLaptax4XaKnbe/HELvlyxC//84Ne47icNTtu4wLTAMNe8sRj767y45b1lyR4KsQlvZBGS2STViv3888/Hnj17MGHCBJSXl2PgwIGYMWNGyORiy5YtiihUly5d8OWXX+Lmm29G//790alTJ/ztb3/DP//5z9A6zzzzDO68805cf/312L17Nzp27IhrrrkGEyZMSPj7S3espQU2Ra58kiot0HqfKwAY3K0VFm/eDwCorvcCiE34lJXkYWWTPbu4GfXcLNk1V1Z47YdNuOtPR6BFblYoqgcAO6vqcf6L8zHv9pMsbcfMGJDX+9ipqmtM9hAyGq+PGQgy1JnpiySlx409Qkh0JFVcAcC4ceMwbtw4zee+/vrriGXDhg3DggULdLdXVFSEJ598Ek8++aRDI2y+jOlfhidmr0X3NgW664TcAgM6boEWEgNdAF68ZDBGPvI1DjT4UFPvA2BsU25G3w7FmLt6d3D7wmbUTUjTIS3wvcXb4AtIuGnUoTjhka8Vz+2oqo9qm1qRK/a5IskkEJDQ6A8gL9ujuw6bCJNMoLn/0tY2+DBjeTlOOrwULQtykj0cQhwn6eKKpC69Souw4PaT0LIgW3cduReWzy8pIh+NBoYWHrdLYczgcgFtW+TirtP74tb3f0H1wWDkKhbhc2j7FuHtC7Erdc1GuhSDT/91p6N3OrXSUtL5gv/5Lzuwu7oBV47okdyBJOh8Spfz1g5nPf8Dlm2rwrIJp6BE5zfHKUMXQhKNeB0KSBI8zTa5F/j3x8vx0dLtGNS1JT68fniyh0OI46SVFTtJPGUleYZ3kmXjCJ8/oJiwb9hTi1vfW4Z9tZFpUnr9s1rkBrW+r2kCFYu4yhfHLGzGqxJX6ZAWCATFqpUaOKtozVHTOXI17q2luPfzlVgn9O0izlNd7426zs+MZduqAADfr6+Iy/YJSRXS+KfWET7+eTsAYMmWyuQORIPmfmyIMzByRWJCrsvyBiITAN9bvC3U/FYkN9uNg96wA558R68wV3k6xqIlxHoxUT+lY1ogEPzBf2dRbP3XRPGr7RYY0+ZTgv113uQOIBM+RAMG3jMTAQn47h8nan63SeJIj18uokU638gihJjDyBWJiXBaYEDzgnGgwRexTB25kvWNWlzFZMUuNhEWNuOPSAuMehdxoV+nEtuv8UbR+0f74s4LPjFGjngu2rwvuQMhCcPrD2Dtrho63BFCiEUorkhMyH2ufH5JM9WsQYhQyeRkaZ92RXlKcRVLXYnCil2suQqkds3Vh9cfh5/uGGXrNfUan7EZr/6wMWJZJpSzJH0CmLCaq4TsRn//CYybJP2YNnOuf3MJTnniW7y1ML692zId8Tvb3CNXzfztk2YAxRWJiSx32C1QaxJU742MqlQd1E7dikgLjGH+pkgLVNRcqdMCo99HPMj2uNGuKNfWa6Ip8v9yxa6IZel6wQukkipM1w8xhUmlw9scmbUy+Fsx+bvIGzIkOnhOE5LZUFyRmMgWIlda88p6X2RUZWCXlprbylNFtGKxYs9ya6cFqiNX6VJzZYTapEMPs7XS9W6qP03Hnc4k8mvDyJU2GfDTlXbMXFGOYx6Yjfm/7Y1pOzynCclsKK5ITMi1Tb5AuInwuYM7Y2iP1gC0U9baF+dhQOdwbZGcmpedpa7Fin72oDS00N9OqkWuosEpe+p5MU4YkoUoCpvLlCWTJ9bq98a7/CRV+Osbi7GnpgEXvqzfa9MKPKcJyWworkhMiPbgcsrd8Ye1w5CQuIpMC3S7gA4l+aG/5bmU2mo8HoYWahJZO2KHC4d0sbyuU41V7/t8Jb5Zu8eRbSWS5thXNtnnbSJrFUUfUs5JSUbAE5mQjIbiisSEKGIa/XJ/KiC3KQqlFblyu1yaNuvZHuWELRYr9iyLL07VVLiJZ/fH/w3tamlddWPkWPh+XfqJK6YFxoeDjX58t24PGn2R6jWR0o6Hl2QCNLQgpPlAcUViQiGumiZhLrhCjoD1WhMzl/LOt/xQXWMVSz1Ulk6+30l9ShV/p3J6hl6zZTXqOjI9rFzP3WmYJymmRXLO4hw3/G8pLpm8EBO/WBXxXGJrrhK3r/Qi/b6rJAhP6dSCNXDEaSiuSEyIqXyrdlYDkCNXHgDaVuwul0shnFzCclFQxCSuFGmB4cfPXzwIH1x3XOjvVL6DqGdZr8aptEAgPQ0+muOFMRGHafaqoEvcG/M3R+4/kVbsNqai63bVYPw7P2NTRW0cR0RShZRyCjVB/M6k8nWnOcLDQZyG4orEhFakw+VymaQF6htJiKLIMSt2YXlulgf9BTONVJ6YW45cOZgWmIaBK2XkqpncE05oWp78v/Bdiae4U2/azvz53Bfn48Ol23HJlB8dHVMyePWHjfjb20sdM6zJNF6fvwn97v4SP2+tTPZQLKGoHeQhTSl4OIjTUFwRx3G5wlEXbUMLl8KsQowsiel8TlmxqxH3nUrzFvWQsy2Kq6qDXizcuM+Ru7jpGLkSa644aYkf4meb2Jor68e3si7YQ2/rvoPxHFJCuOezlfjk5x2hCGLSSbGfhgmfrEBtox+3vPtzwvYZy80n8dxN5Zt6zZFE3TgizQeKK+I4bpcrlBao1efK7XJp1lwBylS4WBzJsgRhok7BEKNtqXRXWC0mraYFXvTKjzjvxfn4309bDNez8k7TUVyJh5fpNvHDH8cJiNFks7kf0doGn+byNPyqpj1Wf5O1UIgrB8ZCnIPHgzgNxRVxHBeM3QJdRmmBQg1XLFbsovOgUdpcKk3G1cJGfA/nHd3Z9PUfLN7m+BjSAVEgp5JYjieJtEIHguJHmX7l7P6NvoZSM7Tab058tmwH/u/lBdhT05DsoZhiNVVbCzEtMJWuO4QZD8R5KK6I47jd5mmBWoYWAJCdJdRcOWTFbjThTqUfVXUqY65wl/SUvmWmr3dCGKV7zRUnLc4jSRK+XrMH506aH1rmeOTK8Dke00zmhv8txbzf9uLhGauTPRRTcpoyMqJBmRbowGCIY/A3hjgNxRVxHNHQQossj6rPlTBTE90HnbJiN5pwp9JkXG0OItZcFeSYX9SdmPCmoxW7eAz9zSTKkeij9MXynXHdv/F31OGdpRlpGEyOisq6xqhel8jTw+i6ZoY4zlS67hCKXeI8FFfEcVwA8rL1xUBBdpZuWlO2Q1bsokgwGksqTdzUkSsxvz/fkrgy+bwsXEG0PvODjX6sKa8xfW2yEI9hc0kLTCQSIq3XnU5LNEwL5MxHk0Rrrmai8QyJpeYqYMOYBQimed/09lLNJt6EkNSG4oo4jtvlQmGuvhgozPUo0s/Ei7ZTVuwiRsIkldIBjAwtrIgrJz4vrW1c9MoCjH7yW3y9ZnfsO4gCf0BCTb3X8HmZZnNHOMkz3XhGrtS6TdTLzeTokhRFrIO1i920wFveW4aPf96BdxdtjXqfqUKDz5/SN0kSMbRUfv/EeSiuSMx8dP1xir/dLhfyc7J01y/IyVLWXAnXK0XkyiF1lW8UuUqhSEekoUX4s7BSSO1EzVVdox+v/bAR5VX1oWVLtlQCAF7XaCabCM6ZNA/97p6J3TX1ms8r0wJT53jGQqMvgKo6fUGZaNSnlvNugQbPKfoDZcbxJZGkw6GNJXIl3hqwc1Mv2nTJVKGqzosj7/oS//dy6vaei/dN1lveXYZTnvhW0+CLZCYUVyRmWhXkKP52uYBCg0hLQY5HVwhkKyJXzszgjOqVUmku3qlVvuJv8UKeZcHdY95ve+GNsejoqTnrcPdnK/F/Ly+IeG7u6t1RiZdd1fX48wvz8PHS7VGNaWmTuJu7SjtyJoqrZEeunNr7KU98gwH3zsTuam1BmWkpWoaTGxoBkBQhJrdARcsIBwaTJsxatQtev4T5G/Ymeyi6xPt35YMl27Bu9wF8tTo52R8k8VBckZjJVt3Nc7ki09hE0aQWV2I9hxiticWKXcS45ir5V7m3rh6KEw5rh6fOP0qxXLyQeyymo/x3gX50yc473VBRq7l83m8VeOW7DXh27jrN5+safag6qIy4TJy+Cos378dN7/xsYwRBxEhFYa52NDQTrdg37a0DAHyzdo/putN/3Wm6TixofUWc/piNthdQTEoz4/g6QXMxukglrNzk0kM8cxmBTS14NIjTUFyRmFHfzXPBhRyPW2HQkKNwvstS1lwJj7MUaYHOjC/VI1fH9WyLqVcOQdc2BYrlyshV5EzqxN7tIpYtU/Qicp4D9T7cP20VHp25VjNNb8A9MzHgnpmKxqdqsWVrf8J29Or4AkKwThRXb/24BZdM/hHVBvVaTiMeJScmUHpbEA0lrn9zScz7MUM9kZckCRsrarG98qAj2zduImzPCCATED8PtZkISU8CitrQJA6ERECxm3r4/AEs3bI/5mycZEFxRWJGnYfudgUnf6KoEaNbOVlu3XqqnASnBabyj6oiiid8XkW5Wfjhtt8rnpdx0kq94kAD7vlshWKZOCnYV6usBZAkCd6mhs0bK2rx7do9uPaNxdhbG33NgCjMyqu0m4zqpQX+66Nf8d26Cnzy846o928Xpd2yA9tLmfNTeV5VHfTixEe/xvCH5jqydUaulDTHyXemv2XJ4C8163enrjtrJpLp516qMGN5Of729lLUNfpM131w+mqc9fw8TPhkeQJG5jwUVyRm1L0/5Al+gWBqIQqBbI9LcSdc4RboUJ8rIChCAODEPqW66wzq2iqmfcQTMVolPj7n6M7o1DJf4awoY5RKaXdeeufHy/HqD5sUy8QfxVOf/A7TfgmnpPmEGaHLBVw6ZSFmrCjHL9uqhDFI2LqvzrJoEMXVvz76VXMdv0afq70HwkKshYFzZTyJpxBIdixj2/5wxMoRAUgrdgXNRUSmIo2+AJZtrdQ2O4rhi2en5mrU499GvyNim0R93Zp7Ku+1/12MT37egRe/2WC67pQfNgIA/rcwPd0yKa5IzKgjKPLvR4EwqRXTAnOy3LpugU5asX/7jxMx46bjcUTHksjnbj0RL10yGCM1UutSBfFzESNX8oVAK/9fbeceCxUHIiNFdY1KtyNR8Pj85qlMz85dj+P/8xWemqNds6XGSkqhOAmShdbaXQdCy3I80YurB6atjPq1TkyQU2WOHWmP7myKk/KzUu5MaoaRKyu1g4lOF3S6t5ljOHxK3PTOUpzx3A94/uv1Ec/FkvYrprc2l/M4beDhiBtPzFqLF77+TbFsd412FkomQXFFYsbjdikm9fJFWEzHE1MH2xXl6gqnHAet2FsV5qBPWbHmc13bFOCUI8pSd8IApVAShZQcKdSqw3IyLVDr+n9QZSUrCutGITdar17usVlrAQBPzrYmrqotiCtFn6umx6LlbSw52y9/tzHq1zoxf9KbYyf7tFU2RI39jRpNNu32B8oExPdp5ViLtYnpSqpEKKf/Wg4AeOlb47vrtm8qNMPzOB3hsXGOXdX1eGrOOjw8Y3Wzs6GnuCKOIIoieTJQKKQFulzA61cOwYuXDEZpUZ4ifU28A3tU15ahx07VXKUr4vv3uF2Y8Me+OLJTMa49oScAaKYFvvXjFqwur3Zk/1pGEOrIlZgS6hNEjFN31dViTgtxkiMLLVFQJasg1plsudS40quPpviROlJbZvhX87vj77f5Pm96e2mcRkJExEuSXTHYHGsH04VU+Z3NNBq84QuF3RtG6Y5+p1dCbJCT5Q5NhGVRUJyfHXre7XLhd4eFU/BcOkVX4jpOprilIy0E63GP24UrR/TAlSN6CMu0742c+uR32PTQmIjldi8g1Qcj74YfVBWiihFJsebKqcaXXp/+mKvrvdhUUatpaCGOxetPzoUznmmBiU8JU/4tTiydmJgYpRmKfzeXKZDdc2e2Tg844izi987uTYXm6HqZLjS3iX8yEM//5vARU1wRRyjJzw7Vx8iaqKUgrtRfJr2olNiTqrn/yHVsmY9/nNobBdkeTaGZY9D7SpKkmFMerUSuxP5ljb7wXarzX4psQqzmjQWbccmx3QzXaTSIOo15+jts3XcQfxEEpzwpTVbkSlGT4cD2UnUOJqZiOjJRNEiZUgi5FP1AJEnCdf9dghZ5WXj03AExb0/TTEFFpv0+puih1cWuAG6O6a3pgvpwNPoCEeUOxD7KSG/yxpEMmBZIHKG0KDf0WL67VyKKK9VvlFs7cKV0HmxmX0Ytrh/ZC5cP76H53Ogjy3Rf50TBqFpIAcBB1TK9yJUVHpq+yvD5/y7YjH9/rG/DunVf0LHus2Vhq3VZR4nmGokUV0ordke82GPfhgOoI2V+hwWPUcqU+NfGilrUJLBvmVU2763DjBXleH/xNsVNhmhpjlbsqYbWzalYJouS4jEPcCoh3sBp8AVw9P2zMOrxb5I4osyjuZ3xFFfEEUqLBXHVdAEqUaUFirg1DDAA5WTdKGpBgs2Hf7pjlOZzO6siG/w6gVpwibV2PpvHK0ujT5eIkbAS0U4LFCNXyflZlxw4ffVGnuyohbIhqgPpj2LKlPo51fb/+vrimPfnNOJvlRMTZ8cjg8Rx7B5nySD1tTlT7/Vj+faqpBqaiHv+bc8BVNf7sLGiNmnjyRTE65R4nUj29SsRUFwRRygtygs9loVUSUG23uq6Xy7lZJ1XIDPaFeXi/jOPjFiuFa1x4tpVZ9Et0ApaTZCjQYyYhQ0tYo9cWUnNMsKRWqQUnYU5XZyvqKtSR65Um5+/YW/M+3Ma8bfKmYBl8zPxSAeUk0V7r5UMzvHmzBWv/oQ/PvN9UvsZKQ4HD41jiDfO7VzL9mSAVTvFFXGEdkXGkSt1ioWiz5WwXIxmiNEHoo/W5MvrQGoSAIw6XNmA2dDQwoIYFnPY9WrGJEnCQ1+stjxGv4a4EqNodiNqoW3FOAGKVhcpzSIs7ivOIsyoz5UTew4YRGpSVF+G2F/bqPitckIM+S1EOTLt5m866A2loYXNyBXMj2lzRL5Z8t8Fm5M2Bj1HUidEsNk2Kg40YNVOZxx+Uw3xN8rOOf/395Y5PpZEQ3FFHKE4L+yNEopcKdIClesraq50ZgnJSudKN7Qm1uoo0ovf/IYVO/R/wLXqdkuLctGyIEexzDAt0IIYFi349dICf9q0H5O++U3zOS38GilqYjRr3e4DWLRpn+XtaW3XKk40vI0mJezpudb6hjmFYgLi8D0QdcQvletTZq/chaPum6VIYTU6bXz+AG7/8Bd8tHSbYvmny3bgi193am4jVaOXqUKyPh27573yu8xjqiapqWI6ZiPONEgX/4p8k0ffPxunPfUd1u6qiX1nCWbi9FX429tLLYlQRVqgya2hZdsqYx1a0qG4Io6g5fJnbGhh/ksabcShuaGlQdXCdKJJJOi20/pELMvP8UQ0KlYbWrhcwR/Yb9buQaOBbbq4vozbBdz/+Up8tVppI23Xxl00EAhFroQr2hfLy3HOpPm2c+ijElcO9GSyYj2ujgRbbcocLZF9rsTIlRNpgcLnpvrap3JE4+EZwe/VL9uqQsuMjvtnv+zA/xZuxc3vhO/MVtY14sb/LcV1by4JNdoUG26mSlpgpkXKYsV+zVX4MfVyaqE0IhKWJyByJfP9uoqY95VoXvx2Az75eQdW6kTelJ+r9ZqrFPnJiwmKK+II+TlhceXWEleqS7MiLVAvcsUrkCW0Pj5RcMgW+UZkafTMytKwolVHrmav2o0Xv92Ay6YstBS5Eo/1pr11eOX7jbjitZ8U69htHq2ouZIkSJKEfbWRAm2dzTuD0aQFKk7ZKE9fK2kpiZ7oqsVcwOGJovg21Z97qogLqxhFNPYeiDwvxUbZjf4A7vjoV5z0WNiprLn8DKba29T6GYqp5kp8nGpvNgVIZuRKUQ/ncPqm1W0c9Ea686YLeg6p6dBGI15QXBFHKMgRI1eRaYHqCZLSil37V5WRK2ucc3TniGWiicOacnNRka1R/5TtcUdEruoaIxsLy2g1HVZj5Qc2lt4igYCEez5biZe+3RDzdv0aIcFGXwDrdtXoih4n7k6nw0VIWSPlbOTqH+//ojh/0+HzELEryj2qou83f9xiaXux9rEjsWG/zxVNSoxIdGN0Eb0Gz05H5Y0wuramIlZ+951Ik09XKK6IIyjSApv+LxbE1YEG5Q+H28JElzVX1ijOy8btqrQ+sebKSrGsVv2T2+WKOE7V9foXgJU7q3Sfk7FyRGOZM/oDwGvzNmk+Z+WcU2xL42Jw1euLcPIT3+JTobeWiBMTKC1reTMS3evSiuGCHdSbWL49fC6l2zXZ7nEXRZJWrzg6y6UOsUwWlelmDg2IOIKek6PTx8no2lbbkF6RK6UINV9HPP+bw20hiiviCPnZYlpg8KsjWm1Xq1LTXFbSAhm5soxaHO2paUDFgaCdqSVxpTE7r6xrtJWi99xXFkwoLFys9tusuRIxmvBovUcjtGquvl27B4C+gHPCRS9g4eIe6d6X2Eivz+GaK7WAUNadpe5MVOvrYXQOakWbxPeu9ZtHQ4vUQXEu2j4szkZ7M42kpgXqPXYkLdDaRtT1zKmOleuUIsVS+B2rqG20lFGTzlBcEUcoyIl0CxRRRzyszHPZ58o66rS+R75cg9FPfIuqg178tueA6euzNNICd9U0OH6HSe9CIwuZ575aryj2t8uPG/VdAT0x1HKp0duSEy5vYumanS3YcVi0i/qj8zvc10n9UVm5cKcCWqlMdscrvnet37xU0Vbxnvymg+AQv5sx9blyZjjEIfQyDpy5cWRtPXUPyVRHef5rv0m9aO20X3Zi9JPfYlMGN2qmuCKOkK/hFiiijgJYcgtknyvLaNUT7a1txPuLt+GnTftNX691PAKS5PiESk+wyPnmj3y5JqbtG0Xp7KYFRiOOJJ2Lia39Riksnp67ProdRoF4HJ3IpY/obeXw9hOJ/XQxk8hVmr3/TCYWN1Bx7eZ6TI0EdCIDV4s27cNFrywImRzppa8lNnKVXjVXliJXJinumWC5rgfFFXGEvBx7p5JHkRao/bPKmivr6NmG3/f5SkuvF8UxEDQjeemSoxNWNJ/MlIilW/bjhEe+wswV5YrlRpErPZy462llG1qHpdEXwDdNaYvxRrzxoXVh/X5dBU598lv8vLXS0vbUF16/4jNIL+yeNuJ3V+s379ftVVhm8XMkzqH1yxdLzZUTN17SnVR53+dMmo8f1u/FlVN/injOaRMGq1vIyJor4XE07rvpDMUVcQQxLdBKrZQ4OdSbvh/ZqTjGUTUfGryxRflaFyqbBf884WSc3Le943cTtVwJAaA2AeJq1c5qjH/3Z2zZW6dYfvXri7F5bx3++sZixXKjPldLtlRqujsp79RFN06t1MJAQFJsW89Z64lZa6PbqQnq/Wk1bha5ePKPWF1eg2veWGRp+5GRK/G59LooG0U8zSbsWr+dn/y8A2c89wNqG9LrznYmEks9TjRGNZmG4ftOQtFVeVU9AKOaodix2mw63azY/TYjV+n2Ox4rFFfEEfKywqdSvTDRL8rN0lrdMC3wy5t+hxt+3wv/PDWysS3RpsEX2w9zK0FcuV1CNNHh653ecU+EDe09n63Eh0u244a3l4aW7a6pDxl/qDFrIvzC15E1TgEH7nqKFyFfQEK9149Rj3+Da/+72OBV8vrKK/l+jX5f0aA+bD6LNVdafZ20UH9WaVNzZdPQQguztECZdJt8ZSQxRJ/0TBOaE0bvO5kOcpLO0bEqjKxv22i91GDtrhpMnbfJ1CDJSj9Gs9YkmdxOguKKOILoVtepZX7osWjHLiL2rFV/v3qXFeGWU3qjKE/7tSQSrSZ+fcqKQo8vHNLF8PWtC8LiKp4F9A06zQbtpgXOuvl3uOZ3hyBHw0LeDDHF6t8fLdddz0xcbVZFwAB1v5ToPkjxjuCWfXUY8/R32FBRiy9X7DJ9rSh63liwGUfdNwtTvt8Y1TgMxxiwJn6yozg+gDOui8nC7vcnoBLTVtYDkuuulkok8o54LNGndLqLHy+HylR92woRoDAU0h9wvddv6XOy+lGmytf5lCe+xV2frsB/F2w2XE+yYLxkVmeYKu85HlBcEcdYcPtJ+OrvI1FSEBZFRXnmkatkNg/MFLREy4l9SkOPS4vyDF+vJ4ITdWzspgVmedy4/Q+H4+S+7WPar5ZAkjETV9pRi/Dj6A0two8/XLIdv+2JdFTSm1iLk/M7Pw4Kx3st1t0ZoX4viporgwmIlgulFkaRq3SzIvfbNOIR36uREDY7H0n8ccqUIlVFBgDc//lKDJ04RzeiHwvGbQoc351l9I6r3nAr6xrR584ZOPfF+ebbTuWDbcAv24z7Vlr5nJS/444MK22guCKOUVaShx5tCxXLdCftvO3qKK1UNVMAMLxnW/znz/3x6uXHaLoJiug9n6jDpBV5E+nXqUTxtzwscfKem2X/58zoczErwNWun7FXcxUISBHpF1bEhN6o49XrKsJwImDtfVqNLEZYsUdpR+800UyM/vyC/oTLTJB/sbw8coUmMr01RbRz0EReS8Tz4aqpi7C7pt7Ga8OPU1knv/L9RuypacCrPzgf8U5VJJ1IuZ4YnLt6NwBg8eb9pttOlWP9+S87MHe1efaDjNmwrRgvmZmD6JUJpKsgFUm6uHruuefQvXt35OXlYejQoVi4cKHh+pWVlRg7diw6dOiA3NxcHHbYYZg+fbpine3bt+Piiy9GmzZtkJ+fj379+mHRImuF1cRZ/jyoEwCgW5sCxXJxTkudFTuXDeuOs4/qhAFdWoaWtSzIxnnHdMGJfUqjbsicqENjdrc/P0fpZij/KGcJ+aV6Qt4Iozup6jGpmxBrXRjsOk2d9+J8jHz0a4W4jOW6IrrNOfm9Ul/sjKzY9wp3vK2mBdrZfqLYtr8OwybOxfNfa1vc+/wBzYbXVaqG6Ub4/AHL7y8a98rmQLwmYpoNn4XHGypq8cC0VZa3l26GFvHIWjD0s3B8b9bRjVw5sm39CE+iovK7q+sx7q2luPK1RZa/L2brKY2X9Lah/Vgmk+d+SRVX77zzDsaPH4+77roLS5YswYABAzB69Gjs3r1bc/3GxkacfPLJ2LRpE95//32sWbMGL7/8Mjp16hRaZ//+/Rg+fDiys7PxxRdfYOXKlXjsscfQqlWrRL0tInDu4C6YeuUQfHT9cMVyZVogiZX8HA8eP38ghnQPn+dlJeFUwMZoxZUDB+ckIT1RD19AMryrpraKl8clCp5inRRUNfJrV+6oxmqDLvHqj0z9WWhNvuwYMUiShEWb92Pb/oOK/lxGEy+zC56YrhdNJE8P9RzAqOZq1srwcbRqv6vevuJmQJLmoY/NXIvy6nr8Z4Z277XzXpyPXdXRp07d9PZSHDtxLvbXWhNj6qhkJk9MUhX16byrOrrIVRpoq7icX0YpxMnIZpGPg7Lmyvw33M5QlcddP/05nm9/f134N8apc08cu97vvNkNhUz+CbM2G4kTjz/+OK6++mpcccUVAIBJkyZh2rRpmDJlCm677baI9adMmYJ9+/Zh3rx5yM4O3qXu3r27Yp2HH34YXbp0wauvvhpa1qNHj/i9CWKI2+3CCYe1i1zOmUFcaCkYU7RtkRt67PWZ/6K6XZGTXPHuZedW+di2/6DtMb106dEY+ehX2LpP/7X+gITv1lXoPl+gilzJiGmBViNXkgQs2bLf1LZc7bynvjaYpXipLyaSJCkmEKJAOSDYbBsJEn9ACr5nne+PmDqWn+1ROHfq0egLIMvtMmyyrH4vPsUERPnc5n3hOrZqy1Ec9fYDOs9o858Zqy2l6NjBLLqwZEtlTNv/+OcdAIAZy3daWj/Zff/iXX8ZbV+4RKIeoVm6td5rMyHtKRpSN/gqCgVhqRN9rsTtqZ5LxucRkCS4LXyX7aQFWjP2SNmDHxeSFrlqbGzE4sWLMWrUqPBg3G6MGjUK8+dr56x/+umnGDZsGMaOHYv27dvjyCOPxIMPPgi/369Y5+ijj8a5556L0tJSHHXUUXj55ZcNx9LQ0IDq6mrFPxJfmBYYH64Y3h3jTuyFObecoFhuJS1Qa6IgHpvv//n7qMbkcbtQkG18H8frlwwF9wFVjx9ZCIhpZ8U23CXPfn6e5h28y6YsDDVeVqc6qNOytEYrXkA2760LRRvqvX78/rFvMPbNJaHnRRElvj+jC7r8Gr1PSjzOednaglSktsGHwffPwiH/mo5lWyux90ADbn1vGRZv3qd6X8rXiVEU9Wi9Qopjgy9gaYISGbmyl0L1/Ne/4ceN+0zXs4MnDj9MWlss0GlXoYaGFslHfS7buUmoV9eTqjh19ovbMfotSGpaoF7kyoFtG0VvkiE4nGrmK/4c6f02mVuxOzKUlCRp4qqiogJ+vx/t2yvdvtq3b4/ycu2i3g0bNuD999+H3+/H9OnTceedd+Kxxx7D/fffr1jnhRdewKGHHoovv/wS1113HW688UZMnTpVdywTJ05ESUlJ6F+XLsa21SR2GLmKDwU5Wfj76N7o2a6FYrkVcaV1TNRLpt04Iqpxmd3h9QcChr26ercvUvwdMrQQtqvnTKmH1oXtm7V7MPn7jdhdU496k75CmuewsMmxby0JNSb+adM+bKyoxbRfd4YmGKJ4O1AfFldGc2gzxyXxImdFXP2wvgI1Tfs+47kfcPdnK/He4m0RpgzqO5NGNVHqc03Pfl8kwo3QYh+teGIUyXOSFhbFlbe52W2lIJHR6+giV83pLr6k8zhVcbo2zihVPFHngXiaWt2l2XriNSHqtEA9QwsL40t1km5oYYdAIIDS0lK89NJLGDx4MM4//3zccccdmDRpkmKdQYMG4cEHH8RRRx2Fv/71r7j66qsV66i5/fbbUVVVFfq3devWRLydZo1bceZRaMWb3mVKcbL0zpPRvjhXsUxTLKiWHdGxBK9ecQzaFeVarnECzMWVLyChwSCF7YIhXTWH5YkiLVDG6OIx5IE5uOp1YxOcUJ9l4a3NWa2sF5VdpQqFCbRsOy9ekGobRXGlPzA5XU5vDa9wwcsWPhs9ca0+Lp8t26G5npFboPjUzqqDmDpf2R/F6LjqbV9MC0zWRFRtYGIHO+lEVm80qd0CM62FRTroDXXqosVOA8HX2qjHTAnicAPU0NAiRazYrfbws7xti2mBiXr7Tv2e6kX7FOvAeJ3M+gVTkrSaq7Zt28Lj8WDXLmUR+65du1BWVqb5mg4dOiA7OxseT/iO7OGHH47y8nI0NjYiJycHHTp0QN++fRWvO/zww/HBBx/ojiU3Nxe5ubm6zxPnEe9YMIgVfy4+thsOev0Y3rMtDm3fAgU5WdhToyzG10wL1NjWib1LsfBfJ+GW95bhwyXbLe3fLArgD0gREY5sjyuUHta6MAfFeVmoboqyyBPSbEGl241cxVrjoXXeajnF1TX6FBPj/bWNaJGbpbiI1wiRq18N+ouENIfOBdLnD+CZOeuwcNM+xefp9Qc0nfus1oxEpAUKC8a/uwyXDeuGC4Z0xfh3lkW8NhiRNBa+kdGv5KdQxRK5CkjWJ95WnTzVNYBqdlfXo7TYuJ9dJpLI80P9tbOXFhh+3JwiVyLGaYHJmwjoHRsnjpJVQ4tEYTW92E7NlV7kym5rkkwiaZGrnJwcDB48GHPmzAktCwQCmDNnDoYNG6b5muHDh2P9+vUICBeZtWvXokOHDsjJyQmts2aN0t1p7dq16NatWxzeBYkWpgUmlmyPG9eP7IUBXVqiICcoQtQ/dlpzSb3D5HK5LPcwAsyjAD6/FJEWKJ4j2R4XcgT3O60+V3ZqrgBgY0Vkc157WDuHT3niW5wnNJvcVxu07xbv5NUKNVe3vv+L7rbMIlcBCXhs1lp8t65C0SBZr4+YVXGlnhSIF+hVO6tx24e/AgDW7zkQ8VoraYHqN5QKboGx1FzpTWC00mCsWqyb9bka97+llrZDoidCXEVpaJEOxKfmyqGNOoQU+l8QCmLKs9732ManY2TFLtnI9N22vw6PfLnalkOljDhaqyLH3Ipd+zNTrmN9e5lGUtMCx48fj5dffhlTp07FqlWrcN1116G2tjbkHnjppZfi9ttvD61/3XXXYd++ffjb3/6GtWvXYtq0aXjwwQcxduzY0Do333wzFixYgAcffBDr16/HW2+9hZdeekmxDkk+CkOL5A2DCNhxvgKgEDsylxyrfRPDbKLqCwQinO2U4sqtEHPyJFVhaGEzLTAWG+3g+Kytp3ZY3NfUG0m821fXaFzfJSO/xu4dTz0rfqsCIiJtT2d7WiLaqJYuvH3l3+L2k3WX3+73QcTOmK02fjaLXC2M0tBj9spdWLBhb1SvTQUSef1QH1c7p4jVyFWqTEKduv9pueYqmWmBwsCcNuVUCAzVJ2DHXOLiV37Ec1/9hmua6nijxanzy1ptmnF0K5OjWUm1Yj///POxZ88eTJgwAeXl5Rg4cCBmzJgRMrnYsmUL3ELaT5cuXfDll1/i5ptvRv/+/dGpUyf87W9/wz//+c/QOscccww++ugj3H777bj33nvRo0cPPPnkk7jooosS/v6IPh5FWiDlVTI4qU8p5qzejb/+7hAAemmB+scmyx0prnqVKo00QrVRJrOQB6evxuEdihXLxJfkeNzIFiNXGtu1UwPmBPIY3C6XrYvkvgORkSurk3F5fi2vPurwUsxepd0XUEQvcmX1zrtRnyvF9jS+y1bs4NWTDq8NQ4t4NeJMmLiKMnLlxM/mzqqDodrCTQ+NiX2DMRDtnC+Z8zNbaYEGEQyRTJ5wpopwlJGPnl7qnhM3dhTbU/0U2tn+pqZMhJ+3VsY0HufSAsVt6mxDsY6WuEqt88FJkiquAGDcuHEYN26c5nNff/11xLJhw4ZhwYIFhtv84x//iD/+8Y9ODI/EiVaF4X5MPdoWJHEkzZenLjwKCzfuxYhewT5kmm6BBnOH7KzIJ9U/lnJNlJWJqthIFwCyPG4AwaiH2+1SREXkR6JILy2KT71JUW4WalRW8ED4wtEiN0uz1kqPOm+koYXVHkahtMCm1ft2KLYkrvS2b/Xapj6utTqRtiyNQqOoIlcWDS0Wb96HDiX5ptuPhtjElfZyrcml1ZqrF7/dgGN7ttFNf41GbInRW3UfNie2n2moD58de3xlDzyjfaTGhNOpGiirdTfJOL3M0gKdOBTKyJX6ucTXJDm1Hyt9rszs2imuCHGYPmVFeOMvQ9CpZT4OUdmGk8TQIjcLv+8TboWgNZnUMkGQydV4Tv37KU+2ozEHKMzxKESLOBZZCNbUh59vVWgvLdAqPUtbaN4t3LCnFn9+YZ4tYQWE+0CJFxu/RZvtUOSq6e8si3Vvjb4A6r1+5Ga5dRsZG2H1Gqh1DkXlFmjB0GLhxn2KWjanEd+Lzx9QfNZmn5uVGoTwtq19uIs378cdHy3HMxcepfl8NJNT8XP3BSSFw6Sa1eU1pgIs01FHWC3VE4ZeLE7a9Y+5+hxJ90iWMi1Q/80k1S1QRwRY+ejNvxP6kTAjswsnURwDy17sxk+Llywrhhba4sraUNKRtLJiJ5mDy+XC8Ye2o7BKIbQiVxcd2xWHtCvEdSN7RjynJbzUP9xytEmMOl00VGmrrkehqv+PONmVh1rRZA4BAIe0bYGWBc4LrFyN2jIAmL9hLxZv3m97e3L9k3hxspwaFopcBdfXihRpsXlvLY6460vc+PbPiuVW0xmt3mHUrrmyb2gxf8PeUCRTa9eBgITv1u2xNKZoEaOi6sifWbRJ/T2QJAlXvLoQ9zY1qBaxeuwB4Js1+lHKaCYq4jCtiLxPfta26neCaN079wu/AU6i9c1Sn4tWorKh1xpsR8RoAp5IHBM7ks7jFMWuq6PZ9y5g8P4V5hlx/GysOPsZvcbseb3fMHGpprjKYHVFcUUIAaDuPRakOC8bc28ZiX+e2ifiuWwd0SEi3+0XhVsLi7VRBSpxJUYO5JSVvQfCaU05WW4suP0kPHDWkZa2bxWnBVsociVenCxGL+QLmvxSq4YUU+dvgj8g4bNlOxTNkS1HzCxckCVJ0hToz8xdh5GPfIUdlQc1XqW9/V+2VeG0p76DJEn4YMm2iPX9khT3SacYbW30B7CnpgEVTeebmSBSP726vAZfrdEWg1YNLdRoHflZK3dh895azFq5S+NZLcQJUuQ41CLxpnd+th2pjTfV9b6YDTne+nEL/vXRr6aTPfWzerWMmq9VpIfp70d9XicrdcopbWU19S1VrNjF32UrH73Z8TE67krb9/gdZ/GrbVXPfLG83DDKZaXPlZkAy+S0QIorQggA+9bTWpGrnipDi9KiYP84cdUWOdbEVWGOR/G3ouaqaXtj+ncEgJAZRl62J6qLtJFVfMv8HN3nokGOeijTArUvMmqDkOp6HzZW1Nq+EHt94fUH3zcr1OPM6rzeygV5Y0WtZiRtyZZKbNpbhwmfrNB9rd419n8Lt2oKBX9AivuFWTwl6hp9OOaB2Tj6/tnw+gNo8BpHLCZ8slzxt1EaodWaK0Bp/qO1xQmfLMcJj3yNq19fhK8MolxaaAl8rY/4mjeMm2sng2fnro/6tfVeP/710a9468ct+HlbpeG66nPOTlqg1doj9Xc73aef6rTADRrtGoBkNxHWS93T/vTFsdqJ8KiPu1KgmA4zasQxqPtbGvHlCv2bNKII1f19M4kCZnDgiuKKEBLEbl3UER3D7n6fjB2OiWf3w8jD2inWketDRGdBy5ErlQjTMrQ4vX8HfHDdMLx7zbGh57Qs4s0wsnF3OnLV2DSJvfPj8ARcne4n88g5/RV///mFeTjx0a+xdldwgmJ1QuIVrty1jX58/kswvct6rVdwXEaf7e8f+wYe4Tir1/11e6X+9nUmKJ8t005DC4or3c2FONjox6Yo+5mJ298tGD/UNvhw+as/Gb7281924vFZa7F0i3naqJ20QDPESY6VaI7fJDVV67gs2BCd5bsWTtWZyBGkukYfKuvspQnaSu1VDXd/bSPu+3wlllg4zsqeP9bWC66bpMiVU1bsqvf9+8e+iev+okEvCmPlq2l2eNTvX8SanXnsiJs+87kfLL9ObTIlYmXs4lItUyVGrgghGY/dyNWxh7TBUxcMxOc3jMCALi1x4ZCuEYW9h7YvAqAUbupaKj1a5CojV1qGFi6XC4O7tUaR4KB2+oAOGN6rDW4d3dvyeylU7UukxOm0wKYZ7Xxh8itHDdQXIHV0MNpr0dItlYq/S5rEpPXIVXDHZmlTYuCqSHWcjfqK6W11y746zeU/bdpnadI55pnvMPLRry2JHDXiexUjFC648Ov2KtPXPz1nHc56fp7pelZTQtVofVvFwyNGK/X3HX5fmmmB0QzMBkaCw+cP4Kqpi/DU7HWm25HrGI+5fzYG3jtLYXRjhpiu6jWJRKk/jx1V9Zj8/UacbeE4i681mlQms+YqHkJOYUFvsF4y0gLl96uoDXI4LdBIhDjtTGhlDHYwajVgZlah3q/WjTzWXBFCMp5orKfPGNgJR3YqMV1PjDq1MBBXh7QrDD1WizAx5cxIB+ZmefDmVcdi7Im9TMclU5CtPyan0wK16jTkqIF6gmvk1ghEPyGRxZVZY1oZ+RpoVgwdTYQS0J/Ubdep03p4xhpLE4YNe4JRq2m/7LQ8FhnxvYrGBXZ6mlnB6jEAzO/ui59jo9/cbEFsLq0l8uJ9Z9loMv/Vmj2YvWoXnpi91nQ7jb4AJEkKtQiQI7tWCCg+M3tGJXYQX2u0FSmGXkixIu7Krivk4s37MfGLVYqaTkBlQZ+ik2mlUAgvd8LQQrEfg9fG8zhHL66Mthl+rO8WGH6sHRmPalhpAcUVIQSAvYaYsWxbr08PANx1+hGhx38Z0QMAcErfoF28OHG3Kiq++vtIS+vl5+hHrorzne1Y4fUHIiZp8p0/deTKqhtgtFi1YlcbaeghCvRCjdo6PXc1uxfZ0qLcmC7Mv+05gH0mLnPiRLBO6OtlRwxZwUqfMqsohIKFeiBRUGlNfvSO9zs/bbE/OA2MjuFBk7o2Ea8/oIgu2plMipNp8TPT+jl0ai5obMWuilw5tE8rxHLj4M8vzMOL32zA81//pnzC4jaTW3MVJmAzmmQncqXeoNMNi/XHEN3rjEoFFOmTFtwCtdbRfc8ZILoorgghAICrfxcUM6MOb2+ypn3EAEybFvqRoE4t87DkzpPx692n4JB2LbD8ntF48ZLBAFQ1VxYvxD3aFqJjiXlz4QIDcVVW7Gxz4kZ/IELU+ALBZVtVaXDZWhaOAv06R0YNTz2iDO2Lcw1fJ4s4p/tciWJQK3L10jcbIEkSdlQeVN7Jt3kxzXK7sHmvdsqgFuLmt+ytw0mPfYNB980yfI1fIa58mssTTWWdFz9t0q952l8XToez0pjaq4hcabkFar/unx/8GlWqZcT2LaaMmREhrmwcI78NQWpnAlzv9WPiF6uwqOl4GdXeiERGNxJ3vjlxbq/fXaP4W9xiqpbY6NmvWzEOUkca1Rg1jxb//m1PLZZbSDeOBq3WELGibBCst47ZzZsUPSEcgOKKEAIAOOuozphzywl44eJBMW1n2CFtAAB/7N8htEyMXLUp1BZXD57VD71Ki9C6MCdUQ9UiNyuUnmI1LVCNlfmCobgqycOyCadY3l8HEzHn9UsR6Uc+v4Qb/rcEf3zme8v7AYBsjwtPXTBQsSwny206iZm1chfeX7zNduTKDPE452dHfqZv/7QVz3/9G457aC6e//o3VDWJAbsTyDmrd2P2Kqt240oWbTY2ZFiwYS/W7apRTLoP1IfFVTQ1Uk5OkG9+52cA5mlbZilu6nU0Jz8Gk8udVfWm2zfDqY9l0946RVTUirCUEYWYeVqg9TG99O0GvPjNBpwzKdjo2qp5QcRzCZx/KtMCnd9mPO3GY0NIC3Tcil3SfAxEilm7v/9WUY/Q6u++/Hu+ZW9dRIq2pd5ZCgEWuU4yb1TFG4orQkiInu1amNb5mDHp4sF49NwBeOjPYac78UdU3b9K5v9MmgvXCBPcLJOIjoiVC3q+gT18u6JcW6YW+TkevHr5MbrPe32BCLMBX0DC9F/LI9c1TUFzKQRNy4Js/P2U3qbv+IMl2/D395ZZFijRNBHWchZs2yIHj3y5BgDwyJdrMPC+mfhhfUVCp1xG1/Mte+twwUsLcPIT3yom3WJvp2gmBE46Am7br98vTMRuWuD90yIbHBsNOyfG3wnA2UjGj4KLoZ2UQvF4ip/ZwUY/VpdXRx1hXb9bWfelSJEy2I76uyb/va+2EdU2jDqiwYl6QmNHPP3X2a3xchI9t0Bn0gK1H1t5rVOoI7lWf49cLuBAgw+/e+QrDH9orm4ao35aoHHkKoO1FcUVIcRZSgqycc7gzgrjCvGHNdpJmZgyYcd8w8oPeIlOXVV+tge5WZERmN5NLoiaSMCJfUrx3rXDNJ9u9Aci7pDrTdg7t8pHXrb+5+V2AQM6twz9veTfJ6NrmwLLk0Cr9T5WL4IeE3Gl/iwlCbh/2qqEpodo7cvnD2DRpn1YuTN8jokTzWpB2J/74nzb+0zGHVor4kpMC/xhfaR1u9FxyTU4L60iTr4WbtyHfbWNYQc3m+fEe4vDzabFNE4z9Awtahv9OPXJ7zB3dXQ1cerRK9MC9d9bROBKCtr/D7pvFvrfPTOqsVhF/CyiNcsxcjtMtTQwSfU/oIpcWbjtY/7V1k99TdTHoR6j9cgVUF4VvpmjJxT1RLl4b1Brn7RiJ4SQGBDFVXaUJg3nHN0ZAHByX3s1YeLvt5YoGtS1Jc4d3EXzta01Uhg9bhfeEfpq6XFM99aay70a4kqvkWxulgdL7zwFfcq0xZzL5ULXNgWYcdPxWPivk2z3KpMZ06+D4fPRTIq0at20LsKSJCVkkvHD+gp8uaJcc19Pzl6HcybNxy3vLgstEw9JlVDLZKcJJxA8ttHarceClebEZuvEO3Kl3v6g+2ZhyINz8NHSbcr1LEwGxfEcbIw9ciXz0dLtocd2vgcRdS7iJNtgM5GRHyjqC+MpUJxw8zPKajTaehL9LHSb+ep9HIq6LBuRK/W6iRIX6v1ajVy5XS5VbZXdyJX2a7W2ofe6dIXiihASd8QeF9Gmf9w86jBMunhwRI2ROeGf6reuHqp4/SFtC/Hh9cM1RRQAFGmYMnhcLuRp1BNF7k2bRl8gop+O0Z3E/ByPrpuh/En2KStGqcJ4w97lyUzw/rRpv6XtzFwZTDM84bB26NqmMOJ5rffpC0hxmWSo07kueuVHXPPGYpRXh2uF5PG89N0GAAhZeQNKgwcxLdAu9V5/XN6f2bfIWuRKHWUwmBmriFbIG+4PQfF68zvLFMuspKuJw6lr9KPqoBffr6swvUsvbvv7dRURz4uul3aOolGUwlafK9WWjN6PJEm2enypEbcdbZZe5Pu2LkSShV66m954rQiw8Da0HwPOt3XQQz1GLfMaPfQElZU+V+I6TAskhBCHsVNgrkdetgenHlmGAoP6KC2O69kWQNBIo02LXJwxsFPoObm+TK+xsVb9mdsN5GqkvI3s3Q4A8LeTDjUcj9cfwNKtSrFiNgHUa/CsNwESNzeoa8vQY735sMdGDZsVxvTroPkZaU0qqw5643KR9elMCkRxJUdutD5f0X0uNnEViLrm6tzBnXHhEONaRD2sGFqoI1dGRetqnEh1tLoFK/sSrfX31zXi/Bfn4+LJP+LNHzcbvk686z5HIwVQvLFhSyQbrGp0Ppg1ETZ67T2frUS/u2fixw2RKZ5qvl9Xgbd+VFrqGzV1topWWqOM0dhTxYpdKSa017dqTqJ+Xi2UEyU2jZoXGxGMXGlHXBUpf3oiVBH1ivw92lRRi40VtZbGkm5QXBFC4k4yXYHuO/NI/OPU3vh47PCI57Kzglf0Yp2Gt1p35z0ul2b07T9/7o9vbz0RZx7VKeI5Ea9firgzv8HkAqMXJdDrTSZetEUx2rJAO0JnNcOra+sCS+u53drRvV+2RVoN76lpwHfr9lgbAIAhPbTTLdX884NfQo/1Ur/kyV6WxucrNkOdb2Gyqke91685sbBCmxa56NI6P6rX2q25AoARD38Vsg4HjMWPIylkBkO0OimX2SuIq2fmrsfq8qAl+OfLjBtIm2lQ0UnUnrZSpYAJ78EoHdPIEELrb5HX5m0CgJBpjBEXT/4R//roVyzbWqm57eijrfqRN6P02GRoK/kt6kcV9SIy4cfXvbkEBxr0a/yMIleJuiyqj6XVmz33fr5SEc3Vcwh89YdN+NdHvwIAquu9+Pt7y5peZxy5evunrTjx0a9tpfGmCxRXhJC4o/5hnXzZ0RjSozWuHN4j7vsuyc/G9SN7oYuGMJBdB7N01IWWptEVOu5g/ZMZVia9avQiV1YQ77y31HE9tBq5MrKsF8lyuzQjV3p88vMOy+vqWfmr+XBJuFZGnAiIZgdyeqbWMW2I4jhp0eDzR11z5XFrCz/APOpjreYqciuvNk3QAZPIlRPOchZjV+qbM1p3/Ct0auHyTM5Zs/ehEFeGayoxyrA0Oh+0Ij9i42orE2MrUUuZnQrDgthT+KKNXCUT8TwUzzW9j0D8nJZtrcQzc9fpb9vALdHKDYpXvtuAm95earqeERHpiDaOw8QvVodfZ3B+yFHQx2euxfuLt+HiyT8q9us3OOfNXDCt/JalGvbyawghJArUd+5POrw9Tjq8Pbz+ADq3ysdxvdokZVxmRflaE1s9p8IWOqmFaqxeKD4RIm16kRM9zSVexkryw4KqVUEOgMgomZXI1YybjsfYN5eYr4igWLEjruygl8JphFhjIFrey1b3Wse03oadtxH13kDUUQCPy6XZdiBoAmK8zWjSAgHlhG9npX4vK39AQl2jDx63K8IFsrrei+m/7MSpR5bpRksB4zv3ehNeQHvSW6MTPcjPdqOu0YfKOi86toyMAppNcMUIrNFH/vWa3RjZu1R3XfFvbyCAg41+7KlpiLghE5HCJUn407M/hP+2INSjuYEDWEuJM0P9MmXKnXJcOVnu0FiTacUuDtLIOl1jdQDAdoP2CMo4WPCveq8f63YdsCRy7p+2ynQdM9TnlN41yOw3RYw0aw09EJAUrSLEdWIR1o9+uQa3/+HwqF+fDBi5IoTEHb2aq2yPG1eO6IE+ZcUJHlHT/rOML+haaXdyFOnW0b0Vy41MLkSsTHr7dSrBgC4tTdfTTwsMPxYjPS3ztSNXZn3DurcpQJ+yYrRpkWs6JkBfFDiBVnNiMw56tT9z+bzU+hzrHYpcLdmyP+qJhcftVjTPlglI4UnbqUeUab42mrTA4LbDE8DTn9Vvalrv9WPAPTPR+98zsLq8WvHcP977Bbd9+CuuNxHjRpM5cR7uU03K7Xya+dkenP38PBz30Fxs0ki/NYtcKc8N/XUvf/Un1RiN0+NOe+pb/O6Rr/DLtkrFeuqJsLreT30u7alpwDNz1mGXUEtoT1yF359V0w0jIlwSxQm26jrgRGqpE4ijsGRoYVGsRG4v+P+lkxfi9Ge/x/uLt+m8ylm0Ilda783skJuljfoCkiLbQzzn99c1RqwvjseIKT9sNB5YCkJxRQiJO6naid1MAIgRDXkSe/XvDgEAjD2xFw7vYF8UWpn4GPW2ElP79C6G4oVTjKjpRRH0RJqMPAF99JwBhuvJeNzORX7UdG5lvwZJa1INhCNaWpE7sRYlFiZ8sgJrm+p/7BJMC4wcnC8QCB37Y3Rq0Op1BKWI1k0P+asqGkRo8fistaHXn/rkd4rnZqwIRgfn/WZcq2b0syD+ZlhJC9QjP8cTqr+a9mtk/ZXZBD/aaI5R5MofkLCpyV5d3TxcvY9pv+xUPR9cYd2uGgx/aC6OeWA2Hpu1FpdNWRhax05aoPjVj0fkSlGno9qoKGxX7azG1HmbkiK4lEYN5p+BernRb7q4bdm8YWFTXeOHgs1/PFELoY0VtTjmgTl47qv1husZbUfrs/EFAorzSdycUeq3Wdq02fUpFaG4IoTEnVTNtRfdAPt3Lol4XhRXT104EB+PHY6/Hn9IaFmlwd04PeosFO/qWcMDQZtzmVqdZqnipy02ey3Ri1yZWLEP6toKANC1TQF+J+xfD4/bjew4pAUW5nhw8bHd0K9T5LEy4tftkUYaQPiOc7yibDJfrbFu2CHidrs0j41fsK/XatYMWOv1VFMfef7Ik0uz9NW1uw5ovs4ORjVXPgNxZWdXYkRZ6/tqxapd/izMRJ1eRODJ2WsVrmjiZxv5GRjvQ/5c/vHBLwp3x9WCgDe7gSMeq2/W7gmdK0Y1NVYxepnXIL1zZ1U97vp0RYTg+G7dHqzbFd3NiWiw0kRY/dkYueGKguT9xduw3+SmRTxQn+IPfbEaFQcaIoxPzL5XZudHMHIV/r2yGv30mhj+6NWdpjIUV4SQuGOnr0YiyRHSAqdeMSTiefFCkZvlwcAuLRXmBxccE7TJPsGC4Hj03GDUx8hZSkYtrvoKETIxLU63p41wTRPryvTSII3uDP5pQEdM+GPf0N9WjqXHDYzo1dZ0PTtcfXwPLJ1wCgpzs3DZcd0d2WZ5VdAEwUhbDdFpBm2HHZX6NRlGBNMrI4+NLxBuvHxEx2L8aUDHiHUa/QHTY1V1MHKiJ0+IrNwEEDkgCH3LkyGDuZeYChgRubKRGCie25V1kd8Xs7TAJZv3o8+dM/DcV+tN9zrm6e9w7qT5wZo4YfmTs9fh02XhO/dGd+pNJ7hNrzUSzw2+AFbuqMbwh+ZGNGQGlO/5rR+3YPy7PwPQ7/cUCEi48+PleG/RVuPBwbjPlRXXzNU7wymm63bV4JLJC3HyE9+avi4WxKOlGKJe5Ep1kIwihepNrN9zQHO9eKIWQnpmPWZiyCxt1O+XoooymUWu9OqcUxmKK0JI3EnVtEAxctVKI1pk9qN+/Yk9MfXKIXj+okGm+xrW07ppRytV+t4LF4e373a70KesCG4XcLTOxF/8tHsL9WzZOirCaDJ835lHKmqtrBhyuF0ueNwuXDUiNjfImTf/LrxNtysUpdGL1tjl4sk/AjB2YzSry7PC3ijvVnvcLk0nyzfmbw5FLdwuF56+8CiMPbFnxHoHhdTMd3/aijFPf6cQelr9u+Sv6kGbaZ3Vwra0+sNpYfSzIEYD1JFvO0GVWuFmhpYrmVnEbebKXfAHJDzy5RrT/a4ur8Gizfuxv85rEsEJf4de/GYDvhDSFc0muLLoNFrP6w9g/Ls/Y3vlwYi2D0DkZPaL5cHURPGrLX4sf3vnZ7yxYDNuff8XmGGn5koL8eaVGB2N1qTDCoqUTZPUN63lCzfu014RkZ+HnZsWTqVIRrgUqsb07Nx1eP7r9bZqrrQuA16DtEAjzK4pFFeEEKLBeUd3AQAc071VkkcSZNThQVevy00iIGY/6tkeN044rJ0lBzszZ0IRdeRKrJtyu4BpNx6PX+8ejeI87TQ/8YI+rGcbTDy7H967dpjuhEzPXl7en4iVhtBymp3HJN3QjMPaF6G0KCjsTukbNm7IiXG7aozutloRCr3bFzk5nBAet3bkSkznkZ/WstMXoxv/+OAXrNhRjYcEa2WtSI58jtjtPVOlEFfGx2fL3jpM+GQ5tuyr013noBAJO2/SfEXDWzviSiyk1zp35cl0Jw0nQTVWU+WC7nEGKY+qcVwnGH+YBXd21zTg7Od/iEjLFGn0BQxrHtUGIaF9a0Su1u8+gM+WWW+VELnN8GMrN9k+FtICxYiSaNjhNOKoFFbsOsdQ63dUr0ZT/VEf1EnlVrO6vBr7okg71xyDQZ+rfbWNeHTmWvxnxhrUNBhboiudFDW+S1GmBZqVDTjd5D4RpN+ICSFpx+XHdce71wzDaxqpd8ngpUuOxqJ/j8JRXY3FXiz9pdTEIq7E+iVJCk66jQSd+lJ14ZCuOKZ7a12TA6PIldoiWW9iJiJfC/UiZXaYfcsJmHHT8RjcLXysrEZGrGIkLq3cPL7vzCMVf5cW5eLobrHfSNATVyKuJrc3rXNV6y65GJGq1Ixc6YurLLdLt97t3s9Whib0OVnGjo7nvjgPr8/fHEpH0+JAQ3j/e2sbQ01KAXtpgfsFASnfIf9o6TYMf2guVuyoCt2BL9JpJC5ida/bK+sMBeCnGmJF/uzM3tsFLy3Aki2VhuuYTVb1RI5WjyexD5YVIvt7hReoa6602F3TEGpcK9YnlcdTXOkcrEsmL8Skb36ztI3lO7TrOtVbthK5WrplP0598jsc99BcS/s2Qy1yxPcrinCzyGJAcX5o1Fz5VW6BUUau1Nt2+Oc+IaThkAkh6Ybb7cKQHq2j6lEUD9xuF9pasBWPNR1BFEl20svUzX5FkWLleqV3Uav3aV/YjVL4IiJXvsiNqyMV8kTf7uenNXEvzsuOsOp3Ki1QxkjAeC2kI6lf7nKZm4RYweN2mQpJWVNp7a+u0Y85q3Zh1OPfhJbJ71WSJFRpRK5+WL8XlXWNWLxlf8RzP/7rJM30WQD4ceM+vPTtBgDmkcVd1cFat20G/YEOGNxFtxO5qlREroLH8uZ3ljWlzP0cmjBaaZBtdb+f/bITc1bvtj5IIGTL7VT6m1HfKD3xpeWa54K98zjCgl4RubL23mRr/3214XMg2rpFKxgdVjHSK6MVkdFrEaFe14q4mrMqeO44dS4YNRE2cuVUY+YWOGN5uSJyZfVrapYWGG/DoXiQfiMmhJAEYRTRsMLUK4bgyE7FePOqoYaT5LeuGoqy4rzQ34U5ShEqTpytpCbdcFIvAMDZgzopltfrXNg9bhf+LZhWiKgnV1rOTt3aFEZsD7DeWFnm03HDzVdCHCJXBhNRKzVmLpdLYXzhgsuWANDD01S7ZmldrUbIPj/+MnUR1u8Op5DJ53R1vS9UiH/8oUrzkVOe+BYvfB15x75Ni1wY6aY1Ta5uVp0iWxVop7UCwAENJ0MgaKhixyZfjFyp78wf9PpDaYEFORYiVxYPqto+3Qr//ng5tuytw1nPz7P9Wi20DtPBRj+ufWMx3tUxprBSb2TGD+v3YvQT36KuKf1N3IyVmiuRfbUNwuM4uuzZfK9an021RhQYiBQ2dRbSAu1EZq1glBaoaG5t8ltnlhb4wPRViuik5bTApvNid029pgkPa64IISSDiDX40K9zCT6/4XgM79XWMDpyXK+2+LvQlLiFKkVJfK2Vm7/XndAT024cgf/8ub9iuZ5JQY+2QXF0flNtnIhad2hdgK87QWmmIF8MLxzaFf06leCcwZ1Nxzy4WyvDu+1mY4gFoyiTlVQmj9uFly87OvS3U9mkelbsinXkKKFWI2SN4y2fS781uZaVFedF9D/bXdMQ8ToZo4lOltuF6nov9h4IT4TfWLBZsY54N769cENBjZ6r5oPTV+P/XvlR93VqREML9XkTCIQjNFaagMfbluethVvMV4qBqfM3YcaKcvxnxhrN5/2qiXHQ9VDSXUePNbtq8PHSYOqj0i3Q2icoT8pFIxit+kCnsCtmtERDtc7NALUg12p/IOL0b1twDMq/xfQ+Mc3brJ7WLHIFBN01wzu2Nj5fIOhuOeSBOThn0vyI52nFTgghGUSskSsRM+EgptapIz4um0XCLpcLR3QsiXCa0xNXxx4SdDJ8+Jz+IQMJPbTuPv9pYEecOTBsBy5Grj67YQTGn3yY6Zjl9y+bQxxn4K7otPmk0ZHRSwsUa6rcLmUPMafOmqAVu7W0QC3R06BRYyevt77JEOHQ9i0M6wHVKZ9GUT6P24WB98xUCKM7P16ODxZvw0WvLEBVnVezrkeL2au00+qm/LAxYpnR+SWe8+rJ4/bKg6G7+E6mBUaLmRFItDT6Ajj9me81U9xE1Fbs57+0AJdMXqhYx+rkX/6dUkRGLH5x5dfsU4ir+EWu7B5XrfXFthji56heVcuhU+ShL1Y7fp6prxm1jdrfCdPIlSi+dY6l2HvNqmj1+qVQWuzPGlFpRq4IISSDcNLQwgxx0mqUThfLdVf9bv495nA8eu4ApTAQVjqyUzFyVSleWnc3s9wuHH9ouNeXegJu5eKY22SCMPXKIbh1dG88c+FRuuuO6NU2IuUxFozu2A7q1jJi2ezxv8NJh7cP/a1+f1YjcFqMO7FX6HGWxzxyZSiuNGrs5LvAslNf9zaFhjVsuSpzCrPIldac65b3luGH9Xvx8JerFXfKrZijWOHE3qW6z5mlPcnmEpbEVZxjV/GqLVm1s1q3kbaIKHzf+nGLpsW4VXElnyfiZ+YPNe02PqcDGuJqfzwjVyaH9Zu1yibgWsKi+qAPu6vr8djMNej97xnofts0vPXjlghhs7taPyoMAJO/3+j4WWb0/sRIcqxpgWqsOMsCwRt2Rj+Z0fTOSjYUV4QQokM875gd17MNTjuyDB9efxwA5UXOyPjDah67FneMUdZVXXX8IREpe+LmP75+eIRQ0LoAu1wuHCbYkas/NysXR3mCX1aSh7En9lL01lLjcbvw+HkDdZ9vZxJ9EwkEpNCkUm3N/9QFA3F6/8gGvb1KixQOVlr1OtEepTH9O4Qeu10uU4EfcgvUqrnSjFwFBy5Hl4rzsyIEtEhhrlJ0GEVzzb4va8trNAvoi/OyIhwX7SAKULUZjIiRi16+BXElvlxs7O0UTv7ciO/U6u+Y+P70PiurE2Z5l5LGNs3GIwsyReTKJOITC2bv6LIpyuid1kdT0+DF+HeX4Zm560O1jP/66NcIYbOrxtz1MN6RKxGxBsyJtEARq0Lc6w8YRvvTUFtRXBFCiB5OpgWKZHtcmHL5MXjh4sEY1GQHLzr5GU12Y7nw9io1TgFTo9XAVqvgGAiml8mo0w/1JlO/7xOOONgZlxlGRgkA0EZwvPMGAiGTjlOPDPfSatsiB2cM7KT5GQBKwah2CrM7GTjrqHAUToxaetwu023JH61WNECr5up/C7fgwpcWhOpZCnKMxdXZgzrjyE7FuHJ40E3SSOyZiejdNQ2qNKQmRzqXC60LtF0IRfQMJcR0ug4l+v2qjNzX9NzelAMI/vfDbb/HgC4tzde3iZPprmIanVHPK+X+rUQjrE2Yn56zHnd/ukJTsJlFriQpeKzFHmXxTQu098FrRTBr6n34fn1FxHK7kavcLHccDC30nxNTePV+28PbEVN6zcdo1e3Q6w8wckUIIc2Fcy0YMUTDwC4tIwroxfoYo7QyuxMBNWbXKbOt69VN5GV7cOXwHhjao3WEpbqWuOrUMh+vXBo2gXDSXt3M+e1IYXy7qxuwYU8tgOAk/c4/9kVethsvNY1NbyIoTjRiFVfi5EGMWqqbcmohP611I0BvUj1/w95QY9jCHI/hZ98yPxuf33A8JpwejHrGEs3dXVOPNeU1ob8bmiZfLhfQt6N5JEgvmiI2Ge1Qom+SYZSGaCctMF5TvSdmr7W0XtfWBabriGl0erWWaqyKKyu/QdsrD+K1eZuwYU/YqdJvNXIlSaiu9ymEuJkRRCzY/UXVOg39AUnh+Apo3yTbbmIpn5ftcdw5xei4KuqvzKzYha+PFXMSq+LKrC+bVffRVCL9RkwIIXGmbYsczLvt96ZNhqNFuz7GaqF4bPs2m6ybzZuG9mit+9yE0/vinWuGRVila73fd645ViEInIxcmVnAi2Lo3x8vDz3OcrvxlxE9sPzu0aGIot5EUJw45GYrx263N5AyxTA8NiuTE7kmStyjHBHcc8D4LjkAFORmGX72atFhdP6YnZv13gAunhx2+qtoGp/b5UI3C4JB7/MQBbCRuDJKe7LkFtj08mTfSO/ettB8JQG95uFqrEyYl2+vxqD7ZuGV7zZY2ma1YPTwyJdBl0K9aLCMJCkNIgDnej7p7c/e+pEv8PkllKnOPZfLfhp3YY4nDjVX+lvcXFEbemzW029DRVgomwkiwHqU0+cPKG4oqrecTUMLQghJf3KzPOjYUj+9KFa0CtfPGdwZ+dkeRc2NFrHUXAFWJobG23/8vIEYe2JPw3XUaKWSqQXYCFWvpVhQ1wmpyRPE0PwNe0OP5dodcfKnNpR4+6/HAlCKYfUdaruTb1HAidtq8BmnywDhWiHxtChqsvJ/7qvIXlVqCnOy0LusSPd5tegwmhdHG1V1IRh5m3L50Ybr6UXixHPJ6HtrNHm00uBcfndBgRln60ADivLs9Y+zmhZoRVzd9uEv2F/nxf3TVoWWGR137bo/45P6sVlrsXpnjWJZYxwsysNYO5ary6txxasL8cu2SHMQXyCAti2Uqa1ev2RbuO2oqg8149bj9fmbcPLj36C8KrJ+q7bBF3EcjQ7rY7PC0VIzg5m/vf1zeJsWzpUDDdbOO69fMnZsddoeNgHY+4YSQkgzIN53prUmF+2KcvHzXSebRnBiLXaONXLVrigXt47ug5e/3Wh5wqNlgiYP47t/nIhftlXhD/3KIleKErOJcpbHjWyPC16/pLgjriV6xajIUxcMDNnWi69Tp3HaPX3EYyJuq9HnN42CyZElsQFscZ5xzZni9bkejDysHSb8sS+m/boTi8U+NYg0ejCa51jtY6RGfs+/79MeLpf+OfjUnHWay0UB3LmVvrg66PXrTgpzs9z44m/HY19tIy7S6aMliwitI3Lr6N7YV9uIyd9v1N2/UxTHQVztq23EX6YuMl1Pq9+U0WE36rVmxFWvK8ciRkEkScKGiloc0rYwJmfO8PasrXf5lJ9QXq1tSOELSBE3jPwByXbjZCtM+GQFAOA/M1bjhN7tsHlvHW486VDsPdCAwffPxoAuLfHJ2HBDdqs35BptjNVK5Epum5Dldhmu7wsEDH80/Q65iiYSRq4IIURFvMWV3uQiN8tjOlmId+TK6tbt3EnWEi2FTXVRXVoXYEz/DjFNktQOcR0NTA2AYG2VeiIEaLu1ifU84muM0jj13suT5w/UbNSsdz40+gOmUYq8prRAUdiom1AbUZiTBZfLhStH9MCIXpHRQ3VaoJGAsjLh0kL8uIxO79fnb45Y1rNdIbKFY+RyufDypdoRMF9AwkmPf6P5nMftwuEdijHQwKgi9PZcwB/6KSPMBTkejD7CuRsERhTZEM8AUG8hpe7W95ZFOxzDc6KuMVJcRVO3J0YdH5+1Fic99g2emK0ttu1i9azVE1YA8Mu2Ks33qndDwAkONPjwt7d/xuOz1mLplv2YuzrYG26ZqleU1UuGWVqgiJ3rkFk9bTBypX9OxEOgxhuKK0IIURFvd6ISEzc7I+IfuXL+QibOpS4d1g3TbhxhKQ3LKi3zlZ/n2YM64Y/9O+COPxyuuX6jT9KcCGnNEUXhIz7W6iElo5c1duZRnRQpiTJ6rpRZbje6tC7AMd31a//k14qTnbwsC853TYjiSWsSpE4LNBJQVtPP1Ijvvnsb89orkRk3/Q4eVermyX3b6/ZJ2yjUmIjI3wst0a3GhWBft89vGCEsAwZ30z9OTmI3ctVg4bhoOd1ZxWiira6dAqxFrmTk+kixXu6ZuesBAE87IFxuenupY9bn6n5YgLmBRSyIn/v+ukZdkWhVCN1iQWB7/QFMnbcJq8trTNeVMRdXxunP0d60SSYUV4QQoiJe4uo/5/THgC4tcdupfaLeRqyRK7N5TTwuY2Ik59D2RTiiY4nB2vZR97XK9rjx7P8NwhXDu2uuX6Fh9DDq8PY4TLCTlxHvsmdnWYtcqcWeiFZUSz3ZvOMPh2NIj9a4YEgwynXN78xr3MTogZaA00MUuVruZmrnRSO75r0HlHbZVk1KxO/bK5cZ112pyfa4NSfrdibwQPg4Z5s0bQbCkTbRddLtdsHjDrpNOoFRxNKuuYMV0WvVUEcLo58kLZc/O5ErOQrbaNGl0C4f/7zDkvX5vN+iF5/xQhQdRh+Nkx/boPtm4a5PV2DWyl2WX2P2O2AWmYo23TiZUFwRQoiKeAWuzju6Cz4ZOxylxfqOZmZYaXZqhFn6XRzmL8r9O7it207rgx5tC3HbaUqxKkdz9CZxu2sixdVDf+5nKnzE9DOtyeiLlwzGgM4leMygwbEWarF59e8OwbvXDDO1lBcRJyDFBuJOjWj+kavhmKcWG0Z3kRdu2qe7bSPEj71Xqb65hh5a0Sa7qWeywLOSnqq1hvw6s92eOTCyKbUWz/3fIO19u+w7hj4605rFu12++HUnAGW9nxqt88VKdFBGFJlWGxiLSJKEWSt3GUaQrPzm/d/L2nV4yUT8zv9l6iJFXZpYWxjrDTmRaCzxzY73vrpGvPB12HxHnVVgZrSRilBcEUKIilQ0fn3o7H7o26E4QkjYxWlXW6MGtPHm2hN64qu/j0TnVspUMvkt6k2U99RE1k7o2beLKXuicYJW9GD0EWX4ZNwI9DCwyh7QJTJq17IgG4v+PQrL7xmt+ZrjD2uLQ9oWGkYzxAnUyX3bRzx/6+jemq9rJTTv1bI8VosUO3eRraZ+xnpKagkpu+LKzvpakW355eJzw5rMT0QOM3BmlBnQpaXiuIhkuV249Lhu6GNhO/HmujeXALA/ebcVuRLOoV3V9ZjwyfKIdWat3IV/vL9MM0L35YpduPr1RRj+0FzdfcTT5j2eNKicGMVaK7EmNtmBH3WrCjX/W7jF8HnWXBFCSBpzwmHtAACXD++R5JFEcsGQrpj+t+PRwcSswQyzO/N/GhC8s96/s3Hq3jUnHAIAuPtPR9jcv63VLWHXCv3E3qWm25ARI1fixPmcpgbTA3Q+J71UozMGdMLEs/vh32PC9WAetwttW+TqCrzcLA9mjz8Bv949GgN0DBfECVTbFrn46PrjcONJh4aWFepEPMW7yuo+PUCkeYJW7xq9z7u9xQhtXozRWC3siyvr62q9X7dG5Eqr1uSUvu1x4+97GW7fHwhEmLSEx+lCaVEePrjuOOsDjjNWbLlF7KRsit+Jf330q6apydWvL8K7i7bhtXmbIp6bL6TzVdd7sa+2MWKd2sb4NSiOJ+q6z13VDcJzorgKHx/xdydRdCjJM/w+mmnzdKy5ohU7IYQ08dKlg7F+9wH07VCc7KHEDbNpzR1jDsfR3Vvhd4e2M1zvtlP74IrjemhOyI3377y6Uk9ijfZx3xlH4IyjOuG9xduUr9FRCB6FuAovP6Vve8y46Xh0b2Otoevlx3UPbsPtwoVDumKB0F9Lqw+YmlCqo86qPdsp68WO6toKR3Vthb4dipGX7caOSn2nM5njD22HS47thjcWbEav0ha4cEhXdFL1jdKKXP39lN6hBrEi+RYa8wL23e+soOVQaYSdOkut80s+Tw5tH44oaQn2orxsjD+lN2486VBkedw48q4vcaBBObn3ByIdMGXk1NRoHPfMaFmQjZr6yD5JZtie+9r4rAtyPCF7/iWqNgGAsp5sl4abn/i9PuE/X2lO1KNJdUsF1D3ExPcvRuPkWrWju7XCX0b0wMAuLfH5Lzs1xWg8aF+ch8/GjcDc1buiSlE1qvNMVRi5IoSQJnKzPDiiY4kjvVNSleFNdtt6KWZ52R6cMbATWhVqpyXJuFwu28IqXqgLpo0O3yXDutvqA5WlsvkWH/cpK45w09Nizi0nYILK6ECceNs53/REw6jDS3HfGUfgo+uVEY1TjyzDyN6llqIFHrcL9515JNY9cBpmjz8BfxkRGcHVmpzqbVstevV6UNl1v5OZfuPxEcvkkcQzLVDUVpcO64ZDS1vg9P7BiO+xh7TBI+f0x0fXH6cZuSppqofLMgiVBQKSbhRTrrlUf+YdHPguHtGxGPedcaSt17z07W/YVxtZw2jEht0HLK+bm+UJRVe16hwfnrE69PjL5eWG29pf59UUUrUNqSGuzBrIq6lXRa627qsLPZajWjX1XryxIBjtO7R9EVwuF47u3hr/OFU7TTgeuF0u9O1YHGE8ZBVGrgghhKQ095xxBHoJk8FEEw/dqp6oOrkPvciVGWJ0Qx1VApTCw87EXqz7mnh2v/D+XC5cMqy77uvs7MOoAF3rLrLWtlvkZll2C9QTEmYU50e+rjgkXmyKKzuRK2HVezXEyLlNvcxys8K1JONPPgyHtS+KEONaDnh+SdIV3C9eMjg4XtVnblbfVlqUq2nkIrKnpsG20Hhw+mq8t2ib+YoCNQ0+TL7saEtNi3Oz3Mj1uNHoC2hOst/9aWvo8Y6qevywviJ0A8kqzwtmCnaRm5FHQ8uCbEVT5gKLkV4Zdc1VrWAEIUeubvvw11C6oHjK2GnXYIUcjxuHdyyO6LEFCDWwUWYt0C2QEEJISlOcl42xJ/ZCV5v9hJyixIaTnR3kejlAeRH/bFy4F1GZUAN0ZCdrqZ9ihMBOhMnM3jlXmNzYqfcRJ9UXDulq+XVaYuO+M+zVywHWI1ef3TBCYQl/w+976Ypes0bJeoji7cGz+uHiY7vi+KaJtXry+PxFg3D2UZ10t6XXa0wLq2uKAvoP/Trg1COtNRnWi0JtemgMjuoa7KWlPhf1auq0xqLHP0b3QdXByL5UZqyzEYkCgCuH97DsaJmb7Va0QFCjdipctbNa8Xe8kxBi6df39d9HKnqlmRk/qFFHrkTkKN+0X3aGlompr3bOdyNuHnUYplx+NH65+xTdCLS822iPBQ0tCCGEEA0eOOtI/HlQZ4w+wtoE0y73CMYa4kW8X+cSLLvrFNx2Wh98IKTMvXfNcWjbwjxNxR1l5MoMMS3QTr2Pk7U2RpEuPbQmOh4NddijbaGilur/hnaN6s711CuH4NtbT8Sz/3dUxHNihO3/hnbF/Wf2Cx0vdcpqfo4H7Yr1j7fV+jDA+vHKEQSt1dTHwhwPHv5zf8tjkTlEIzqqHIvxdO/mUYdhVN/2qNZo+gsoa8Ds9FFTs/COk/DvMYdb/gzdLpdh7zF13ZH4/Vi+vQrlVea1hrFQqNEu4dwmsxsjBnQuQcuCHEWvtIFdWtnatxj1UqPlgBjNT8e71wwzfL4oLwu/79Meedke3XPMTpsDNY+dOwCfjBtu+3XJhuKKEEJI3LloaDc8dt6AuBTiA8pJlXoPJfnZuPaEngpzhvwcD565MDhhP3uQfkQDAA7vUIzWhTnobcP+2qyuK1pxZbc5rszBRvNGslZQ95z595jDdcekbFCsL17UzYdFTjisHbq2KdC0JjeKxrRtoVy/c8t8lBbp1yUV2HAstHq4vBZ6jz2r6mf13rXHoWPTeWr1UN806tAI4xE1ZpGrQ9oFjVnEyJVo6S9GfTvqOJbmZbvRu73xd6S0KC/UcFmNVguD1eU1tvpiydvduq8Of3zme3xhUocVK6ccEdn24Pxjupi+7n3B7XHZXadg/u2/x9AerR0bl1Z9mlrc3H26ecNrs49e0WRdZ+VQ5Mp0b5Ec2akEh6ehwRTFFSGEkLTHE0X63rCebbDo36Pw6DkDDNf7/IYRWHD7SYYCQc09ZxyBAZ1L8NQFAzWfFye7dpJeohWnake6aBHTAhf+6yRcdfwhEeJK/vjFCEdetltXlGhNBNVouecZ1VWJ50BpUS4ObV9kaPpgpzm31Qic6GSnZ/V/Yp9SXDQ0nN5ZIrxPq1He0UeUocCkYbOZQJFTMw8tDUfAbhAs40VbfT0jG4/LpRi/EVqCvG/HyEl0QY5+RESL3dUNuOuT5Zi5cpfl10RLfrYH406MtNVX14D+vk9pRFNo8XiU5GejQ0k+urQuwJUOtQG5+Z2fI5apb+J0amWeGu4xcd0Uf4/0v49NbQqETT1x/gA8JNSMZhoUV4QQQtIeo8iVEW1b5JrWH3jcLks1KyKdWxXgk3EjcMZA7aiYKNTsWA3fdtrhKMrLUvSwskKdQ5Ersbi8tGnCLX72FxzTBTNv+h0A5XvM8bjxj9HKBth3nd4XRXlZEc5l14/sCQD41x/C67dWuVf2Km1hOuk+pSny8ui5QfHc3iAtsEAjvUsPqy7vouGAkeBXT7RlHjrbOD3w3WuG4akLBuLwDsWmpiBm56+cwnnV8YfglpMPw/Qbj1dEHsXIlV6vPbfLpWnQobeuGq1o751/7GsrcvXsV+sxdf5m3Pf5Skvrv3r5MZa3rWZU3/aaojzL7cKDZ4WFQ7sWuZadAI8/zJ4Zhx7bKw9GLFP/zBmlW8qYRcrF775+WmDwf/GmRLbHbeuGRrqREuLqueeeQ/fu3ZGXl4ehQ4di4cKFhutXVlZi7Nix6NChA3Jzc3HYYYdh+vTpmus+9NBDcLlcuOmmm+IwckIIIamAndS6VECc7NpxG+vRthA/TzgF408+zNb+jura0tb6etw8Krjf844O15WI0aw7xhwe6vUkRmuyPO6ICeYVw3tg2YRT0L+zcmy3ju6N7/5xIq4+/pDQMjEt8N1rhuHLm35nGqF86oKjMOOm4/G7JrOT1oVKcSXOG62mBd59el/LEUx1k1c9/jSwI3q0LcTZgzopRFJJQXao1uwejWbdQ3q0Dol3PZt7q8iRq7xsD2446VD07Vgc6qkFKIVpx5bakauAJBn2vBIjmVpRDi2zm8PaF9m+sWGHrm0KohZYlXWNmpHkLI8L/ydEI+2YR+TacbexiXocVkRrmxbGLTmspAXK54T4dfW4XJb2b2YMlKok3Yr9nXfewfjx4zFp0iQMHToUTz75JEaPHo01a9agtLQ0Yv3GxkacfPLJKC0txfvvv49OnTph8+bNaNmyZcS6P/30E1588UX072+/OJQQQkj6IM4b1A5iqYg4KbFrNRxNauCIXm0x5fKjsX3/Qdz5yQqcPiA6K/4zj+qEIT1aKyIZYj2XWOBvZVKsNfF0uVzo0lqZsiRamBfnZ1n6DPJzPOhTFk41696mAH8a0BHlVfV49qKjcPzDX4VSEvXS9kQGdmmJy5qaQVtBbbagx6CurfDV30dqPvfH/h0x6vD2pv3UTuxdiqtG9MDhHYoxa+UuzFihrDWqqffi3MGdI5pny2gZenRsmYfOrfKRl+1BG8H8RS9yVe8LIGDw3RP3oXUzRM9JVCvCEosFukhhThZO7FOK4rwsVNtsJlxZ51UIUBl1tMdOnWQ8haT6I7cibozqFAFlC4PsLO33qRWZd7vj0U4+dUi6uHr88cdx9dVX44orrgAATJo0CdOmTcOUKVNw2223Raw/ZcoU7Nu3D/PmzUN2dvCL2L1794j1Dhw4gIsuuggvv/wy7r///ri+B0IIIclFnGwH0qwvijdgPS0wWlwuF37fJ5gmd3LfMpRG2dATQMhwQaa2MTwpFcVStBbrejx94VHYtr9OIZjs4HK58PSFYdfBnCx3SFyJUbD2xbmh3kAAcOoRZXjgrCMVAsMKWn24osFKo2qXy4V/NzWqrjzojRBXDb4A/nNO/5C4yslyKxzltGqlsjxuzLnlBHhcLny4ZHtouV6UzB8wi1yF34eW4NA7X7q3KcSSLZWKZX07FGPZtir9nVlErlVrVZhjSVyNPqI9vlwRrOc6pF2h5s0BudH3cT3bYN5ve3HBEHODC5l49nRSyxkraYFmNzHECKSeWPM2iStRUHtc2qYmmUJS0wIbGxuxePFijBo1KrTM7XZj1KhRmD9/vuZrPv30UwwbNgxjx45F+/btceSRR+LBBx+E368Mv48dOxZjxoxRbFuPhoYGVFdXK/4RQghJH8T8/Vh6zySS044sQ/c2BRh2SJuE7resJM+xPjcAUNegnf526pFlOKZ7K1zzu0M0n7fLnwZ0xPUjIw0EoqVI5zz5bNwIPH7egJAD30XHdrUtrADgjjF9cUz3Vnj+okHmKzvIJcd2w8N/7qfoodTgDUSYfMiMO7GXrrtlbpYHWR63ogeTlqufjFHNlRi50ppY69nhD+jSMmKZVmPuaJAb9/7NYg3jH/p1wLQbR+CyYd1w5x+13fZkwfH6lUPw0x2jcETHEs31tBjQpaVhCu/lJpHTjk1mIzkeN15QNUfO8ajFVewSQBRMejVXsgOlIi3Q7bLd6DudSOoVqKKiAn6/H+3bK60s27dvj9WrV2u+ZsOGDZg7dy4uuugiTJ8+HevXr8f1118Pr9eLu+66CwDw9ttvY8mSJfjpp58sjWPixIm45557YnszhBBCkkZulgcfXHccApKUNuLq+YsGQZKca+iZLHqVak90c7M8eO/a4xTLXC4gVbI227TIxQ6NPkilxXk4e1BnjOxdio0VBzC4W3QW2Z1a5ke8/0SQk+XG+ccoG0yrG86WFuVi2/6g6YEV6/AaIaqj5xYIwDAtMNckAqdncHDS4aW469MVimXtS/KQn+3BQW9sRi2ys9/Zgzqjc6sCfLR0G37ZVoUVO4I32W8/rQ8mfhGej+Zle3BExxLcc4a+YJIjV1keN9rZjBDnZXvw0fXD0f22aZrPXzqsG37bcwBFeVmY/mukzXyLvCygCmj0B/DwDOU8Wv27qCeu/nbSoaj3+nFaP3MTDjECqSeW5CiwGDnzuK3VXKUraffOAoEASktL8dJLL2Hw4ME4//zz8f/t3XtU1GX+B/D3XJzhOtzvDAwmKsioCKKomQWrq2aarbclvNTWD5MV2jLXn912Ny+1J9dLpdU5qVtutrVqu57UQ6iY/RQVQUVdtbxAyiVDbmGCzPP7A/k6XxhuOjCDvl/nzDnO9/vMzPP9gDPz4Xmez7N48WKsW7cOAFBYWIi0tDRs2rQJDg6tzxVttGjRIlRUVEi3wsLCzrwEIiLqBDGhHhhssN5eMZ1NoVB0+8QKaBhRem1CpGykpCX2dLVtLdb3dNbccWJlb240Wf/V1lqapmrMpn72UClllRzNtTbD1dFs9KvWwjocH1etrDx344hVsIcTNj87VNbWy1lz139EaVqlMi7ME8sm95eVow/xdJKVpG9P4ZP2VpO8E44aFT5+eghSH7Y80tZaTJqes5QMrZg6AKmP9MKicREYaGHEsCnz9y91CxdeWtXwBwxlk5Gr9kxL7Mjm3vbEpsmVt7c3VCoVSkrk+xGUlJTA39/y/g4BAQHo3bs3VKrbAY+IiEBxcbE0zbC0tBSDBg2CWq2GWq1GVlYWVq9eDbVa3Wz6IABotVrodDrZjYiIiNqmVCowZ3gYooLanv7U3j3IusKoW1UE7wdNR67ME8v2/EieGBQMP51W2ocpxNPyHkmtDUqONIu3pU2hfV21mB4XgpyXE7FgTB98kBwjnRva0wvZ/5sg3fd01sg2uJ338APSvy1NI7RkZrzB4nHz31EfV60saWhXctVCQBsrfP5lYvPKj+3V+Nzm0zTNtVaS37nJXmhNp/H9dkgIJg8K7tCIkvnIVUvXffXWJuHmp5UKRYvJWKPUh3sh1KvlKaj2zKbJlUajQUxMDDIzM6VjJpMJmZmZiI+Pt/iY4cOH47vvvoPJ7M8jZ8+eRUBAADQaDRISEnDixAnk5eVJt9jYWCQlJSEvL0+WlBEREVHX+XBmwxfmZXawgWhyvAGvPhqJHWkP2rorna7pbD21UoG3ftMffxzbF8Ht2EzWy0WLg4sS8OqEhnVGTcvaN3rrif5w1aplGyMDDUmK+Xo5T2cN/vk/8Vgwpo+sTeNrzXu4l2zjYkC+kXFPHxfZNDPzNWNhXm1fD9DyKKr5cR9XrawKnmOPlpOXuDBP/OFXveHdwvq8+QnhOLw4EcktJHXmHunbUC17aE/5yGljgtLS+qbWkqume7mZj1zNTwjHaxMsryFrjfnIVUtVWhu3bXBzvJ1QB3s4trnm6sUxfVo9b89sPjH9D3/4A2bNmoXY2FjExcVh5cqV+Pnnn6XqgTNnzkRQUBCWLVsGAJg7dy7eeecdpKWl4fe//z3OnTuHpUuXYv78+QAAV1dXREVFyV7D2dkZXl5ezY4TERFR13mkrx/OvjG2U0tOt5dKqcBTI8Js3Y0u0XR6lUKhwNTY9lexa3xMIw+z6oLaW1UX1UoFjMFuyHttNH64VoNN2QUAGtbwPPfwA81+5nFhnvjhWo10vz0bOa+cNhBXKq5joN5dtm+WeSn99o52tDTSYr6Oy9tFK6s+6uHcvPDH8slGHPuhHEsmGduc5tveNVgfJMegrKYWp4uqcPD87b1fGxPKlrYO0KqV0KiUFqddOmtaXnOVGOHb7v3bzJmPXFkqZvJBcgxGhDdsjDwkzBPrnoxBL19n6D2dcLakqsOv113YPLmaNm0afvzxR7z66qsoLi7GwIEDsXPnTqnIRUFBAZRmQ4d6vR67du3C888/j/79+yMoKAhpaWlYuHChrS6BiIiI2skeEqv7xWfPDsVr/z6JNybJ/7jcnvLurTHfk+rPE/vhy7wr0ms0VIK7/TOeEhvc4hf3Eb0avniHt1AUpalJ0UHSv0f18cWG/7uI38QEy4plRAS4Sv8O9nDEeGMA3t93vtlztTQdMtbgiR35DcUinLVqnCutls7565qvVZseF4LpcSHNjt8NtUoJX1cHFJbVyI435jItxVOjVjaU2beQXDk1mRZonlzd6a5T5vtcWSojP7rf7SU+SqUCv44yu28/M4StzubJFQCkpqYiNTXV4rm9e/c2OxYfH4+DBw+2+/ktPQcRERHRvWxITy/sTB8p3X95fAS25l5GykN3Vx7f20WLmFAP1JsEpsTom1UnNP/S3VpRAl+dA3Jf+VVDlbsOWjSuLx6PDoIxyA0nLt/e88q8bL6XixaLxkUgMdIPU9bJt/hpKbmaPcyA6l9uoqdPwwhYVKAbvsy7Asceqi5fM9i0CEXjaFtLf6BQqxqSK9zaps1Jo0LNrU2+m64Xa09Bibao2jEtsCXdbDvCDrGL5IqIiIiIOtfvHuyJ3z149/uOKZUKfJHSsDa+rYSjrRLsHs6tV21s8XnVKql4Rf9gNzwY7o0zxVWICNBB7+mIwrLrGPZAwx5ygw2eiA5xR67ZZsQtjdaolAqkJd6uxpccHwpHjQqj+nR9AZSmU/naSq6EkE8ZrDMbwWq6Tks2cnWHeVZLm7cnDQlpc9ppZ26YbGtMroiIiIioQ1pLqvx0WoyO9INDD1WrRRas2Zf1swdDeWt7g3+lDEPG6RI8bjaN8Hrt7bVUff1d2z1y49BDhSeHhlq9z+3RUml1S5swA8CV8uuytWR19bcTmKYJWXv2qGqLLLkyy5WWPN52wZqePs5w1qjg7qTB5fLrd/T69orJFRERERFZjUKhwAczY7v0Nc3XefnqHJA0RJ4QVd+4vVfXf34/wq62BWhJ0/LpdRY2Epsz3ID1314EAFz86WdZomIMckNPH2fcqDMhyN1R9jiFQoHZwwy4Wn0Dffxc0RaVUoEJ/QNw7IcKXLj6s3SsUUdHorRqFXJe+RVUSgXCF+/o0GPtHZMrIiIiIrqn1ZiNXHVkLydbalq4wtL+YK5aNSICdDhdVImHevvg7wcuSefeSxoEfQt7kgHA64+1vefWk0ND8MnBAiweF4GnRoTho/0X8OftpwDIk6vGNWod0VJhlfYke/aMyRURERER3dPmDDPg7YyzGNPPz9Zd6ZCPZseiuOIGnogJsjgd0MVBjU+ejsOO/GJMHBiImtp6fJHzAz55ekiriVV7/fmxKPxuRE+E3to/rLdZ4mO+bm1GXAhKK2/gwVul1+/E6Eg//HZICKL1HnfeYTugEJYK09/nKisr4ebmhoqKCuh0Olt3h4iIiIjuQr1JIOfSNfQPdrvrUvT2IOXjHOw9W4pvXnpEtn9W7U0Tymtq4WuhbLw1mEwCT6z7P1z6qQb7XnrYKmvqJr37LfIKy7F+zmA83MfXCr20vo7kBkyuLGByRURERET2ymQSqK032SRRrL3ZsPbLWnvW3bhZj8vXrqOnT/v2O7OFjuQGnBZIRERERNSNKJUKOChtMwJn7Y3AtWqVXSdWHdU9VvQRERERERHZOSZXREREREREVsDkioiIiIiIyAqYXBEREREREVkBkysiIiIiIiIrYHJFRERERERkBUyuiIiIiIiIrIDJFRERERERkRUwuSIiIiIiIrICJldERERERERWwOSKiIiIiIjICphcERERERERWQGTKyIiIiIiIitgckVERERERGQFalt3wB4JIQAAlZWVNu4JERERERHZUmNO0JgjtIbJlQVVVVUAAL1eb+OeEBERERGRPaiqqoKbm1urbRSiPSnYfcZkMuHKlStwdXWFQqGwaV8qKyuh1+tRWFgInU5n077cTxh322DcbYNxtw3Gvesx5rbBuNsG4249QghUVVUhMDAQSmXrq6o4cmWBUqlEcHCwrbsho9Pp+B/DBhh322DcbYNxtw3Gvesx5rbBuNsG424dbY1YNWJBCyIiIiIiIitgckVERERERGQFTK7snFarxWuvvQatVmvrrtxXGHfbYNxtg3G3Dca96zHmtsG42wbjbhssaEFERERERGQFHLkiIiIiIiKyAiZXREREREREVsDkioiIiIiIyAqYXBEREREREVkBkys79+6778JgMMDBwQFDhgzBoUOHbN2lbmvZsmUYPHgwXF1d4evri0mTJuHMmTOyNr/88gvmzZsHLy8vuLi44IknnkBJSYmsTUFBAcaPHw8nJyf4+vpiwYIFuHnzZldeSre2fPlyKBQKpKenS8cY985x+fJlPPnkk/Dy8oKjoyOMRiOOHDkinRdC4NVXX0VAQAAcHR2RmJiIc+fOyZ6jrKwMSUlJ0Ol0cHd3x9NPP43q6uquvpRuob6+Hq+88grCwsLg6OiIBx54AH/5y19gXjeKMb97+/btw4QJExAYGAiFQoFt27bJzlsrxsePH8eDDz4IBwcH6PV6vPXWW519aXattbjX1dVh4cKFMBqNcHZ2RmBgIGbOnIkrV67InoNx77i2ft/NpaSkQKFQYOXKlbLjjHsXE2S3Nm/eLDQajfjoo4/EyZMnxTPPPCPc3d1FSUmJrbvWLY0ZM0asX79e5Ofni7y8PDFu3DgREhIiqqurpTYpKSlCr9eLzMxMceTIETF06FAxbNgw6fzNmzdFVFSUSExMFLm5ueKrr74S3t7eYtGiRba4pG7n0KFDwmAwiP79+4u0tDTpOONufWVlZSI0NFTMnj1bZGdni/Pnz4tdu3aJ7777TmqzfPly4ebmJrZt2yaOHTsmHnvsMREWFiauX78utfn1r38tBgwYIA4ePCi++eYb0atXLzFjxgxbXJLdW7JkifDy8hLbt28XFy5cEJ9//rlwcXERq1atktow5nfvq6++EosXLxZbtmwRAMTWrVtl560R44qKCuHn5yeSkpJEfn6++PTTT4Wjo6N4//33u+oy7U5rcS8vLxeJiYnis88+E//973/FgQMHRFxcnIiJiZE9B+PecW39vjfasmWLGDBggAgMDBR/+9vfZOcY967F5MqOxcXFiXnz5kn36+vrRWBgoFi2bJkNe3XvKC0tFQBEVlaWEKLhw6FHjx7i888/l9qcPn1aABAHDhwQQjS8ySmVSlFcXCy1Wbt2rdDpdOLGjRtdewHdTFVVlQgPDxcZGRnioYcekpIrxr1zLFy4UIwYMaLF8yaTSfj7+4u//vWv0rHy8nKh1WrFp59+KoQQ4tSpUwKAOHz4sNRmx44dQqFQiMuXL3de57up8ePHi6eeekp2bPLkySIpKUkIwZh3hqZfNq0V4/fee094eHjI3l8WLlwo+vTp08lX1D209iW/0aFDhwQAcenSJSEE424NLcX9hx9+EEFBQSI/P1+EhobKkivGvetxWqCdqq2tRU5ODhITE6VjSqUSiYmJOHDggA17du+oqKgAAHh6egIAcnJyUFdXJ4t53759ERISIsX8wIEDMBqN8PPzk9qMGTMGlZWVOHnyZBf2vvuZN28exo8fL4svwLh3ln//+9+IjY3FlClT4Ovri+joaHz44YfS+QsXLqC4uFgWdzc3NwwZMkQWd3d3d8TGxkptEhMToVQqkZ2d3XUX000MGzYMmZmZOHv2LADg2LFj2L9/P8aOHQuAMe8K1orxgQMHMHLkSGg0GqnNmDFjcObMGVy7dq2LrqZ7q6iogEKhgLu7OwDGvbOYTCYkJydjwYIF6NevX7PzjHvXY3Jlp65evYr6+nrZl0kA8PPzQ3FxsY16de8wmUxIT0/H8OHDERUVBQAoLi6GRqORPggamce8uLjY4s+k8RxZtnnzZhw9ehTLli1rdo5x7xznz5/H2rVrER4ejl27dmHu3LmYP38+Nm7cCOB23Fp7jykuLoavr6/svFqthqenJ+NuwR//+EdMnz4dffv2RY8ePRAdHY309HQkJSUBYMy7grVizPecu/PLL79g4cKFmDFjBnQ6HQDGvbO8+eabUKvVmD9/vsXzjHvXU9u6A0S2MG/ePOTn52P//v227so9r7CwEGlpacjIyICDg4Otu3PfMJlMiI2NxdKlSwEA0dHRyM/Px7p16zBr1iwb9+7e9M9//hObNm3CP/7xD/Tr1w95eXlIT09HYGAgY073jbq6OkydOhVCCKxdu9bW3bmn5eTkYNWqVTh69CgUCoWtu0O3cOTKTnl7e0OlUjWrmFZSUgJ/f38b9erekJqaiu3bt2PPnj0IDg6Wjvv7+6O2thbl5eWy9uYx9/f3t/gzaTxHzeXk5KC0tBSDBg2CWq2GWq1GVlYWVq9eDbVaDT8/P8a9EwQEBCAyMlJ2LCIiAgUFBQBux6219xh/f3+UlpbKzt+8eRNlZWWMuwULFiyQRq+MRiOSk5Px/PPPSyO2jHnns1aM+Z5zZxoTq0uXLiEjI0MatQIY987wzTffoLS0FCEhIdLn66VLl/DCCy/AYDAAYNxtgcmVndJoNIiJiUFmZqZ0zGQyITMzE/Hx8TbsWfclhEBqaiq2bt2K3bt3IywsTHY+JiYGPXr0kMX8zJkzKCgokGIeHx+PEydOyN6oGj9Amn6RpQYJCQk4ceIE8vLypFtsbCySkpKkfzPu1jd8+PBmWw2cPXsWoaGhAICwsDD4+/vL4l5ZWYns7GxZ3MvLy5GTkyO12b17N0wmE4YMGdIFV9G91NTUQKmUf6yqVCqYTCYAjHlXsFaM4+PjsW/fPtTV1UltMjIy0KdPH3h4eHTR1XQvjYnVuXPn8PXXX8PLy0t2nnG3vuTkZBw/flz2+RoYGIgFCxZg165dABh3m7B1RQ1q2ebNm4VWqxUbNmwQp06dEs8++6xwd3eXVUyj9ps7d65wc3MTe/fuFUVFRdKtpqZGapOSkiJCQkLE7t27xZEjR0R8fLyIj4+XzjeWBB89erTIy8sTO3fuFD4+PiwJ3kHm1QKFYNw7w6FDh4RarRZLliwR586dE5s2bRJOTk7ik08+kdosX75cuLu7iy+//FIcP35cTJw40WLJ6ujoaJGdnS32798vwsPDWRa8BbNmzRJBQUFSKfYtW7YIb29v8dJLL0ltGPO7V1VVJXJzc0Vubq4AIFasWCFyc3OlqnTWiHF5ebnw8/MTycnJIj8/X2zevFk4OTnd16WpW4t7bW2teOyxx0RwcLDIy8uTfcaaV6Bj3Duurd/3pppWCxSCce9qTK7s3Jo1a0RISIjQaDQiLi5OHDx40NZd6rYAWLytX79eanP9+nXx3HPPCQ8PD+Hk5CQef/xxUVRUJHueixcvirFjxwpHR0fh7e0tXnjhBVFXV9fFV9O9NU2uGPfO8Z///EdERUUJrVYr+vbtKz744APZeZPJJF555RXh5+cntFqtSEhIEGfOnJG1+emnn8SMGTOEi4uL0Ol0Ys6cOaKqqqorL6PbqKysFGlpaSIkJEQ4ODiInj17isWLF8u+XDLmd2/Pnj0W38tnzZolhLBejI8dOyZGjBghtFqtCAoKEsuXL++qS7RLrcX9woULLX7G7tmzR3oOxr3j2vp9b8pScsW4dy2FEGZbxxMREREREdEd4ZorIiIiIiIiK2ByRUREREREZAVMroiIiIiIiKyAyRUREREREZEVMLkiIiIiIiKyAiZXREREREREVsDkioiIiIiIyAqYXBEREREREVkBkysiIqIOMhgMWLlypa27QUREdobJFRER2bXZs2dj0qRJAIBRo0YhPT29y157w4YNcHd3b3b88OHDePbZZ7usH0RE1D2obd0BIiKirlZbWwuNRnPHj/fx8bFib4iI6F7BkSsiIuoWZs+ejaysLKxatQoKhQIKhQIXL14EAOTn52Ps2LFwcXGBn58fkpOTcfXqVemxo0aNQmpqKtLT0+Ht7Y0xY8YAAFasWAGj0QhnZ2fo9Xo899xzqK6uBgDs3bsXc+bMQUVFhfR6r7/+OoDm0wILCgowceJEuLi4QKfTYerUqSgpKZHOv/766xg4cCA+/vhjGAwGuLm5Yfr06aiqqpLafPHFFzAajXB0dISXlxcSExPx888/d1I0iYioMzC5IiKibmHVqlWIj4/HM888g6KiIhQVFUGv16O8vByPPPIIoqOjceTIEezcuRMlJSWYOnWq7PEbN26ERqPBt99+i3Xr1gEAlEolVq9ejZMnT2Ljxo3YvXs3XnrpJQDAsGHDsHLlSuh0Oun1XnzxxWb9MplMmDhxIsrKypCVlYWMjAycP38e06ZNk7X7/vvvsW3bNmzfvh3bt29HVlYWli9fDgAoKirCjBkz8NRTT+H06dPYu3cvJk+eDCFEZ4SSiIg6CacFEhFRt+Dm5gaNRgMnJyf4+/tLx9955x1ER0dj6dKl0rGPPvoIer0eZ8+eRe/evQEA4eHheOutt2TPab5+y2Aw4I033kBKSgree+89aDQauLm5QaFQyF6vqczMTJw4cQIXLlyAXq8HAPz9739Hv379cPjwYQwePBhAQxK2YcMGuLq6AgCSk5ORmZmJJUuWoKioCDdv3sTkyZMRGhoKADAajXcRLSIisgWOXBERUbd27Ngx7NmzBy4uLtKtb9++ABpGixrFxMQ0e+zXX3+NhIQEBAUFwdXVFcnJyfjpp59QU1PT7tc/ffo09Hq9lFgBQGRkJNzd3XH69GnpmMFgkBIrAAgICEBpaSkAYMCAAUhISIDRaMSUKVPw4Ycf4tq1a+0PAhER2QUmV0RE1K1VV1djwoQJyMvLk93OnTuHkSNHSu2cnZ1lj7t48SIeffRR9O/fH//617+Qk5ODd999F0BDwQtr69Gjh+y+QqGAyWQCAKhUKmRkZGDHjh2IjIzEmjVr0KdPH1y4cMHq/SAios7D5IqIiLoNjUaD+vp62bFBgwbh5MmTMBgM6NWrl+zWNKEyl5OTA5PJhLfffhtDhw5F7969ceXKlTZfr6mIiAgUFhaisLBQOnbq1CmUl5cjMjKy3demUCgwfPhw/OlPf0Jubi40Gg22bt3a7scTEZHtMbkiIqJuw2AwIDs7GxcvXsTVq1dhMpkwb948lJWVYcaMGTh8+DC+//577Nq1C3PmzGk1MerVqxfq6uqwZs0anD9/Hh9//LFU6ML89aqrq5GZmYmrV69anC6YmJgIo9GIpKQkHD16FIcOHcLMmTPx0EMPITY2tl3XlZ2djaVLl+LIkSMoKCjAli1b8OOPPyIiIqJjASIiIptickVERN3Giy++CJVKhcjISPj4+KCgoACBgYH49ttvUV9fj9GjR8NoNCI9PR3u7u5QKlv+mBswYABWrFiBN998E1FRUdi0aROWLVsmazNs2DCkpKRg2rRp8PHxaVYQA2gYcfryyy/h4eGBkSNHIjExET179sRnn33W7uvS6XTYt28fxo0bh969e+Pll1/G22+/jbFjx7Y/OEREZHMKwTqvREREREREd40jV0RERERERFbA5IqIiIiIiMgKmFwRERERERFZAZMrIiIiIiIiK2ByRUREREREZAVMroiIiIiIiKyAyRUREREREZEVMLkiIiIiIiKyAiZXREREREREVsDkioiIiIiIyAqYXBEREREREVnB/wMhXZpGuRz+4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "#plt.plot(generator_losses)\n",
    "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "#plt.plot(multi_scale_losses, label='Multi-Scale Pixel-wise Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator  Loss ')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebf01304-cff8-49be-86fb-1660a0b8ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:00:33<00:00, 277.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  22960.797956466675  seconds\n",
      "[1/40] Training absolute losses: L1 0.0020342 ; L2 0.0004042 BCE 0.0053799; Average PSNR: 12.86; Average SSIM: 0.5396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|███████████▍                                                              | 6/39 [05:19<29:17, 53.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m total_ssim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_pipe_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_pipe_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reshape and move to device\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrontal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reshape and move to device\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[14], line 120\u001b[0m, in \u001b[0;36mImagePipeline.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Advance the iterator to the desired index\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(index):\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# Return the next batch\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m, in \u001b[0;36mExternalInputIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(profile_filename) \u001b[38;5;28;01mas\u001b[39;00m profile_img:\n\u001b[1;32m---> 56\u001b[0m         profiles\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(profile_img))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile image not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\PIL\\Image.py:673\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 673\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\PIL\\Image.py:732\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    730\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tor\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8946018b-2337-4daa-a51d-5a1c24a64c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_epoch = 30\n",
    "checkpoint_path = os.path.join(checkpoint_dir1, f\"checkpoint_{latest_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "\n",
    "# Load training progress\n",
    "loss_L1 = checkpoint['loss_L1']\n",
    "loss_L2 = checkpoint['loss_L2']\n",
    "loss_gan = checkpoint['loss_gan']\n",
    "psnr_values = checkpoint['psnr_values']\n",
    "ssim_values = checkpoint['ssim_values']\n",
    "losses_L1 = checkpoint['losses_L1']\n",
    "losses_L2 = checkpoint['losses_L2']\n",
    "losses_gan = checkpoint['losses_gan']\n",
    "discriminator_losses = checkpoint['discriminator_losses']\n",
    "generator_losses = checkpoint['generator_losses']\n",
    "multi_scale_losses = checkpoint['multi_scale_losses']\n",
    "avg_generator_losses = checkpoint['avg_generator_losses']\n",
    "avg_discriminator_losses = checkpoint['avg_discriminator_losses']\n",
    "avg_multi_scale_losses = checkpoint['avg_multi_scale_losses']\n",
    "\n",
    "# Start training from the loaded epoch\n",
    "start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3d1f5-673f-4014-ac31-0ccf345815d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:05:08<00:00, 284.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/40] Training absolute losses: L1 0.0018189 ; L2 0.0003346 BCE 0.0054548; Average PSNR: 13.70; Average SSIM: 0.6004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:02:53<00:00, 281.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/40] Training absolute losses: L1 0.0016262 ; L2 0.0002760 BCE 0.0054760; Average PSNR: 14.54; Average SSIM: 0.6548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:03:00<00:00, 281.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/40] Training absolute losses: L1 0.0014816 ; L2 0.0002378 BCE 0.0054776; Average PSNR: 15.20; Average SSIM: 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:02:23<00:00, 280.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/40] Training absolute losses: L1 0.0013631 ; L2 0.0002037 BCE 0.0054893; Average PSNR: 15.86; Average SSIM: 0.7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:10:37<00:00, 293.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/40] Training absolute losses: L1 0.0012299 ; L2 0.0001699 BCE 0.0054461; Average PSNR: 16.64; Average SSIM: 0.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:03:23<00:00, 282.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/40] Training absolute losses: L1 0.0010896 ; L2 0.0001361 BCE 0.0054975; Average PSNR: 17.59; Average SSIM: 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:02:40<00:00, 281.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/40] Training absolute losses: L1 0.0010124 ; L2 0.0001186 BCE 0.0054976; Average PSNR: 18.17; Average SSIM: 0.8148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:01:49<00:00, 279.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/40] Training absolute losses: L1 0.0009526 ; L2 0.0001064 BCE 0.0055020; Average PSNR: 18.64; Average SSIM: 0.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████████████████████████████████████████| 39/39 [3:02:27<00:00, 280.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/40] Training absolute losses: L1 0.0008863 ; L2 0.0000921 BCE 0.0054772; Average PSNR: 19.26; Average SSIM: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:03:08<00:00, 281.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/40] Training absolute losses: L1 0.0008239 ; L2 0.0000811 BCE 0.0054883; Average PSNR: 19.80; Average SSIM: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:04:45<00:00, 284.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/40] Training absolute losses: L1 0.0008160 ; L2 0.0000767 BCE 0.0054678; Average PSNR: 20.05; Average SSIM: 0.8637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:02:38<00:00, 280.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/40] Training absolute losses: L1 0.0007457 ; L2 0.0000674 BCE 0.0054781; Average PSNR: 20.60; Average SSIM: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:02:54<00:00, 281.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/40] Training absolute losses: L1 0.0007256 ; L2 0.0000628 BCE 0.0054408; Average PSNR: 20.91; Average SSIM: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:04:18<00:00, 283.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/40] Training absolute losses: L1 0.0006965 ; L2 0.0000588 BCE 0.0054612; Average PSNR: 21.20; Average SSIM: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:05:01<00:00, 284.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/40] Training absolute losses: L1 0.0006679 ; L2 0.0000545 BCE 0.0054738; Average PSNR: 21.53; Average SSIM: 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:05:00<00:00, 284.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/40] Training absolute losses: L1 0.0006360 ; L2 0.0000504 BCE 0.0054934; Average PSNR: 21.86; Average SSIM: 0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:03:47<00:00, 282.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/40] Training absolute losses: L1 0.0006163 ; L2 0.0000478 BCE 0.0054474; Average PSNR: 22.09; Average SSIM: 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:05:27<00:00, 285.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/40] Training absolute losses: L1 0.0006136 ; L2 0.0000457 BCE 0.0054640; Average PSNR: 22.28; Average SSIM: 0.9105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:02:47<00:00, 281.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/40] Training absolute losses: L1 0.0005905 ; L2 0.0000434 BCE 0.0054839; Average PSNR: 22.51; Average SSIM: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:02:24<00:00, 280.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/40] Training absolute losses: L1 0.0005710 ; L2 0.0000414 BCE 0.0053709; Average PSNR: 22.71; Average SSIM: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:03:47<00:00, 282.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/40] Training absolute losses: L1 0.0005433 ; L2 0.0000380 BCE 0.0053739; Average PSNR: 23.08; Average SSIM: 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:03:33<00:00, 282.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/40] Training absolute losses: L1 0.0005435 ; L2 0.0000376 BCE 0.0054659; Average PSNR: 23.13; Average SSIM: 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:04:18<00:00, 283.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/40] Training absolute losses: L1 0.0005201 ; L2 0.0000352 BCE 0.0054957; Average PSNR: 23.42; Average SSIM: 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:06:32<00:00, 286.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/40] Training absolute losses: L1 0.0005299 ; L2 0.0000350 BCE 0.0054711; Average PSNR: 23.44; Average SSIM: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:05:42<00:00, 285.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/40] Training absolute losses: L1 0.0005185 ; L2 0.0000336 BCE 0.0054927; Average PSNR: 23.63; Average SSIM: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:09:27<00:00, 291.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/40] Training absolute losses: L1 0.0004947 ; L2 0.0000320 BCE 0.0054790; Average PSNR: 23.83; Average SSIM: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:03:35<00:00, 282.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/40] Training absolute losses: L1 0.0004926 ; L2 0.0000310 BCE 0.0054926; Average PSNR: 23.97; Average SSIM: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:10:45<00:00, 293.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/40] Training absolute losses: L1 0.0004931 ; L2 0.0000310 BCE 0.0054941; Average PSNR: 23.98; Average SSIM: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:24:25<00:00, 314.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/40] Training absolute losses: L1 0.0004695 ; L2 0.0000289 BCE 0.0053932; Average PSNR: 24.27; Average SSIM: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:04:32<00:00, 283.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/40] Training absolute losses: L1 0.0004548 ; L2 0.0000274 BCE 0.0054837; Average PSNR: 24.50; Average SSIM: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31:  69%|██████████████████████████████████████████████▍                    | 27/39 [1:30:57<1:09:04, 345.36s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1a535-ea0a-4f35-a83f-f8d017cda548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa82673-44c8-47ce-b4ff-239a6df7fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:54:27<00:00, 268.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/40] Training absolute losses: L1 0.0005859 ; L2 0.0000458 BCE 0.0054510; Average PSNR: 22.50; Average SSIM: 0.9208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:51:26<00:00, 263.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/40] Training absolute losses: L1 0.0005185 ; L2 0.0000353 BCE 0.0054886; Average PSNR: 23.50; Average SSIM: 0.9357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [3:25:00<00:00, 315.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/40] Training absolute losses: L1 0.0005383 ; L2 0.0000375 BCE 0.0054895; Average PSNR: 23.29; Average SSIM: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:37<00:00, 265.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/40] Training absolute losses: L1 0.0004855 ; L2 0.0000322 BCE 0.0054034; Average PSNR: 23.88; Average SSIM: 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:48<00:00, 265.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/40] Training absolute losses: L1 0.0004716 ; L2 0.0000295 BCE 0.0054798; Average PSNR: 24.24; Average SSIM: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:52:41<00:00, 265.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/40] Training absolute losses: L1 0.0004349 ; L2 0.0000252 BCE 0.0054435; Average PSNR: 24.87; Average SSIM: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|█████████████████████████████████████████████████████████████████████| 39/39 [2:50:34<00:00, 262.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/40] Training absolute losses: L1 0.0004374 ; L2 0.0000248 BCE 0.0054806; Average PSNR: 24.94; Average SSIM: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38:  56%|██████████████████████████████████████▉                              | 22/39 [54:44<1:13:44, 260.27s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch,40):  # Assuming 3 epochs for demonstration\n",
    "    \n",
    "    # Track loss values for each epoch\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "            profile = data[0].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "            frontal = data[1].view(128, 1, 128, 128).to(device)  # Reshape and move to device\n",
    "\n",
    "            # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            \n",
    "            real_output = netD(real,real)  # Discriminator output for real images\n",
    "            generated = netG(profile)  # Generate images from profile\n",
    "            fake_output = netD(profile, generated.detach())  # Discriminator output for fake images\n",
    "\n",
    "            # Concatenate real and fake outputs along a new dimension\n",
    "            concatenated = torch.cat((real_output, fake_output), dim=0)\n",
    "\n",
    "            # Create labels for real and fake images\n",
    "            target_real = torch.ones_like(real_output)\n",
    "            target_fake = torch.zeros_like(fake_output)\n",
    "            targets = torch.cat((target_real, target_fake), dim=0)\n",
    "\n",
    "            # Calculate BCE loss for the concatenated outputs\n",
    "            #errD = F.binary_cross_entropy_with_logits(concatenated, targets)\n",
    "\n",
    "            errD = criterion(concatenated, targets.float())\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "             # Accumulate discriminator loss\n",
    "            discriminator_losses.append(errD.item())\n",
    "\n",
    "            # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    "            generated = netG(profile)\n",
    "            output = netD(profile, generated)\n",
    "\n",
    "            # G wants to have the synthetic images be accepted by D\n",
    "            errG_GAN = criterion(output, torch.ones_like(output).float())\n",
    "\n",
    "            # Calculate L1 and L2 loss between generated and real images\n",
    "            #errG_L1 = F.l1_loss(generated, frontal.float())\n",
    "            #errG_L2 = F.mse_loss(generated, frontal.float())\n",
    "            errG_L1 = multi_scale_pixelwise_loss(generated, real)  # Multi-scale pixel-wise loss\n",
    "           \n",
    "            #errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "            \n",
    "            # Total generator loss\n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "             #Accumulate generator loss\n",
    "            generator_losses.append(errG.item())\n",
    "\n",
    "            #Accumulate multi-scale pixel-wise loss\n",
    "            multi_scale_losses.append(errG_L1.item())\n",
    "\n",
    "            # Update loss values\n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "\n",
    "            # Calculate PSNR for each generated image and accumulate\n",
    "            psnr = calculate_psnr(generated, frontal)\n",
    "            total_psnr += psnr\n",
    "\n",
    "            # Calculate SSIM for each generated image and accumulate\n",
    "            ssim_val = calculate_ssim(generated, frontal)\n",
    "            total_ssim += ssim_val\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "   # Append the average losses to the respective lists\n",
    "\n",
    "\n",
    "    avg_gen_loss = sum(generator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_disc_loss = sum(discriminator_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "    avg_multi_loss = sum(multi_scale_losses[epoch * len(train_pipe_loader):(epoch + 1) * len(train_pipe_loader)]) / len(train_pipe_loader)\n",
    "\n",
    "    avg_generator_losses.append(avg_gen_loss)\n",
    "    avg_discriminator_losses.append(avg_disc_loss)\n",
    "    avg_multi_scale_losses.append(avg_multi_loss)\n",
    "    \n",
    "    \n",
    "    # Calculate average PSNR and SSIM for this epoch\n",
    "    avg_psnr = total_psnr / len(train_pipe_loader)\n",
    "    avg_ssim = total_ssim / len(train_pipe_loader)\n",
    "\n",
    "    # Append the average PSNR and SSIM for this epoch to the respective lists\n",
    "    psnr_values.append(avg_psnr)\n",
    "    ssim_values.append(avg_ssim)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    #if epoch > 0:\n",
    "        #print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "\n",
    "     # Save checkpoint after each epoch\n",
    "    checkpoint_state = {\n",
    "      'epoch': epoch,\n",
    "      'netG_state_dict': netG.state_dict(),\n",
    "      'netD_state_dict': netD.state_dict(),\n",
    "      'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "      'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "      'loss_L1': loss_L1,\n",
    "      'loss_L2': loss_L2,\n",
    "      'loss_gan': loss_gan,\n",
    "      'psnr_values': psnr_values,\n",
    "      'ssim_values': ssim_values,\n",
    "      'losses_L1': losses_L1,\n",
    "      'losses_L2': losses_L2,\n",
    "      'losses_gan': losses_gan,\n",
    "      'discriminator_losses': discriminator_losses,\n",
    "      'generator_losses': generator_losses,\n",
    "      'multi_scale_losses': multi_scale_losses,\n",
    "      'avg_generator_losses': avg_generator_losses,\n",
    "      'avg_discriminator_losses': avg_discriminator_losses,\n",
    "      'avg_multi_scale_losses': avg_multi_scale_losses,\n",
    "    }\n",
    "    torch.save(checkpoint_state, os.path.join(checkpoint_dir1, f\"checkpoint_{epoch}.pth\"))\n",
    "\n",
    "    \n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/40] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f; Average PSNR: %.2f; Average SSIM: %.4f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train, avg_psnr, avg_ssim, ))\n",
    "\n",
    "    # Print the PSNR and SSIM on each epoch\n",
    "    #print('[%d/30] Average PSNR: %.2f, Average SSIM: %.4f' % (epoch + 1, avg_psnr, avg_ssim))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'FFRAD_CAS_output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'FFRAD_CAS_output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'FFRAD_CAS_output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'FFRAD_CAS_output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0e781-06e7-4b1f-892b-74320131edf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea6f83-d9d8-40c0-9e16-353be1a918ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
