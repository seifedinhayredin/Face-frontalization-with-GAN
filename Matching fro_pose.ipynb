{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240e97f-d88f-446e-a369-5e5893349d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c7605-17ed-4a90-9c3c-fad8b91113e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfde0e5b-c82c-4dd5-9f02-61b0b7a2bc27",
   "metadata": {},
   "source": [
    "**The Following Code is worked Correctly!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabdafd-17e0-4523-84cd-7b022ff09aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32726a76-3389-45aa-b040-3fac71213164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def is_jpeg(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".jpg\", \".jpeg\", \".png\"])\n",
    "\n",
    "def get_subdirs(directory):\n",
    "    subdirs = sorted([os.path.join(directory, name) for name in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, name))])\n",
    "    return subdirs\n",
    "\n",
    "class ExternalInputIterator:\n",
    "    def __init__(self, imageset_dir, batch_size, random_shuffle=False):\n",
    "        self.imageset_dir = imageset_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Get subdirectories (assuming \"pose\" and \"frontal\" folders exist)\n",
    "        #self.pose_dirs = get_subdirs(os.path.join(imageset_dir, \"pose\"))\n",
    "        self.pose_dirs = os.path.join(imageset_dir, \"pose\")\n",
    "        self.frontal_dir = os.path.join(imageset_dir, \"frontal\")\n",
    "        print(self.frontal_dir)\n",
    "        print(self.pose_dirs)\n",
    "\n",
    "        # Collect profile image paths\n",
    "        self.profile_files = []\n",
    "        #for pose_dir in self.pose_dirs:\n",
    "        profile_files = [os.path.join(self.pose_dirs, file) for file in sorted(os.listdir(self.pose_dirs)) if is_jpeg(file)]\n",
    "        self.profile_files.extend(profile_files)\n",
    "        print(len(self.profile_files))\n",
    "\n",
    "        # Collect frontal image paths\n",
    "        self.frontal_files = [os.path.join(self.frontal_dir, file) for file in sorted(os.listdir(self.frontal_dir)) if is_jpeg(file)]\n",
    "        print(len(self.frontal_files))\n",
    "\n",
    "        # Shuffle if necessary\n",
    "        if random_shuffle:\n",
    "            np.random.shuffle(self.profile_files)\n",
    "            np.random.shuffle(self.frontal_files)\n",
    "\n",
    "        self.i = 0\n",
    "        self.n = len(self.profile_files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        profiles = []\n",
    "        frontals = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            profile_filename = self.profile_files[self.i]\n",
    "            frontal_filename = self.match_frontal_image(profile_filename)\n",
    "\n",
    "            with Image.open(profile_filename) as profile_img:\n",
    "                profiles.append(np.array(profile_img))\n",
    "            with Image.open(frontal_filename) as frontal_img:\n",
    "                frontals.append(np.array(frontal_img))\n",
    "\n",
    "            self.i = (self.i + 1) % self.n\n",
    "\n",
    "        return (profiles, frontals)\n",
    "\n",
    "    def match_frontal_image(self, profile_filename):\n",
    "        profile_name = os.path.basename(profile_filename).split(\"_\")[1]\n",
    "        for frontal_file in self.frontal_files:\n",
    "            if profile_name in frontal_file:\n",
    "                return frontal_file\n",
    "        return None\n",
    "\n",
    "class ImagePipeline:\n",
    "    def __init__(self, imageset_dir, image_size=128, random_shuffle=False, batch_size=64,device_id = 0):\n",
    "        self.eii = ExternalInputIterator(imageset_dir, batch_size, random_shuffle)\n",
    "        self.iterator = iter(self.eii)\n",
    "        self.num_inputs = len(self.eii.profile_files)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def epoch_size(self, name=None):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_inputs\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        (images, targets) = next(self.iterator)\n",
    "\n",
    "        # Perform resizing and normalization using NumPy\n",
    "        resized_images = np.array([np.array(Image.fromarray(img).resize((self.image_size, self.image_size))) for img in images])\n",
    "        resized_targets = np.array([np.array(Image.fromarray(target).resize((self.image_size, self.image_size))) for target in targets])\n",
    "\n",
    "        # Normalize using mean and standard deviation\n",
    "        normalized_images = (resized_images - 128.0) / 128.0\n",
    "        normalized_targets = (resized_targets - 128.0) / 128.0\n",
    "\n",
    "        return (normalized_images, normalized_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Advance the iterator to the desired index\n",
    "        for _ in range(index):\n",
    "            next(self.iterator)\n",
    "\n",
    "        # Return the next batch\n",
    "        return next(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "323ffd6b-93df-4bdc-abd1-7cc4f490fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\mydata\\frontal\n",
      "C:\\Users\\zed\\Dataset\\mydata\\pose\n",
      "200\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x = ExternalInputIterator(imageset_dir=r\"C:\\Users\\zed\\Dataset\\mydata\",batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae159f11-eb54-4228-ba26-b91343463cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "''' Generator network for 128x128 RGB images '''\n",
    "class G(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Input HxW = 128x128\n",
    "            nn.Conv2d(1, 16, 4, 2, 1), # Output HxW = 64x64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 4, 2, 1), # Output HxW = 32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), # Output HxW = 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), # Output HxW = 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), # Output HxW = 4x4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1), # Output HxW = 2x2\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            # At this point, we arrive at our low D representation vector, which is 512 dimensional.\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 1, 0, bias = False), # Output HxW = 4x4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False), # Output HxW = 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False), # Output HxW = 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias = False), # Output HxW = 32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1, bias = False), # Output HxW = 64x64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1, bias = False), # Output HxW = 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "''' Discriminator network for 128x128 RGB images '''\n",
    "class D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                                  nn.Conv2d(1, 16, 4, 2, 1),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(16, 32, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(32),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(32, 64, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(64, 128, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(128, 256, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(256, 512, 4, 2, 1),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Conv2d(512, 1, 4, 2, 1, bias = False),\n",
    "                                  nn.Sigmoid()\n",
    "                                  )\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77dffb68-3153-49cf-b6d6-c9e9203911ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\mydata\\frontal\n",
      "C:\\Users\\zed\\Dataset\\mydata\\pose\n",
      "200\n",
      "10\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:33<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  573.5028319358826  seconds\n",
      "[1/30] Training absolute losses: L1 0.1250928 ; L2 0.0379307 BCE 4.1914748\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:17<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 is starting..\n",
      "[2/30] Training absolute losses: L1 0.0585486 ; L2 0.0065839 BCE 3.5193734\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:20<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 is starting..\n",
      "[3/30] Training absolute losses: L1 0.0503019 ; L2 0.0044936 BCE 3.1273609\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"C:\\Users\\zed\\Dataset\\mydata\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "gpu_id = 0\n",
    "device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=32, device_id=gpu_id)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,)\n",
    "# Generator:\n",
    "#netG = network.G().to(device)\n",
    "#netG.apply(network.weights_init)\n",
    "netG = G().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Discriminator:\n",
    "#netD = network.D().to(device)\n",
    "#netD.apply(network.weights_init)\n",
    "netD = D().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Here is where you set how important each component of the loss function is:\n",
    "L1_factor = 0\n",
    "L2_factor = 1\n",
    "GAN_factor = 0.0005\n",
    "\n",
    "criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "\n",
    "# Optimizers for the generator and the discriminator (Adam is a fancier version of gradient descent with a few more bells and whistles that is used very often):\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999), eps = 1e-8)\n",
    "\n",
    "# Create a directory for the output files\n",
    "try:\n",
    "    os.mkdir('output')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's train for 30 epochs (meaning, we go through the entire training set 30 times):\n",
    "for epoch in range(3):\n",
    "    \n",
    "    # Lets keep track of the loss values for each epoch:\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    \n",
    "    # Your train_pipe_loader will load the images one batch at a time\n",
    "    # The inner loop iterates over those batches:\n",
    "    print(\"starting...\")\n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "        \n",
    "        # These are your images from the current batch:\n",
    "        #profile = data[0]['profiles']\n",
    "        #frontal = data[0]['frontals']\n",
    "            profile = data[0].view(32, 1, 128, 128)\n",
    "            frontal = data[1].view(32, 1, 128, 128)\n",
    "        \n",
    "        \n",
    "        # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(real)\n",
    "        # D should accept the GT images\n",
    "            errD_real = criterion(output, target)\n",
    "        \n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            generated = netG(profile)\n",
    "            target = Variable(torch.zeros(real.size()[0])).to(device)\n",
    "            output = netD(generated.detach()) # detach() because we are not training G here\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # D should reject the synthetic images\n",
    "            errD_fake = criterion(output, target)\n",
    "        \n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "        # Update D\n",
    "            optimizerD.step()\n",
    "        \n",
    "        # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(generated)\n",
    "        \n",
    "        # G wants to :\n",
    "        # (a) have the synthetic images be accepted by D (= look like frontal images of people)\n",
    "            errG_GAN = criterion(output, target)\n",
    "        \n",
    "        # (b) have the synthetic images resemble the ground truth frontal image\n",
    "            errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "        \n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "        \n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "        \n",
    "            errG.backward()\n",
    "        # Update G\n",
    "            optimizerG.step()\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    if epoch > 0:\n",
    "        print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train,))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0a64f-f58d-4aca-8d7a-133444f8218c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085797f7-71a1-471f-80e7-9805c44d6ae7",
   "metadata": {},
   "source": [
    "**Edited to visualize the loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbe450-4566-483c-82c0-7273d400c6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f9a02e-7f9f-4a10-97d1-c027430ddb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\mydata\\frontal\n",
      "C:\\Users\\zed\\Dataset\\mydata\\pose\n",
      "200\n",
      "10\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:27<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training epoch completed in  567.092960357666  seconds\n",
      "[1/30] Training absolute losses: L1 0.1250928 ; L2 0.0379307 BCE 4.1914748\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:17<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 is starting..\n",
      "[2/30] Training absolute losses: L1 0.0585486 ; L2 0.0065839 BCE 3.5193734\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 200/200 [09:12<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 is starting..\n",
      "[3/30] Training absolute losses: L1 0.0503019 ; L2 0.0044936 BCE 3.1273609\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#from data import ImagePipeline\n",
    "#import network\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "# Where is your training dataset at?\n",
    "datapath =r\"C:\\Users\\zed\\Dataset\\mydata\"\n",
    "\n",
    "# You can also choose which GPU you want your model to be trained on below:\n",
    "gpu_id = 0\n",
    "device = torch.device(\"cuda\", gpu_id)\n",
    "\n",
    "\"\"\"train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=30, device_id=gpu_id)\n",
    "train_pipe.build()\n",
    "m_train = train_pipe.epoch_size()\n",
    "print(\"Size of the training set: \", m_train)\n",
    "train_pipe_loader = DALIGenericIterator(train_pipe, [\"profiles\", \"frontals\"], m_train)\"\"\"\n",
    "# Assuming you have the modified ImagePipeline class from the previous responses\n",
    "train_pipe = ImagePipeline(datapath, image_size=128, random_shuffle=True, batch_size=32, device_id=gpu_id)\n",
    "# No need to call build() without DALI\n",
    "\n",
    "# Use a standard PyTorch DataLoader instead of DALIGenericIterator\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=train_pipe.batch_size)\n",
    "m_train = train_pipe.epoch_size()\n",
    "#train_pipe_loader = DataLoader(train_pipe, batch_size=32,)\n",
    "train_pipe_loader = DataLoader(train_pipe,)\n",
    "# Generator:\n",
    "#netG = network.G().to(device)\n",
    "#netG.apply(network.weights_init)\n",
    "netG = G().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Discriminator:\n",
    "#netD = network.D().to(device)\n",
    "#netD.apply(network.weights_init)\n",
    "netD = D().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Here is where you set how important each component of the loss function is:\n",
    "L1_factor = 0\n",
    "L2_factor = 1\n",
    "GAN_factor = 0.0005\n",
    "\n",
    "criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "\n",
    "# Optimizers for the generator and the discriminator (Adam is a fancier version of gradient descent with a few more bells and whistles that is used very often):\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999), eps = 1e-8)\n",
    "\n",
    "# Create a directory for the output files\n",
    "try:\n",
    "    os.mkdir('output')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Lists to store the losses\n",
    "losses_L1 = []\n",
    "losses_L2 = []\n",
    "losses_gan = []\n",
    "\n",
    "# Let's train for 30 epochs (meaning, we go through the entire training set 30 times):\n",
    "for epoch in range(3):\n",
    "    \n",
    "    # Lets keep track of the loss values for each epoch:\n",
    "    loss_L1 = 0\n",
    "    loss_L2 = 0\n",
    "    loss_gan = 0\n",
    "    \n",
    "    # Your train_pipe_loader will load the images one batch at a time\n",
    "    # The inner loop iterates over those batches:\n",
    "    print(\"starting...\")\n",
    "    with tqdm(total=len(train_pipe_loader), desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for i, data in enumerate(train_pipe_loader, 0):\n",
    "        \n",
    "        # These are your images from the current batch:\n",
    "        #profile = data[0]['profiles']\n",
    "        #frontal = data[0]['frontals']\n",
    "            profile = data[0].view(32, 1, 128, 128)\n",
    "            frontal = data[1].view(32, 1, 128, 128)\n",
    "        \n",
    "        \n",
    "        # TRAINING THE DISCRIMINATOR\n",
    "            netD.zero_grad()\n",
    "            real = Variable(frontal).type('torch.FloatTensor').to(device)\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(real)\n",
    "        # D should accept the GT images\n",
    "            errD_real = criterion(output, target)\n",
    "        \n",
    "            profile = Variable(profile).type('torch.FloatTensor').to(device)\n",
    "            generated = netG(profile)\n",
    "            target = Variable(torch.zeros(real.size()[0])).to(device)\n",
    "            output = netD(generated.detach()) # detach() because we are not training G here\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # D should reject the synthetic images\n",
    "            errD_fake = criterion(output, target)\n",
    "        \n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "        # Update D\n",
    "            optimizerD.step()\n",
    "        \n",
    "        # TRAINING THE GENERATOR\n",
    "            netG.zero_grad()\n",
    "            target = Variable(torch.ones(real.size()[0])).to(device)\n",
    "            output = netD(generated)\n",
    "        \n",
    "        # G wants to :\n",
    "        # (a) have the synthetic images be accepted by D (= look like frontal images of people)\n",
    "            errG_GAN = criterion(output, target)\n",
    "        \n",
    "        # (b) have the synthetic images resemble the ground truth frontal image\n",
    "            errG_L1 = torch.mean(torch.abs(real - generated))\n",
    "            errG_L2 = torch.mean(torch.pow((real - generated), 2))\n",
    "        \n",
    "            errG = GAN_factor * errG_GAN + L1_factor * errG_L1 + L2_factor * errG_L2\n",
    "        \n",
    "            loss_L1 += errG_L1.item()\n",
    "            loss_L2 += errG_L2.item()\n",
    "            loss_gan += errG_GAN.item()\n",
    "        \n",
    "            errG.backward()\n",
    "        # Update G\n",
    "            optimizerG.step()\n",
    "            \n",
    "    # Append the losses for this epoch to the respective lists\n",
    "    losses_L1.append(loss_L1 / m_train)\n",
    "    losses_L2.append(loss_L2 / m_train)\n",
    "    losses_gan.append(loss_gan / m_train)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print('First training epoch completed in ',(time.time() - start_time),' seconds')\n",
    "    if epoch > 0:\n",
    "        print(f\"Epoch: {epoch} is starting..\")\n",
    "    # reset the DALI iterator\n",
    "    #train_pipe_loader.reset()\n",
    "\n",
    "    # Print the absolute values of three losses to screen:\n",
    "    print('[%d/30] Training absolute losses: L1 %.7f ; L2 %.7f BCE %.7f' % ((epoch + 1), loss_L1/m_train, loss_L2/m_train, loss_gan/m_train,))\n",
    "\n",
    "    # Save the inputs, outputs, and ground truth frontals to files:\n",
    "    vutils.save_image(profile.data, 'output/%03d_input.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(real.data, 'output/%03d_real.jpg' % epoch, normalize=True)\n",
    "    vutils.save_image(generated.data, 'output/%03d_generated.jpg' % epoch, normalize=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # Save the pre-trained Generator as well\n",
    "    torch.save(netG,'output/netG_%d.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8dd0ac9-01fa-49c3-a589-441dea4d21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the losses\n",
    "epochs = range(1, 4)  # Assuming you trained for 3 epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, losses_L1, label='L1 Loss')\n",
    "plt.plot(epochs, losses_L2, label='L2 Loss')\n",
    "plt.plot(epochs, losses_gan, label='GAN Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aae60f14-d0a4-402b-be3c-f4831f55fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zed\\Dataset\\CAS-PEAL-R1\\test_data\\frontal\n",
      "C:\\Users\\zed\\Dataset\\CAS-PEAL-R1\\test_data\\pose\n",
      "3\n",
      "4\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([3, 1, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([3, 1, 128, 128])\n",
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([3, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(999)\n",
    "torch.cuda.manual_seed(999)\n",
    "#from data import ImagePipeline  # Assuming this custom class still exists\n",
    "\n",
    "device = 'cuda'\n",
    "datapath = r'C:\\Users\\zed\\Dataset\\CAS-PEAL-R1\\test_data'\n",
    "\n",
    "# Generate frontal images from the test set\n",
    "def frontalize(model, datapath, mtest):\n",
    "    \n",
    "    test_pipe = ImagePipeline(datapath, image_size=128, batch_size = 3, random_shuffle=False)  # Removed batch_size\n",
    "    test_pipe_loader = DataLoader(test_pipe, batch_size=mtest)  # Use DataLoader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_pipe_loader:\n",
    "             \n",
    "            profile = data[0].to(device).type(torch.float)  # Correct syntax to change data type\n",
    "            print(profile.shape)\n",
    "            profile = profile.view(3, 1, 128, 128) \n",
    "            print(profile.shape)\n",
    "            generated = model(profile).type(torch.float)  # Convert output to float\n",
    "\n",
    "            #profile = data[0].to(device)  # Assuming profiles are in data['profiles']\n",
    "            #print(\"length:\",len(profile))\n",
    "            #generated = model(profile)\n",
    "            vutils.save_image(torch.cat((profile, generated.data)), 'output/test.jpg', nrow=3, padding=2, normalize=True)  # Removed frontal for consistency\n",
    "\n",
    "# Load a pre-trained Pytorch model\n",
    "saved_model = torch.load(\"output/netG_1.pt\")\n",
    "\n",
    "frontalize(saved_model, datapath, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c02df5-395c-49ae-a72b-fb59cfbe4c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
